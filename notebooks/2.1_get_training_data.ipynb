{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_doc2vec(string_data, max_epochs, vec_size, alpha):\n",
    "     \n",
    "    # Tagging each of the documents with a unique ID\n",
    "    tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(string_data)]\n",
    "    \n",
    "    # Instantiating my model \n",
    "    model = Doc2Vec(size=vec_size, alpha=alpha, min_alpha=0.00025, min_count=1, dm=1) # dm=1 means 'distributed memory' (PV-DM)\n",
    "    \n",
    "    # Building the vocabulary table\n",
    "    model.build_vocab(tagged_data)\n",
    "    \n",
    "    for epoch in range(max_epochs): # Run for max_epochs\n",
    "        print('iteration {0}'.format(epoch))\n",
    "        model.train(tagged_data, total_examples=model.corpus_count, epochs=model.iter) # This statement trains the model on the current epoch\n",
    "        # Decreasing the learning rate\n",
    "        model.alpha -= 0.0002\n",
    "        # Fixing the learning rate, no decay\n",
    "        model.min_alpha = model.alpha\n",
    "        \n",
    "    # Saving model\n",
    "    model.save(\"models/d2v.model\")\n",
    "    print(\"Model Saved\")\n",
    "    \n",
    "# Training\n",
    "train_doc2vec(processed_inbound_extra, max_epochs = 100, vec_size = 20, alpha = 0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a synthetic dataset - generating N Tweets resembling a mock tweet\n",
    "# This will subsequently be merged with the existing inbound data for inclusion in the doc2vec training process\n",
    "\n",
    "# Version 1 - will be improved in future iterations\n",
    "ideal = {\n",
    "            \"order track\": \"@AmazonHelo Hi, could you provide an update on the order? Its been days since the product has moved from its last location \", # change intent to \"order tracking\"???\n",
    "            \"product inquiry\": \"@AmazonHelp Looking for more info on the product. Can you share details or direct me to a reliable source?\", # product inquire??? \n",
    "            \"return refund\": \"@AmazonHelp How can I start a return process? The item I received doesn't match the description.\",\n",
    "            \"account management\": \"@AmazonHelp Hi, I am having trouble logging into my account. Can you help me reset my password?\", \n",
    "            \"promotion discount\": \"@AmazonHelp Are there any ongoing promotions or deals in the ongoing festive season? Looking to buy a few items.\",\n",
    "            \"shipping\": \"@AmazonHelp Hi, My address has changed. Can you help me update the shipping address for my order?\",\n",
    "            \"technical support\": \"@AmazonHelp Encountering errors during checkout. Can you help me troubleshoot the issue?\",\n",
    "            \"payment issue\": \"@AmazonHelp My payment method isn't going through. Any suggestions on how to resolve this?\",\n",
    "            \"general query\": \"@AmazonHelp Hi, I have a general question regarding the product. Can you help me with this?\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_extra(current_tokenized_data, extra_tweets):\n",
    "    '''Adding extra tweets to the current tokenized data'''\n",
    "    \n",
    "    # Convert the extra tweets into a pandas Series\n",
    "    extra_tweets = pd.Series(extra_tweets)\n",
    "\n",
    "    # Convert the current tokenized data into a single string\n",
    "    print('Converting to string...')\n",
    "    string_processed_data = current_tokenized_data.progress_apply(\" \".join)\n",
    "\n",
    "    # Concatenate the extra tweets to the current data\n",
    "    string_processed_data = pd.concat([string_processed_data, extra_tweets], axis = 0)\n",
    "\n",
    "    # Tokenize the combined data\n",
    "    tknzr = TweetTokenizer(strip_handles = True, reduce_len = True)\n",
    "    print('Tokenizing...')\n",
    "    tokenized_data = string_processed_data.progress_apply(tknzr.tokenize)\n",
    "\n",
    "    return tokenized_data\n",
    "\n",
    "# Add the extra tweets to the current data\n",
    "processed_inbound_extra = add_extra(processed['Processed Inbound'], list(ideal.values()))\n",
    "\n",
    "# Save the updated data to a pickle file\n",
    "processed_inbound_extra.to_pickle('objects/processed_inbound_extra.pkl')\n",
    "\n",
    "processed_inbound_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the necessary cleaning and convert them into the \"processed_inbound\" format\n",
    "def scrape_tweets_with_replies(tweet):\n",
    "    # Creating a list of replies to the tweet\n",
    "    replies = []\n",
    "    for reply in tweepy.Cursor(api.search, q='to:'+tweet.user.screen_name, since_id=tweet.id, tweet_mode='extended').items(1000):\n",
    "        if hasattr(reply, 'in_reply_to_status_id_str'):\n",
    "            if (reply.in_reply_to_status_id_str==tweet.id_str):\n",
    "                replies.append(reply)\n",
    "    return replies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "customer-support",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

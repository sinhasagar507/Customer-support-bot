{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import triu\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     different people have given different answers ...\n",
       "5     way to drop the ball on customer service so pi...\n",
       "6     i want my amazon payments account closed dm me...\n",
       "9     yeah this is crazy were less than a week away ...\n",
       "10    how about you guys figure out my xbox one x pr...\n",
       "Name: clean_inbound_text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the processed data and the processed inbound dataset \n",
    "processed_df = pd.read_pickle(\"../data/processed/processed_v2.pkl\")\n",
    "processed_inbound_extra = processed_df[\"clean_inbound_text\"]\n",
    "processed_inbound_extra.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index. Set it properly in this iteration \n",
    "processed_df = processed_df.reset_index(drop=True)\n",
    "processed_inbound_extra = processed_inbound_extra.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inbound_text               0\n",
       "author_id                  0\n",
       "created_at                 0\n",
       "outbound_text              0\n",
       "response_tweet_id      60327\n",
       "inbound_lang               0\n",
       "inbound_hashtags           0\n",
       "outbound_hashtags          0\n",
       "clean_inbound_text         0\n",
       "clean_outbound_text        0\n",
       "outbound_tokens_pos        0\n",
       "inbound_tokens_pos         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for some null values \n",
    "processed_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "intents:\n",
      "{'track': ['tracking', 'order', 'shipment', 'late', 'status', 'carrier', 'update', 'number', 'info', 'received', 'details'], 'support': ['service'], 'quality': ['quality', 'product', 'damaged', 'received', 'refund', 'return', 'issue', 'order', 'packaging', 'proper', 'working', 'expected', 'different'], 'discount': ['prime', 'product', 'offer', 'price', 'sale'], 'account': ['email', 'orders', 'details', 'bank', 'access']}\n",
      "\n",
      "processed:\n",
      "                                        inbound_text   author_id  \\\n",
      "0  @AmazonHelp 3 different people have given 3 di...  AmazonHelp   \n",
      "1  Way to drop the ball on customer service @1158...  AmazonHelp   \n",
      "2  @115823 I want my amazon payments account CLOS...  AmazonHelp   \n",
      "3  @AmazonHelp @115826 Yeah this is crazy we’re l...  AmazonHelp   \n",
      "4  @115828 How about you guys figure out my Xbox ...  AmazonHelp   \n",
      "\n",
      "                  created_at  \\\n",
      "0  2017-10-31 23:28:00+00:00   \n",
      "1  2017-10-31 22:29:00+00:00   \n",
      "2  2017-10-31 22:28:34+00:00   \n",
      "3  2017-11-01 12:53:34+00:00   \n",
      "4  2017-10-31 22:28:00+00:00   \n",
      "\n",
      "                                       outbound_text response_tweet_id  \\\n",
      "0  @115820 We'd like to take a further look into ...               619   \n",
      "1  @115820 I'm sorry we've let you down! Without ...               616   \n",
      "2  @115822 I am unable to affect your account via...               NaN   \n",
      "3              @115827 Thanks for your patience. ^KM               NaN   \n",
      "4  @115826 I'm sorry for the wait. You'll receive...               627   \n",
      "\n",
      "  inbound_lang inbound_hashtags outbound_hashtags  \\\n",
      "0           en               []                []   \n",
      "1           en               []                []   \n",
      "2           en               []                []   \n",
      "3           en               []                []   \n",
      "4           en               []                []   \n",
      "\n",
      "                                  clean_inbound_text  \\\n",
      "0  different people have given different answers ...   \n",
      "1  way to drop the ball on customer service so pi...   \n",
      "2  i want my amazon payments account closed dm me...   \n",
      "3  yeah this is crazy were less than a week away ...   \n",
      "4  how about you guys figure out my xbox one x pr...   \n",
      "\n",
      "                                 clean_outbound_text  \\\n",
      "0  wed like to take a further look into this with...   \n",
      "1  i am sorry we have let you down without provid...   \n",
      "2  i am unable to affect your account via twitter...   \n",
      "3                        thanks for your patience km   \n",
      "4  i am sorry for the wait you will receive an em...   \n",
      "\n",
      "                                 outbound_tokens_pos  \\\n",
      "0  [-PRON-: NOUN, d: VERB, like: VERB, to: NOUN, ...   \n",
      "1  [i: NOUN, be: NOUN, sorry: NOUN, -PRON-: NOUN,...   \n",
      "2  [i: NOUN, be: NOUN, unable: NOUN, to: NOUN, af...   \n",
      "3  [thank: NOUN, for: NOUN, -PRON-: NOUN, patienc...   \n",
      "4  [i: NOUN, be: NOUN, sorry: NOUN, for: NOUN, th...   \n",
      "\n",
      "                                  inbound_tokens_pos  \n",
      "0  [different: NOUN, people: NOUN, have: NOUN, gi...  \n",
      "1  [way: NOUN, to: NOUN, drop: VERB, the: NOUN, b...  \n",
      "2  [i: NOUN, want: VERB, -PRON-: NOUN, amazon: NO...  \n",
      "3  [yeah: NOUN, this: NOUN, be: NOUN, crazy: NOUN...  \n",
      "4  [how: NOUN, about: NOUN, -PRON-: NOUN, guy: NO...  \n"
     ]
    }
   ],
   "source": [
    "# Read in the intents back \n",
    "with open(r\"../objects/intents_amazon_support.yml\") as file:\n",
    "    intents = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "# Previewing\n",
    "print(f'\\nintents:\\n{intents}')\n",
    "print(f'\\nprocessed:\\n{processed_df.head()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet Collection with Doc2Vec \n",
    "I can use my Doc2Vec representation to find top 1000 Tweets most similar to a generalized intent version of a Tweet based on it's cosine similarity. \n",
    "\n",
    "Heuristic search refers to a search strategy that attempts to optimize a problem by iteratively improving the solution based on a given heuristic function or a cost measure. My cost measure is trying to get the closest cosine distances.\n",
    "\n",
    "So I basically trained my doc2vec model with my training data, which is the `processed_inbound`. I can actually compute a vector based on my training data to vectorize that word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training my Doc2Vec \n",
    "\n",
    "### Data Synthesis \n",
    "Basically, there are 2 ways I can get my current training data (1000 for each)\n",
    "* **Doc2Vec:** Some intent examples I will synthetically generate from an idealized example using doc2vec\n",
    "* **Manual:** Some intent examples I will synthetically generate by duplicating and manual (like greeting, because the current data does not represent this)\n",
    "* **Hybrid:** Some intents I will do a hybrid approach, where 50 percent might be my generated data, and 50 percent might be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Add information about Doc2Vec or post a link to it over here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a synthetic dataset - generating N Tweets resembling a mock tweet\n",
    "# This will subsequently be merged with the existing inbound data for inclusion in the doc2vec training process\n",
    "\n",
    "# Version 1 - will be improved in future iterations\n",
    "ideal = {\n",
    "            \"order track\": \"@AmazonHelo Hi, could you provide an update on the order? Its been days since the product has moved from its last location \", # change intent to \"order tracking\"???\n",
    "            \"product inquiry\": \"@AmazonHelp Looking for more info on the product. Can you share details or direct me to a reliable source?\", # product inquire??? \n",
    "            \"return refund\": \"@AmazonHelp How can I start a return process? The item I received doesn't match the description.\",\n",
    "            \"account management\": \"@AmazonHelp Hi, I am having trouble logging into my account. Can you help me reset my password?\", \n",
    "            \"promotion discount\": \"@AmazonHelp Are there any ongoing promotions or deals in the ongoing festive season? Looking to buy a few items.\",\n",
    "            \"shipping\": \"@AmazonHelp Hi, My address has changed. Can you help me update the shipping address for my order?\",\n",
    "            \"technical support\": \"@AmazonHelp Encountering errors during checkout. Can you help me troubleshoot the issue?\",\n",
    "            \"payment issue\": \"@AmazonHelp My payment method isn't going through. Any suggestions on how to resolve this?\",\n",
    "            \"general query\": \"@AmazonHelp Hi, I have a general question regarding the product. Can you help me with this?\"\n",
    "        }\n",
    "\n",
    "# Version 2 - Here I will try writing some more intent items \n",
    "ideal_tag_dict = {\n",
    "                    \"track\": \"tracking order shipoment late status carrier update number info received details\", \n",
    "                    \"support\": \"support chat customer resolution feedback satisfaction\",\n",
    "                    \"quality\": \"quality product damaged received refund return issue order packaging proper working expected different\", \n",
    "                    \"discount\": \"prime product offer price sale\", \n",
    "                    \"account\": \"email orders details bank access\"\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inbound_text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>outbound_text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>inbound_lang</th>\n",
       "      <th>inbound_hashtags</th>\n",
       "      <th>outbound_hashtags</th>\n",
       "      <th>clean_inbound_text</th>\n",
       "      <th>clean_outbound_text</th>\n",
       "      <th>outbound_tokens_pos</th>\n",
       "      <th>inbound_tokens_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@AmazonHelp 3 different people have given 3 di...</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>2017-10-31 23:28:00+00:00</td>\n",
       "      <td>@115820 We'd like to take a further look into ...</td>\n",
       "      <td>619</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>different people have given different answers ...</td>\n",
       "      <td>wed like to take a further look into this with...</td>\n",
       "      <td>[-PRON-: NOUN, d: VERB, like: VERB, to: NOUN, ...</td>\n",
       "      <td>[different: NOUN, people: NOUN, have: NOUN, gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Way to drop the ball on customer service @1158...</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>2017-10-31 22:29:00+00:00</td>\n",
       "      <td>@115820 I'm sorry we've let you down! Without ...</td>\n",
       "      <td>616</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>way to drop the ball on customer service so pi...</td>\n",
       "      <td>i am sorry we have let you down without provid...</td>\n",
       "      <td>[i: NOUN, be: NOUN, sorry: NOUN, -PRON-: NOUN,...</td>\n",
       "      <td>[way: NOUN, to: NOUN, drop: VERB, the: NOUN, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@115823 I want my amazon payments account CLOS...</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>2017-10-31 22:28:34+00:00</td>\n",
       "      <td>@115822 I am unable to affect your account via...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>i want my amazon payments account closed dm me...</td>\n",
       "      <td>i am unable to affect your account via twitter...</td>\n",
       "      <td>[i: NOUN, be: NOUN, unable: NOUN, to: NOUN, af...</td>\n",
       "      <td>[i: NOUN, want: VERB, -PRON-: NOUN, amazon: NO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@AmazonHelp @115826 Yeah this is crazy we’re l...</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>2017-11-01 12:53:34+00:00</td>\n",
       "      <td>@115827 Thanks for your patience. ^KM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>yeah this is crazy were less than a week away ...</td>\n",
       "      <td>thanks for your patience km</td>\n",
       "      <td>[thank: NOUN, for: NOUN, -PRON-: NOUN, patienc...</td>\n",
       "      <td>[yeah: NOUN, this: NOUN, be: NOUN, crazy: NOUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@115828 How about you guys figure out my Xbox ...</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>2017-10-31 22:28:00+00:00</td>\n",
       "      <td>@115826 I'm sorry for the wait. You'll receive...</td>\n",
       "      <td>627</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>how about you guys figure out my xbox one x pr...</td>\n",
       "      <td>i am sorry for the wait you will receive an em...</td>\n",
       "      <td>[i: NOUN, be: NOUN, sorry: NOUN, for: NOUN, th...</td>\n",
       "      <td>[how: NOUN, about: NOUN, -PRON-: NOUN, guy: NO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122335</th>\n",
       "      <td>@AmazonHelp I sent you guys a DM regarding the...</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>2017-11-22 00:17:00+00:00</td>\n",
       "      <td>@328597 We're unable to access customer accoun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>i sent you guys a dm regarding the status of m...</td>\n",
       "      <td>were unable to access customer accounts via so...</td>\n",
       "      <td>[be: NOUN, unable: NOUN, to: NOUN, access: VER...</td>\n",
       "      <td>[i: NOUN, send: VERB, -PRON-: NOUN, guy: NOUN,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122336</th>\n",
       "      <td>This is happening in my area w/@115821 “Prime”...</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>2017-11-22 02:16:55+00:00</td>\n",
       "      <td>@777901 I'm sorry for the delay, Brenda! We st...</td>\n",
       "      <td>2987557</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>this is happening in my area w prime deliverie...</td>\n",
       "      <td>i am sorry for the delay brenda we strive to s...</td>\n",
       "      <td>[i: NOUN, be: NOUN, sorry: NOUN, for: NOUN, th...</td>\n",
       "      <td>[this: NOUN, be: NOUN, happen: VERB, in: NOUN,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122337</th>\n",
       "      <td>@132994 @132995 @115850 got my #OnePlus5T at 8...</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>2017-11-22 03:49:29+00:00</td>\n",
       "      <td>@823783 Woohoo! That's awesome! Hope you love ...</td>\n",
       "      <td>2987674</td>\n",
       "      <td>en</td>\n",
       "      <td>[#AmazonPrime, #OnePlus5T]</td>\n",
       "      <td>[]</td>\n",
       "      <td>got my at am thanks for fulfilling the order fast</td>\n",
       "      <td>woohoo that is awesome hope you love the phone js</td>\n",
       "      <td>[woohoo: NOUN, that: NOUN, be: NOUN, awesome: ...</td>\n",
       "      <td>[get: VERB, -PRON-: NOUN, at: NOUN, be: NOUN, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122338</th>\n",
       "      <td>@115850 @132994 No exchange available for #One...</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>2017-11-22 05:22:31+00:00</td>\n",
       "      <td>@823802 The Exchange Offer is currently availa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>[#OnePlus5T]</td>\n",
       "      <td>[]</td>\n",
       "      <td>no exchange available for i need to exchange m...</td>\n",
       "      <td>the exchange offer is currently available only...</td>\n",
       "      <td>[the: NOUN, exchange: NOUN, offer: NOUN, be: N...</td>\n",
       "      <td>[no: NOUN, exchange: NOUN, available: NOUN, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122339</th>\n",
       "      <td>@115850  there should be bonus and gifts for r...</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>2017-11-22 06:20:00+00:00</td>\n",
       "      <td>@823829 We do not have any such offer at this ...</td>\n",
       "      <td>2987817</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>there should be bonus and gifts for regular cu...</td>\n",
       "      <td>we do not have any such offer at this point in...</td>\n",
       "      <td>[-PRON-: NOUN, do: NOUN, not: NOUN, have: NOUN...</td>\n",
       "      <td>[there: NOUN, should: VERB, be: NOUN, bonus: N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122340 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             inbound_text   author_id  \\\n",
       "0       @AmazonHelp 3 different people have given 3 di...  AmazonHelp   \n",
       "1       Way to drop the ball on customer service @1158...  AmazonHelp   \n",
       "2       @115823 I want my amazon payments account CLOS...  AmazonHelp   \n",
       "3       @AmazonHelp @115826 Yeah this is crazy we’re l...  AmazonHelp   \n",
       "4       @115828 How about you guys figure out my Xbox ...  AmazonHelp   \n",
       "...                                                   ...         ...   \n",
       "122335  @AmazonHelp I sent you guys a DM regarding the...  AmazonHelp   \n",
       "122336  This is happening in my area w/@115821 “Prime”...  AmazonHelp   \n",
       "122337  @132994 @132995 @115850 got my #OnePlus5T at 8...  AmazonHelp   \n",
       "122338  @115850 @132994 No exchange available for #One...  AmazonHelp   \n",
       "122339  @115850  there should be bonus and gifts for r...  AmazonHelp   \n",
       "\n",
       "                       created_at  \\\n",
       "0       2017-10-31 23:28:00+00:00   \n",
       "1       2017-10-31 22:29:00+00:00   \n",
       "2       2017-10-31 22:28:34+00:00   \n",
       "3       2017-11-01 12:53:34+00:00   \n",
       "4       2017-10-31 22:28:00+00:00   \n",
       "...                           ...   \n",
       "122335  2017-11-22 00:17:00+00:00   \n",
       "122336  2017-11-22 02:16:55+00:00   \n",
       "122337  2017-11-22 03:49:29+00:00   \n",
       "122338  2017-11-22 05:22:31+00:00   \n",
       "122339  2017-11-22 06:20:00+00:00   \n",
       "\n",
       "                                            outbound_text response_tweet_id  \\\n",
       "0       @115820 We'd like to take a further look into ...               619   \n",
       "1       @115820 I'm sorry we've let you down! Without ...               616   \n",
       "2       @115822 I am unable to affect your account via...               NaN   \n",
       "3                   @115827 Thanks for your patience. ^KM               NaN   \n",
       "4       @115826 I'm sorry for the wait. You'll receive...               627   \n",
       "...                                                   ...               ...   \n",
       "122335  @328597 We're unable to access customer accoun...               NaN   \n",
       "122336  @777901 I'm sorry for the delay, Brenda! We st...           2987557   \n",
       "122337  @823783 Woohoo! That's awesome! Hope you love ...           2987674   \n",
       "122338  @823802 The Exchange Offer is currently availa...               NaN   \n",
       "122339  @823829 We do not have any such offer at this ...           2987817   \n",
       "\n",
       "       inbound_lang            inbound_hashtags outbound_hashtags  \\\n",
       "0                en                          []                []   \n",
       "1                en                          []                []   \n",
       "2                en                          []                []   \n",
       "3                en                          []                []   \n",
       "4                en                          []                []   \n",
       "...             ...                         ...               ...   \n",
       "122335           en                          []                []   \n",
       "122336           en                          []                []   \n",
       "122337           en  [#AmazonPrime, #OnePlus5T]                []   \n",
       "122338           en                [#OnePlus5T]                []   \n",
       "122339           en                          []                []   \n",
       "\n",
       "                                       clean_inbound_text  \\\n",
       "0       different people have given different answers ...   \n",
       "1       way to drop the ball on customer service so pi...   \n",
       "2       i want my amazon payments account closed dm me...   \n",
       "3       yeah this is crazy were less than a week away ...   \n",
       "4       how about you guys figure out my xbox one x pr...   \n",
       "...                                                   ...   \n",
       "122335  i sent you guys a dm regarding the status of m...   \n",
       "122336  this is happening in my area w prime deliverie...   \n",
       "122337  got my at am thanks for fulfilling the order fast   \n",
       "122338  no exchange available for i need to exchange m...   \n",
       "122339  there should be bonus and gifts for regular cu...   \n",
       "\n",
       "                                      clean_outbound_text  \\\n",
       "0       wed like to take a further look into this with...   \n",
       "1       i am sorry we have let you down without provid...   \n",
       "2       i am unable to affect your account via twitter...   \n",
       "3                             thanks for your patience km   \n",
       "4       i am sorry for the wait you will receive an em...   \n",
       "...                                                   ...   \n",
       "122335  were unable to access customer accounts via so...   \n",
       "122336  i am sorry for the delay brenda we strive to s...   \n",
       "122337  woohoo that is awesome hope you love the phone js   \n",
       "122338  the exchange offer is currently available only...   \n",
       "122339  we do not have any such offer at this point in...   \n",
       "\n",
       "                                      outbound_tokens_pos  \\\n",
       "0       [-PRON-: NOUN, d: VERB, like: VERB, to: NOUN, ...   \n",
       "1       [i: NOUN, be: NOUN, sorry: NOUN, -PRON-: NOUN,...   \n",
       "2       [i: NOUN, be: NOUN, unable: NOUN, to: NOUN, af...   \n",
       "3       [thank: NOUN, for: NOUN, -PRON-: NOUN, patienc...   \n",
       "4       [i: NOUN, be: NOUN, sorry: NOUN, for: NOUN, th...   \n",
       "...                                                   ...   \n",
       "122335  [be: NOUN, unable: NOUN, to: NOUN, access: VER...   \n",
       "122336  [i: NOUN, be: NOUN, sorry: NOUN, for: NOUN, th...   \n",
       "122337  [woohoo: NOUN, that: NOUN, be: NOUN, awesome: ...   \n",
       "122338  [the: NOUN, exchange: NOUN, offer: NOUN, be: N...   \n",
       "122339  [-PRON-: NOUN, do: NOUN, not: NOUN, have: NOUN...   \n",
       "\n",
       "                                       inbound_tokens_pos  \n",
       "0       [different: NOUN, people: NOUN, have: NOUN, gi...  \n",
       "1       [way: NOUN, to: NOUN, drop: VERB, the: NOUN, b...  \n",
       "2       [i: NOUN, want: VERB, -PRON-: NOUN, amazon: NO...  \n",
       "3       [yeah: NOUN, this: NOUN, be: NOUN, crazy: NOUN...  \n",
       "4       [how: NOUN, about: NOUN, -PRON-: NOUN, guy: NO...  \n",
       "...                                                   ...  \n",
       "122335  [i: NOUN, send: VERB, -PRON-: NOUN, guy: NOUN,...  \n",
       "122336  [this: NOUN, be: NOUN, happen: VERB, in: NOUN,...  \n",
       "122337  [get: VERB, -PRON-: NOUN, at: NOUN, be: NOUN, ...  \n",
       "122338  [no: NOUN, exchange: NOUN, available: NOUN, fo...  \n",
       "122339  [there: NOUN, should: VERB, be: NOUN, bonus: N...  \n",
       "\n",
       "[122340 rows x 12 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122345/122345 [00:05<00:00, 22029.41it/s]\n",
      "100%|██████████| 122345/122345 [00:00<00:00, 2024005.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         different people have given different answers ...\n",
       "1         way to drop the ball on customer service so pi...\n",
       "2         i want my amazon payments account closed dm me...\n",
       "3         yeah this is crazy were less than a week away ...\n",
       "4         how about you guys figure out my xbox one x pr...\n",
       "                                ...                        \n",
       "122340    tracking order shipoment late status carrier u...\n",
       "122341    support chat customer resolution feedback sati...\n",
       "122342    quality product damaged received refund return...\n",
       "122343                       prime product offer price sale\n",
       "122344                     email orders details bank access\n",
       "Length: 122345, dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_extra(clean_inbound_text, extra_tweets):\n",
    "    '''Adding extra tweets to the current tokenized data'''\n",
    "    \n",
    "    # Convert the extra tweets into a pandas Series\n",
    "    extra_tweets = pd.Series(extra_tweets)\n",
    "\n",
    "    ## The following 2 steps aren't required for now as the data is already in string format \n",
    "    ## Convert the extra tweets into a single string\n",
    "    # print(\"Converting to string...\")\n",
    "    # string_processed_data = current_tokenized_data.progress_apply(\" \".join)\n",
    "\n",
    "    # Concatenate the extra tweets to the current data\n",
    "    clean_inbound_text = pd.concat([clean_inbound_text, extra_tweets], axis = 0, ignore_index = True)\n",
    "\n",
    "    # Tokenize the combined data\n",
    "    tknzr = TweetTokenizer(strip_handles = True, reduce_len = True)\n",
    "    print(\"Tokenizing...\")\n",
    "    tokenized_data = clean_inbound_text.progress_apply(tknzr.tokenize)\n",
    "    string_processed_data = tokenized_data.progress_apply(\" \".join)\n",
    "\n",
    "    return string_processed_data\n",
    "\n",
    "# Add the extra tweets to the current data\n",
    "processed_inbound_extra = add_extra(processed_df[\"clean_inbound_text\"], list(ideal_tag_dict.values()))\n",
    "\n",
    "# Save the updated data to a pickle file\n",
    "processed_inbound_extra.to_pickle(\"../objects/processed_inbound_extra.pkl\")\n",
    "\n",
    "processed_inbound_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122338    no exchange available for i need to exchange m...\n",
       "122339    there should be bonus and gifts for regular cu...\n",
       "122340    tracking order shipoment late status carrier u...\n",
       "122341    support chat customer resolution feedback sati...\n",
       "122342    quality product damaged received refund return...\n",
       "122343                       prime product offer price sale\n",
       "122344                     email orders details bank access\n",
       "dtype: object"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_inbound_extra[-7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122345,)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_inbound_extra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 20\n",
      "iteration 21\n",
      "iteration 22\n",
      "iteration 23\n",
      "iteration 24\n",
      "iteration 25\n",
      "iteration 26\n",
      "iteration 27\n",
      "iteration 28\n",
      "iteration 29\n",
      "iteration 30\n",
      "iteration 31\n",
      "iteration 32\n",
      "iteration 33\n",
      "iteration 34\n",
      "iteration 35\n",
      "iteration 36\n",
      "iteration 37\n",
      "iteration 38\n",
      "iteration 39\n",
      "iteration 40\n",
      "iteration 41\n",
      "iteration 42\n",
      "iteration 43\n",
      "iteration 44\n",
      "iteration 45\n",
      "iteration 46\n",
      "iteration 47\n",
      "iteration 48\n",
      "iteration 49\n",
      "iteration 50\n",
      "iteration 51\n",
      "iteration 52\n",
      "iteration 53\n",
      "iteration 54\n",
      "iteration 55\n",
      "iteration 56\n",
      "iteration 57\n",
      "iteration 58\n",
      "iteration 59\n",
      "iteration 60\n",
      "iteration 61\n",
      "iteration 62\n",
      "iteration 63\n",
      "iteration 64\n",
      "iteration 65\n",
      "iteration 66\n",
      "iteration 67\n",
      "iteration 68\n",
      "iteration 69\n",
      "iteration 70\n",
      "iteration 71\n",
      "iteration 72\n",
      "iteration 73\n",
      "iteration 74\n",
      "iteration 75\n",
      "iteration 76\n",
      "iteration 77\n",
      "iteration 78\n",
      "iteration 79\n",
      "iteration 80\n",
      "iteration 81\n",
      "iteration 82\n",
      "iteration 83\n",
      "iteration 84\n",
      "iteration 85\n",
      "iteration 86\n",
      "iteration 87\n",
      "iteration 88\n",
      "iteration 89\n",
      "iteration 90\n",
      "iteration 91\n",
      "iteration 92\n",
      "iteration 93\n",
      "iteration 94\n",
      "iteration 95\n",
      "iteration 96\n",
      "iteration 97\n",
      "iteration 98\n",
      "iteration 99\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "# Train a Doc2Vec model on the entire corpus \n",
    "def train_doc2vec(string_data, max_epochs, vec_size, alpha):\n",
    "     \n",
    "    # Tagging each of the documents with a unique ID\n",
    "    tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(string_data)]\n",
    "    \n",
    "    # Instantiating my model \n",
    "    model = Doc2Vec(vector_size=vec_size, alpha=alpha, min_alpha=0.00025, min_count=1, dm=1) # dm=1 means 'distributed memory' (PV-DM)\n",
    "    \n",
    "    # Building the vocabulary table\n",
    "    model.build_vocab(tagged_data)\n",
    "    \n",
    "    for epoch in range(max_epochs): # Run for max_epochs\n",
    "        print('iteration {0}'.format(epoch))    \n",
    "        model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs) # This statement trains the model on the current epoch\n",
    "        # Decreasing the learning rate\n",
    "        model.alpha -= 0.0002\n",
    "        # Fixing the learning rate, no decay\n",
    "        model.min_alpha = model.alpha\n",
    "        \n",
    "    # Saving model\n",
    "    model.save(\"../models/d2v.model\")\n",
    "    print(\"Model Saved\")        \n",
    "    \n",
    "# Training\n",
    "train_doc2vec(processed_inbound_extra, max_epochs=100, vec_size=20, alpha=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the Doc2Vec model \n",
    "model = Doc2Vec.load(\"../models/d2v.model\")\n",
    "\n",
    "# Storing all inbound data into a list for clustering \n",
    "inbound_d2v = np.array([model.infer_vector(word_tokenize(_d.lower())) for _d in list(processed_inbound_extra)])\n",
    "\n",
    "# Saving\n",
    "with open(\"../objects/inbound_d2v.pkl\", \"wb\") as f:\n",
    "    pkl.dump(inbound_d2v, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122340, 20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbound_d2v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before, we did not have a concept of distance in our vectorizers, they don't really have a specific meaning. This is a much better way because it captures the contextual representations between words! Now the clustering should be a lot better than tfidf or bag of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "Initially, to get the top 1000 similar Tweets, I tried using the existing data. But I don't think that would yield the most accurate results because I am not capturing not the best representative Tweet for an intent. For that reason, I made all these base representative Tweets myself (as seen in the values derived from `ideal` dict above). The goal is to find trying to find an idealized, wholistic representation of an intent. Then from there I use my doc2vec representations to find the top 1000 tweets most similar based on cosine similarity.\n",
    "\n",
    "### Package Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'track': ['tracking',\n",
       "  'order',\n",
       "  'shipment',\n",
       "  'late',\n",
       "  'status',\n",
       "  'carrier',\n",
       "  'update',\n",
       "  'number',\n",
       "  'info',\n",
       "  'received',\n",
       "  'details'],\n",
       " 'support': ['service'],\n",
       " 'quality': ['quality',\n",
       "  'product',\n",
       "  'damaged',\n",
       "  'received',\n",
       "  'refund',\n",
       "  'return',\n",
       "  'issue',\n",
       "  'order',\n",
       "  'packaging',\n",
       "  'proper',\n",
       "  'working',\n",
       "  'expected',\n",
       "  'different'],\n",
       " 'discount': ['prime', 'product', 'offer', 'price', 'sale'],\n",
       " 'account': ['email', 'orders', 'details', 'bank', 'access']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.04887684,  0.05137751,  0.02112605, -0.04393798, -0.0508075 ,\n",
       "        -0.01057845,  0.10617889, -0.04808602,  0.13243914, -0.0396963 ,\n",
       "        -0.04897077, -0.13161062,  0.00144   ,  0.02005946, -0.0413356 ,\n",
       "         0.07014607, -0.02099573,  0.09428328, -0.02107974,  0.0300785 ],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Trying an example \n",
    "## Finding and making idealized versions of each tweet so that I can \n",
    "intents_eg = {\"discount\": [\"prime\", \"product\", \"offer\", \"price\", \"sale\"]}\n",
    "inferred_vectors = []\n",
    "\n",
    "for keywords in intents_eg.values():\n",
    "    inferred_vectors.append(model.infer_vector(intents_eg))\n",
    "    \n",
    "inferred_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: My Doc2Vec model vector is inferring different vector values for a given sample. I think I need to treat the model in a better fashion later on  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([['tracking', 'order', 'shipment', 'late', 'status', 'carrier', 'update', 'number', 'info', 'received', 'details'], ['service'], ['quality', 'product', 'damaged', 'received', 'refund', 'return', 'issue', 'order', 'packaging', 'proper', 'working', 'expected', 'different'], ['prime', 'product', 'offer', 'price', 'sale'], ['email', 'orders', 'details', 'bank', 'access']])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'track': ['tracking', 'order', 'shipment', 'late', 'status', 'carrier', 'update', 'number', 'info', 'received', 'details'], 'support': ['service'], 'quality': ['quality', 'product', 'damaged', 'received', 'refund', 'return', 'issue', 'order', 'packaging', 'proper', 'working', 'expected', 'different'], 'discount': ['prime', 'product', 'offer', 'price', 'sale'], 'account': ['email', 'orders', 'details', 'bank', 'access']}\n"
     ]
    }
   ],
   "source": [
    "# These are the current intents I wish to add to my training data \n",
    "print(intents) \n",
    "\n",
    "# Concatenate all the intent values in a sentence form \n",
    "ideal_values = list(\" \".join(_words) for _words in intents.values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have chosen my intent value tokens based on the frequency count of words as described in the previous notebooks. If performance is not upto the mark, reiterate and improve upon them in the future version(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding intent tags \n",
    "I want to get the tags of my representative Tweets because that's what doc2vec's `model.similarity` method takes in as paramater to generate top N Tweets similar to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Improve this block of code later - The following code block isn't the most efficient one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('track', ['tracking', 'order', 'shipment', 'late', 'status', 'carrier', 'update', 'number', 'info', 'received', 'details']), ('support', ['service']), ('quality', ['quality', 'product', 'damaged', 'received', 'refund', 'return', 'issue', 'order', 'packaging', 'proper', 'working', 'expected', 'different']), ('discount', ['prime', 'product', 'offer', 'price', 'sale']), ('account', ['email', 'orders', 'details', 'bank', 'access'])])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'track': ['tracking', 'order', 'shipoment', 'late', 'status', 'carrier', 'update', 'number', 'info', 'received', 'details'], 'support': ['support', 'chat', 'customer', 'resolution', 'feedback', 'satisfaction'], 'quality': ['quality', 'product', 'damaged', 'received', 'refund', 'return', 'issue', 'order', 'packaging', 'proper', 'working', 'expected', 'different'], 'discount': ['prime', 'product', 'offer', 'price', 'sale'], 'account': ['email', 'orders', 'details', 'bank', 'access']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = TweetTokenizer(strip_handles = True, reduce_len = True)\n",
    "\n",
    "intents_repr = {k: tokenizer.tokenize(v) for k, v in ideal_tag_dict.items()}\n",
    "print(intents_repr)\n",
    "\n",
    "# Save them into objects \n",
    "with open(\"../objects/intents_repr.yml\", \"w\") as f:\n",
    "    yaml.dump(intents_repr, f, default_flow_style=False)\n",
    "\n",
    "# Storing tags in order of the dictionary above\n",
    "tags = []\n",
    "\n",
    "# Tokenize and process inbound tweets \n",
    "tokenized_processed_inbound_extra = processed_inbound_extra.apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inbound_text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>outbound_text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>inbound_lang</th>\n",
       "      <th>inbound_hashtags</th>\n",
       "      <th>outbound_hashtags</th>\n",
       "      <th>clean_inbound_text</th>\n",
       "      <th>clean_outbound_text</th>\n",
       "      <th>outbound_tokens_pos</th>\n",
       "      <th>inbound_tokens_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@AmazonHelp 3 different people have given 3 di...</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>2017-10-31 23:28:00+00:00</td>\n",
       "      <td>@115820 We'd like to take a further look into ...</td>\n",
       "      <td>619</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>different people have given different answers ...</td>\n",
       "      <td>wed like to take a further look into this with...</td>\n",
       "      <td>[-PRON-: NOUN, d: VERB, like: VERB, to: NOUN, ...</td>\n",
       "      <td>[different: NOUN, people: NOUN, have: NOUN, gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Way to drop the ball on customer service @1158...</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>2017-10-31 22:29:00+00:00</td>\n",
       "      <td>@115820 I'm sorry we've let you down! Without ...</td>\n",
       "      <td>616</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>way to drop the ball on customer service so pi...</td>\n",
       "      <td>i am sorry we have let you down without provid...</td>\n",
       "      <td>[i: NOUN, be: NOUN, sorry: NOUN, -PRON-: NOUN,...</td>\n",
       "      <td>[way: NOUN, to: NOUN, drop: VERB, the: NOUN, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@115823 I want my amazon payments account CLOS...</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>2017-10-31 22:28:34+00:00</td>\n",
       "      <td>@115822 I am unable to affect your account via...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>i want my amazon payments account closed dm me...</td>\n",
       "      <td>i am unable to affect your account via twitter...</td>\n",
       "      <td>[i: NOUN, be: NOUN, unable: NOUN, to: NOUN, af...</td>\n",
       "      <td>[i: NOUN, want: VERB, -PRON-: NOUN, amazon: NO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@AmazonHelp @115826 Yeah this is crazy we’re l...</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>2017-11-01 12:53:34+00:00</td>\n",
       "      <td>@115827 Thanks for your patience. ^KM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>yeah this is crazy were less than a week away ...</td>\n",
       "      <td>thanks for your patience km</td>\n",
       "      <td>[thank: NOUN, for: NOUN, -PRON-: NOUN, patienc...</td>\n",
       "      <td>[yeah: NOUN, this: NOUN, be: NOUN, crazy: NOUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@115828 How about you guys figure out my Xbox ...</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>2017-10-31 22:28:00+00:00</td>\n",
       "      <td>@115826 I'm sorry for the wait. You'll receive...</td>\n",
       "      <td>627</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>how about you guys figure out my xbox one x pr...</td>\n",
       "      <td>i am sorry for the wait you will receive an em...</td>\n",
       "      <td>[i: NOUN, be: NOUN, sorry: NOUN, for: NOUN, th...</td>\n",
       "      <td>[how: NOUN, about: NOUN, -PRON-: NOUN, guy: NO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122335</th>\n",
       "      <td>@AmazonHelp I sent you guys a DM regarding the...</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>2017-11-22 00:17:00+00:00</td>\n",
       "      <td>@328597 We're unable to access customer accoun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>i sent you guys a dm regarding the status of m...</td>\n",
       "      <td>were unable to access customer accounts via so...</td>\n",
       "      <td>[be: NOUN, unable: NOUN, to: NOUN, access: VER...</td>\n",
       "      <td>[i: NOUN, send: VERB, -PRON-: NOUN, guy: NOUN,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122336</th>\n",
       "      <td>This is happening in my area w/@115821 “Prime”...</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>2017-11-22 02:16:55+00:00</td>\n",
       "      <td>@777901 I'm sorry for the delay, Brenda! We st...</td>\n",
       "      <td>2987557</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>this is happening in my area w prime deliverie...</td>\n",
       "      <td>i am sorry for the delay brenda we strive to s...</td>\n",
       "      <td>[i: NOUN, be: NOUN, sorry: NOUN, for: NOUN, th...</td>\n",
       "      <td>[this: NOUN, be: NOUN, happen: VERB, in: NOUN,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122337</th>\n",
       "      <td>@132994 @132995 @115850 got my #OnePlus5T at 8...</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>2017-11-22 03:49:29+00:00</td>\n",
       "      <td>@823783 Woohoo! That's awesome! Hope you love ...</td>\n",
       "      <td>2987674</td>\n",
       "      <td>en</td>\n",
       "      <td>[#AmazonPrime, #OnePlus5T]</td>\n",
       "      <td>[]</td>\n",
       "      <td>got my at am thanks for fulfilling the order fast</td>\n",
       "      <td>woohoo that is awesome hope you love the phone js</td>\n",
       "      <td>[woohoo: NOUN, that: NOUN, be: NOUN, awesome: ...</td>\n",
       "      <td>[get: VERB, -PRON-: NOUN, at: NOUN, be: NOUN, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122338</th>\n",
       "      <td>@115850 @132994 No exchange available for #One...</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>2017-11-22 05:22:31+00:00</td>\n",
       "      <td>@823802 The Exchange Offer is currently availa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>[#OnePlus5T]</td>\n",
       "      <td>[]</td>\n",
       "      <td>no exchange available for i need to exchange m...</td>\n",
       "      <td>the exchange offer is currently available only...</td>\n",
       "      <td>[the: NOUN, exchange: NOUN, offer: NOUN, be: N...</td>\n",
       "      <td>[no: NOUN, exchange: NOUN, available: NOUN, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122339</th>\n",
       "      <td>@115850  there should be bonus and gifts for r...</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>2017-11-22 06:20:00+00:00</td>\n",
       "      <td>@823829 We do not have any such offer at this ...</td>\n",
       "      <td>2987817</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>there should be bonus and gifts for regular cu...</td>\n",
       "      <td>we do not have any such offer at this point in...</td>\n",
       "      <td>[-PRON-: NOUN, do: NOUN, not: NOUN, have: NOUN...</td>\n",
       "      <td>[there: NOUN, should: VERB, be: NOUN, bonus: N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122340 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             inbound_text   author_id  \\\n",
       "0       @AmazonHelp 3 different people have given 3 di...  AmazonHelp   \n",
       "1       Way to drop the ball on customer service @1158...  AmazonHelp   \n",
       "2       @115823 I want my amazon payments account CLOS...  AmazonHelp   \n",
       "3       @AmazonHelp @115826 Yeah this is crazy we’re l...  AmazonHelp   \n",
       "4       @115828 How about you guys figure out my Xbox ...  AmazonHelp   \n",
       "...                                                   ...         ...   \n",
       "122335  @AmazonHelp I sent you guys a DM regarding the...  AmazonHelp   \n",
       "122336  This is happening in my area w/@115821 “Prime”...  AmazonHelp   \n",
       "122337  @132994 @132995 @115850 got my #OnePlus5T at 8...  AmazonHelp   \n",
       "122338  @115850 @132994 No exchange available for #One...  AmazonHelp   \n",
       "122339  @115850  there should be bonus and gifts for r...  AmazonHelp   \n",
       "\n",
       "                       created_at  \\\n",
       "0       2017-10-31 23:28:00+00:00   \n",
       "1       2017-10-31 22:29:00+00:00   \n",
       "2       2017-10-31 22:28:34+00:00   \n",
       "3       2017-11-01 12:53:34+00:00   \n",
       "4       2017-10-31 22:28:00+00:00   \n",
       "...                           ...   \n",
       "122335  2017-11-22 00:17:00+00:00   \n",
       "122336  2017-11-22 02:16:55+00:00   \n",
       "122337  2017-11-22 03:49:29+00:00   \n",
       "122338  2017-11-22 05:22:31+00:00   \n",
       "122339  2017-11-22 06:20:00+00:00   \n",
       "\n",
       "                                            outbound_text response_tweet_id  \\\n",
       "0       @115820 We'd like to take a further look into ...               619   \n",
       "1       @115820 I'm sorry we've let you down! Without ...               616   \n",
       "2       @115822 I am unable to affect your account via...               NaN   \n",
       "3                   @115827 Thanks for your patience. ^KM               NaN   \n",
       "4       @115826 I'm sorry for the wait. You'll receive...               627   \n",
       "...                                                   ...               ...   \n",
       "122335  @328597 We're unable to access customer accoun...               NaN   \n",
       "122336  @777901 I'm sorry for the delay, Brenda! We st...           2987557   \n",
       "122337  @823783 Woohoo! That's awesome! Hope you love ...           2987674   \n",
       "122338  @823802 The Exchange Offer is currently availa...               NaN   \n",
       "122339  @823829 We do not have any such offer at this ...           2987817   \n",
       "\n",
       "       inbound_lang            inbound_hashtags outbound_hashtags  \\\n",
       "0                en                          []                []   \n",
       "1                en                          []                []   \n",
       "2                en                          []                []   \n",
       "3                en                          []                []   \n",
       "4                en                          []                []   \n",
       "...             ...                         ...               ...   \n",
       "122335           en                          []                []   \n",
       "122336           en                          []                []   \n",
       "122337           en  [#AmazonPrime, #OnePlus5T]                []   \n",
       "122338           en                [#OnePlus5T]                []   \n",
       "122339           en                          []                []   \n",
       "\n",
       "                                       clean_inbound_text  \\\n",
       "0       different people have given different answers ...   \n",
       "1       way to drop the ball on customer service so pi...   \n",
       "2       i want my amazon payments account closed dm me...   \n",
       "3       yeah this is crazy were less than a week away ...   \n",
       "4       how about you guys figure out my xbox one x pr...   \n",
       "...                                                   ...   \n",
       "122335  i sent you guys a dm regarding the status of m...   \n",
       "122336  this is happening in my area w prime deliverie...   \n",
       "122337  got my at am thanks for fulfilling the order fast   \n",
       "122338  no exchange available for i need to exchange m...   \n",
       "122339  there should be bonus and gifts for regular cu...   \n",
       "\n",
       "                                      clean_outbound_text  \\\n",
       "0       wed like to take a further look into this with...   \n",
       "1       i am sorry we have let you down without provid...   \n",
       "2       i am unable to affect your account via twitter...   \n",
       "3                             thanks for your patience km   \n",
       "4       i am sorry for the wait you will receive an em...   \n",
       "...                                                   ...   \n",
       "122335  were unable to access customer accounts via so...   \n",
       "122336  i am sorry for the delay brenda we strive to s...   \n",
       "122337  woohoo that is awesome hope you love the phone js   \n",
       "122338  the exchange offer is currently available only...   \n",
       "122339  we do not have any such offer at this point in...   \n",
       "\n",
       "                                      outbound_tokens_pos  \\\n",
       "0       [-PRON-: NOUN, d: VERB, like: VERB, to: NOUN, ...   \n",
       "1       [i: NOUN, be: NOUN, sorry: NOUN, -PRON-: NOUN,...   \n",
       "2       [i: NOUN, be: NOUN, unable: NOUN, to: NOUN, af...   \n",
       "3       [thank: NOUN, for: NOUN, -PRON-: NOUN, patienc...   \n",
       "4       [i: NOUN, be: NOUN, sorry: NOUN, for: NOUN, th...   \n",
       "...                                                   ...   \n",
       "122335  [be: NOUN, unable: NOUN, to: NOUN, access: VER...   \n",
       "122336  [i: NOUN, be: NOUN, sorry: NOUN, for: NOUN, th...   \n",
       "122337  [woohoo: NOUN, that: NOUN, be: NOUN, awesome: ...   \n",
       "122338  [the: NOUN, exchange: NOUN, offer: NOUN, be: N...   \n",
       "122339  [-PRON-: NOUN, do: NOUN, not: NOUN, have: NOUN...   \n",
       "\n",
       "                                       inbound_tokens_pos  \n",
       "0       [different: NOUN, people: NOUN, have: NOUN, gi...  \n",
       "1       [way: NOUN, to: NOUN, drop: VERB, the: NOUN, b...  \n",
       "2       [i: NOUN, want: VERB, -PRON-: NOUN, amazon: NO...  \n",
       "3       [yeah: NOUN, this: NOUN, be: NOUN, crazy: NOUN...  \n",
       "4       [how: NOUN, about: NOUN, -PRON-: NOUN, guy: NO...  \n",
       "...                                                   ...  \n",
       "122335  [i: NOUN, send: VERB, -PRON-: NOUN, guy: NOUN,...  \n",
       "122336  [this: NOUN, be: NOUN, happen: VERB, in: NOUN,...  \n",
       "122337  [get: VERB, -PRON-: NOUN, at: NOUN, be: NOUN, ...  \n",
       "122338  [no: NOUN, exchange: NOUN, available: NOUN, fo...  \n",
       "122339  [there: NOUN, should: VERB, be: NOUN, bonus: N...  \n",
       "\n",
       "[122340 rows x 12 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_inbound_extra = pd.concat([processed_inbound_extra, pd.Series(ideal_tag_dict.values())], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_processed_inbound_extra = pd.concat([tokenized_processed_inbound_extra, pd.Series(intents_repr.values())], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         different people have given different answers ...\n",
       "1         way to drop the ball on customer service so pi...\n",
       "2         i want my amazon payments account closed dm me...\n",
       "3         yeah this is crazy were less than a week away ...\n",
       "4         how about you guys figure out my xbox one x pr...\n",
       "                                ...                        \n",
       "122340    tracking order shipoment late status carrier u...\n",
       "122341    support chat customer resolution feedback sati...\n",
       "122342    quality product damaged received refund return...\n",
       "122343                       prime product offer price sale\n",
       "122344                     email orders details bank access\n",
       "Length: 122345, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_inbound_extra "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [different, people, have, given, different, an...\n",
       "1         [way, to, drop, the, ball, on, customer, servi...\n",
       "2         [i, want, my, amazon, payments, account, close...\n",
       "3         [yeah, this, is, crazy, were, less, than, a, w...\n",
       "4         [how, about, you, guys, figure, out, my, xbox,...\n",
       "                                ...                        \n",
       "122340    [tracking, order, shipoment, late, status, car...\n",
       "122341    [support, chat, customer, resolution, feedback...\n",
       "122342    [quality, product, damaged, received, refund, ...\n",
       "122343                 [prime, product, offer, price, sale]\n",
       "122344               [email, orders, details, bank, access]\n",
       "Length: 122345, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_processed_inbound_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAGGED INDEXES TO LOOK FOR\n",
      "\n",
      "track \n",
      "Index: 122340\n",
      "Preview: 122340    tracking order shipoment late status carrier u...\n",
      "dtype: object\n",
      "\n",
      "support \n",
      "Index: 122341\n",
      "Preview: 122341    support chat customer resolution feedback sati...\n",
      "dtype: object\n",
      "\n",
      "quality \n",
      "Index: 122342\n",
      "Preview: 122342    quality product damaged received refund return...\n",
      "dtype: object\n",
      "\n",
      "discount \n",
      "Index: 122343\n",
      "Preview: 122343    prime product offer price sale\n",
      "dtype: object\n",
      "\n",
      "account \n",
      "Index: 122344\n",
      "Preview: 122344    email orders details bank access\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Find the index locations of specific Tweets\n",
    "# get_indices = []\n",
    "def report_index_loc(tweet, intent_name):\n",
    "    ''' Takes in the tweet to find the index for and returns a report of that tweet index along with what the \n",
    "    representative Tweet looks like'''\n",
    "    try:\n",
    "        tweets = [] # List which stores tuples of indexes of representative tweets AND a boolean value to indicate if the tweet has the intent we are looking for\n",
    "        for i, j in enumerate(tokenized_processed_inbound_extra):\n",
    "            if j == tweet:\n",
    "                tweets.append((i, True))\n",
    "            else:\n",
    "                tweets.append((i, False))\n",
    "\n",
    "        indices = [i[0] for i in tweets if i[1] == True]\n",
    "        # get_indices.append(indices.append(i[0]) if i[1] == True else False for i in tweets)\n",
    "\n",
    "        preview = processed_inbound_extra.iloc[indices]\n",
    "\n",
    "        # Appending to indexes for dictionary \n",
    "        tags.append(str(indices[0]))\n",
    "\n",
    "    except IndexError as e:\n",
    "        print(\"Index not in list, move on\")\n",
    "        return\n",
    "\n",
    "    return intent_name, str(indices[0]), preview\n",
    "\n",
    "\n",
    "# Reporting and storing indexes with the function\n",
    "print(\"TAGGED INDEXES TO LOOK FOR\")\n",
    "for j, i in intents_repr.items():\n",
    "    try:\n",
    "        print('\\n{} \\nIndex: {}\\nPreview: {}'.format(*report_index_loc(i, j)))\n",
    "    except Exception as e:\n",
    "        print(\"Index ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.3733561 ,  0.02103804, -0.11288577,  0.10018096,  0.02359817,\n",
       "        0.20761223,  0.13943799, -0.07680623,  0.8658018 , -0.05790734,\n",
       "       -0.07379842, -0.91106176, -0.29489738, -0.16348544,  0.17043671,\n",
       "        0.04266841, -0.37820813,  0.34814504,  0.0160022 , -0.33846483],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferred_vector = model.infer_vector(tokenized_processed_inbound_extra[122342])\n",
    "inferred_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quality',\n",
       " 'product',\n",
       " 'damaged',\n",
       " 'received',\n",
       " 'refund',\n",
       " 'return',\n",
       " 'issue',\n",
       " 'order',\n",
       " 'packaging',\n",
       " 'proper',\n",
       " 'working',\n",
       " 'expected',\n",
       " 'different']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_processed_inbound_extra[122342]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tyrwhitt', 0.7233047485351562),\n",
       " ('charles', 0.7212222814559937),\n",
       " ('poundmax', 0.7111672759056091),\n",
       " ('biotique', 0.7026564478874207),\n",
       " ('honeywell', 0.6814860105514526)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Great! Now I can get the training data for my battery intent (as an example)\n",
    "similar_doc = model.wv.most_similar(inferred_vector, topn = 1000)\n",
    "# Preview\n",
    "similar_doc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tracking order shipoment late status carrier update number info received details'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_inbound_extra[122340]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tracking',\n",
       " 'order',\n",
       " 'shipoment',\n",
       " 'late',\n",
       " 'status',\n",
       " 'carrier',\n",
       " 'update',\n",
       " 'number',\n",
       " 'info',\n",
       " 'received',\n",
       " 'details']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_processed_inbound_extra[122340]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [different, people, have, given, different, an...\n",
       "1         [way, to, drop, the, ball, on, customer, servi...\n",
       "2         [i, want, my, amazon, payments, account, close...\n",
       "3         [yeah, this, is, crazy, were, less, than, a, w...\n",
       "4         [how, about, you, guys, figure, out, my, xbox,...\n",
       "                                ...                        \n",
       "122340    [tracking, order, shipoment, late, status, car...\n",
       "122341    [support, chat, customer, resolution, feedback...\n",
       "122342    [quality, product, damaged, received, refund, ...\n",
       "122343                 [prime, product, offer, price, sale]\n",
       "122344               [email, orders, details, bank, access]\n",
       "Length: 122345, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_processed_inbound_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'False',\n",
       " 'False',\n",
       " 'False',\n",
       " 'False',\n",
       " 'False',\n",
       " 'False',\n",
       " 'False',\n",
       " 'False',\n",
       " 'False',\n",
       " 'False',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " '122340',\n",
       " '122341',\n",
       " '122342',\n",
       " '122343',\n",
       " '122344']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Synthesis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's is the catch. Have intent buckets inplace already in place. You would need to supply this to the below function to get your top N tweets corresponding to the current tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping the intent to the row index \n",
    "intent_itags = {\n",
    "    \n",
    "}\n",
    "\n",
    "# Storing tags in order of the dictionary above \n",
    "\n",
    "\n",
    "def generate_intent(nsim, idx_tag): \n",
    "    '''Function that maps an index tag to an intent and returns nsim number of similar tweets'''\n",
    "    sim_docs = model.docvecs.most_similar(idx_tag, topn = nsim)\n",
    "    \n",
    "    # Getting just the indexes \n",
    "    indexes = [int(i[0]) for i in sim_docs]\n",
    "    \n",
    "    # Actually seeing the top 1000 tweets similar to 0th tweet which seems to be about updates \n",
    "    # print(processed_inbound_extra[indexes])\n",
    "    return indexes\n",
    "    \n",
    "# Create a dictionary mapping the intent to the row index of tweets\n",
    "index_intents = {}\n",
    "for intent, tag in intent_itags.items():\n",
    "    print('Intent: ', intent)\n",
    "    index_indents[intent] = generate_intent(1000, tag)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now map the index to each row of the preprocessed inbound data\n",
    "preprocessed_inbound[\"intent\"] = processed_inbounnd.index.map(index_intents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intent classification with Keras \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.37.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (5.3.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (1.8.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (5.4.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/saggysimmba/Library/Python/3.12/lib/python/site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in /Users/saggysimmba/Library/Python/3.12/lib/python/site-packages (from streamlit) (24.0)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (10.3.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (4.25.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (17.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (2.31.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (13.7.1)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (8.3.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (4.11.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /Users/saggysimmba/Library/Python/3.12/lib/python/site-packages (from streamlit) (6.4)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit) (4.22.0)\n",
      "Requirement already satisfied: toolz in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/saggysimmba/Library/Python/3.12/lib/python/site-packages (from pandas<3,>=1.3.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/saggysimmba/Library/Python/3.12/lib/python/site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/saggysimmba/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## Install streamlit \n",
    "%pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "## actions.py \n",
    "import random\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy \n",
    "\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "# Data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import collections\n",
    "import yaml\n",
    "\n",
    "## Load in the objects\n",
    "\n",
    "# Load in thew training data  \n",
    "train_data = pd.read_pickle(\"../objects/train.pkl\")\n",
    "\n",
    "# Entity_dictionary \n",
    "# Read in the entity dictionary\n",
    "with open('../objects/entities_non_span.yml') as file:\n",
    "    entity_dict_non_span = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "# Load in the entities \n",
    "human_nlp = spacy.load(\"../models/human_nlp\")\n",
    "robot_nlp = spacy.load(\"../models/robot_nlp\")\n",
    "package_nlp = spacy.load(\"../models/package_nlp\")\n",
    "\n",
    "class Actions: \n",
    "    memory = {\"ROBOT_AI\": [], \"HUMAN\": [], \"PACKAGE\": []}\n",
    "    \n",
    "    def __init__(self, startup): \n",
    "        # The initial prompt \n",
    "        self.startup = startup\n",
    "        \n",
    "    # If greet \n",
    "    def utter_greet(self):\n",
    "        # Storing the bank of responses \n",
    "        return random.choice(\n",
    "            [\n",
    "                \"Hello! I am the Saggy AI robot. How may I assist you today?\", \n",
    "                \"Hello, How may I be of help?\" \n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    # If goodbye \n",
    "    def utter_goodbye(self):\n",
    "        reaffirm = [\"Is there anything else I can help you with?\"]\n",
    "        goodbye = [\n",
    "            \"Thank you for this your time. Have a nice day!!!\", \n",
    "            \"Glad I could be of help, have a nice day!!!\"\n",
    "        ]\n",
    "        return random.choice(goodbye)\n",
    "        \n",
    "    \n",
    "    # Speak to a representative\n",
    "    def link_to_human(self):\n",
    "        return random.choice(\n",
    "            [\n",
    "                \"Alright. Let me direct you to a representative. \"\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    # Check order status\n",
    "    def check_order_status(self):\n",
    "        return random.choice(\n",
    "            [\n",
    "                \"Please provide me with your order number\", \n",
    "                \"Please provide me with your order number so I can check the status of your shipment\" \n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    # Returns and refunds \n",
    "    def return_refunds(self): \n",
    "        return random.choice(\n",
    "            [\n",
    "              \"The refunds should ideally be processed within 3-5 business days. For more details, refer to the following link: https://www.amazon.com/gp/help/customer/display.html?nodeId=GNW5VKFXMF72FFMR\",\n",
    "              \"Thank you for reaching out. I understand that you're concerned about the refund process. Typically, refunds are processed within 3-5 business days. For more detailed information, you can visit the following link: https://www.amazon.com/gp/help/customer/display.html?nodeId=GNW5VKFXMF72FFMR\"\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    # Faulty_product\n",
    "    def faulty_product(self):\n",
    "        return random.choice(\n",
    "            [\n",
    "                \"I am sorry to hear that you received a faulty product. For details on how to return the product, please refer to the following link: https://www.amazon.com/gp/help/customer/display.html?nodeId=GP7Z9RS868ZP5J9F\",\n",
    "                \"I'm truly sorry to hear that you've received a faulty product. To make things right, you can follow our return instructions by visiting the link below:  https://www.amazon.com/gp/help/customer/display.html?nodeId=GP7Z9RS868ZP5J9F\"\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    # Account issues \n",
    "    def account_issues(self):\n",
    "        return random.choice(\n",
    "            [\n",
    "                \"In case you have forgotten your password, please click on the forgot password link. You can refer the instructions here: https://www.amazon.com/gp/help/customer/display.html?nodeId=GH3NM2YWEFEL2CQ4\", \n",
    "                \"If your account was locked due to unusual payment activity, please follow the instructions over here: https://www.amazon.com/gp/help/customer/display.html?nodeId=ThMznYkNjxdOL3GTah\"\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    # Poor customer support \n",
    "    def customer_support(self):\n",
    "        return random.choice(\n",
    "            [\n",
    "                \"I'm sorry to hear that you've had a poor experience with our customer support. You can email your experience to experience@amazon.com\", \n",
    "                \"I apologize for the poor customer support you've received. I urge you to email your experience at: experience@amazon.com \"\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    # Discounts and promotions\n",
    "    def discounts_promotions(self):\n",
    "        return random.choice(\n",
    "            [\"If you have queries with respect to discounts, promotions, gift cards and related things, you can visit the following link: https://www.amazon.com/hz/contact-us/foresight/hubgateway\", \n",
    "             \"For inquiries regarding discounts, promotions, gift cards, or related topics, please visit: https://www.amazon.com/hz/contact-us/foresight/hubgateway\"\n",
    "            ] \n",
    "        )\n",
    "        \n",
    "    # Issues with payment \n",
    "    def payment_issues(self):\n",
    "        return random.choice(\n",
    "            [\n",
    "                \"Ensure your card details (number, expiration date, and CVV) are entered correctly, your payment method is up-to-date, and there are no issues with your card by contacting your bank\"\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def talk_entity(self, entity_label): \n",
    "        # I think I might need to improvise my chatbot along these lines \n",
    "        # if entity == \"check_order_status\": \n",
    "        #     return self.check_order_status()\n",
    "        # elif entity == \"return_refunds\": \n",
    "        #     return self.return_refunds()\n",
    "        # elif entity == \"faulty_product\": \n",
    "        #     return self.faulty_product()\n",
    "        # elif entity == \"account_issues\": \n",
    "        #     return self.account_issues()\n",
    "        # elif entity == \"customer_support\": \n",
    "        #     return self.customer_support()\n",
    "        # elif entity == \"payment_issues\": \n",
    "        #     return self.payment_issues()\n",
    "        # else: \n",
    "        #     return \"I am sorry, I am not sure how to help with that.\"\n",
    "        # entity_lst = []\n",
    "        # Load the human_nlp model \n",
    "        # human_nlp = spacy.load(\"../objects/human_nlp\")\n",
    "        \n",
    "        # # Load the robot_nlp model\n",
    "        # robot_nlp = spacy.load(\"../objects/robot_nlp\")\n",
    "        \n",
    "        if entity_label==\"ROBOT_AI\":\n",
    "            return random.choice(\"Yeah I am saggy AI bot. I am here to help!!!\")\n",
    "        \n",
    "        elif entity_label==\"HUMAN\":\n",
    "            return random.choice(\"Please hold on. If you haven't already shared your issue with me, kindly do so now. Otherwise, you will need to wait for a representative to assist you at the following contact number: 1-602-670-3742.\")\n",
    "            \n",
    "       # So I am going to add all of these \n",
    "       ## check_order_status AND wrong_items \n",
    "       ## account_issues - unable  to login and all - untimely delivery \n",
    "       ## unauthorized access - faulty_product - customer_service \n",
    "       ## customer_support not working \n",
    "       ## faulty payment system \n",
    "       \n",
    "    def fallback(self):\n",
    "        return random.choice(\n",
    "            [\n",
    "                \"I apologize, I am not sure how to help with that. For more instructions, refer this link: https://www.amazon.com/hz/contact-us/\"\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define_model.py \n",
    "from torch import nn\n",
    "import wandb\n",
    "\n",
    "# Define the default model configuration\n",
    "# start a new wandb run to track this script\n",
    "CONFIG = {\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"epochs\": 30,\n",
    "    \"batch_size\": 32, \n",
    "    \"embedding_size\": 200,\n",
    "    \"hidden_size\": 128,\n",
    "    \"output_size\": 9,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.2,\n",
    "    \"eval_metric\": \"accuracy\", \n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"scheduler_lambda_epoch_threshold\": 10,\n",
    "    \"scheduler_decay_rate\": -0.1\n",
    "}\n",
    "\n",
    "# Define global constants \n",
    "SEQ_LEN = 32 \n",
    "\n",
    "class IntentClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_matrix): \n",
    "        super().__init__()\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding_dim = CONFIG[\"embedding_size\"]\n",
    "        embedding_matrix_tensor = torch.FloatTensor(embedding_matrix)\n",
    "        self.embedding = nn.Embedding(SEQ_LEN, self.embedding_dim)\n",
    "        self.embedding.weight = nn.Parameter(embedding_matrix_tensor)\n",
    "        self.embedding.weight.requires_grad = False  # To not train the embedding layer\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.hidden_dim = CONFIG[\"hidden_size\"]\n",
    "        self.num_layers = CONFIG[\"num_layers\"]\n",
    "        self.dropout = nn.Dropout(CONFIG[\"dropout\"])\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_dim, \n",
    "                            hidden_size=self.hidden_dim, \n",
    "                            num_layers=self.num_layers, \n",
    "                            bidirectional=True, \n",
    "                            dropout=CONFIG[\"dropout\"], \n",
    "                            batch_first=True)\n",
    "        \n",
    "        # The output of this operation should be \n",
    "        \n",
    "        # Dense layers \n",
    "\n",
    "        self.fc1 = nn.Linear(self.hidden_dim*2, 1024)  # 2 for bidirectional. Over here, its (128*2) = 256, 1024 is the output dimension of the first dense layer\n",
    "        self.fc2 = nn.Linear(1024, 512) \n",
    "        self.fc3 = nn.Linear(512, 256) \n",
    "        \n",
    "        # Dropout layer\n",
    "       # self.dropout = nn.Dropout(self.dropout)  \n",
    "        \n",
    "        # Output layer\n",
    "        self.output_dim = CONFIG[\"output_size\"]\n",
    "        self.out = nn.Linear(256, self.output_dim) ## Yaar idhr output hoga RNN ya LSTM ka (batch_size output_dim, no_of_classes) aayega kya? \n",
    "        # self.out_2 = nn.Linear(output_dim, 9)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # text = [batch_size, embed_length]\n",
    "        \n",
    "        # embeddings = self.dropout(self.embedding(inputs))\n",
    "        \n",
    "        # embedded = [batch_size, sent_length, emb_dim]\n",
    "\n",
    "        # if self.embedding_matrix is not None: \n",
    "        #     assert self.embeddings.shape == (inputs.shape[0], inputs.shape[1], self.embedding_dim)\n",
    "         \n",
    "        # pack_padded_sequence before feeding to the LSTM. This is required so PyTorch knows \n",
    "        # which elements of the sequence are padded and ignores them in the computation \n",
    "        # Accomplished only after the embedding step \n",
    "        # embeds_pack = pack_padded_sequence(embeddings, inputs_lengths, batch_first=True)\n",
    "        \n",
    "        # Get the dimensions of the packed sequence \n",
    "        # dimensions = embeds_pack.data.size()\n",
    "\n",
    "        # Assert the shape of input sequence \n",
    "        # assert inputs.shape == (Config.BATCH_SIZE, 1000)\n",
    "\n",
    "        embeddings = self.embedding(inputs)\n",
    "        # print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "        _, (hidden, _) = self.lstm(embeddings)\n",
    "\n",
    "        # hidden shape: [num_layers*num_directions, batch_size, hidden_dim]\n",
    "        # print(f\"Hidden shape: {hidden.shape}\n",
    "        \n",
    "        # Ours task being a classification model, we are only interested in the final hidden state and not the LSTM output \n",
    "        # h_n and c_n = [num_directions * num_layers, batch_size, hidden_size]\n",
    "        final_hidden_forward = hidden[-2, :, :] # [batch_size, hidden_dim]\n",
    "        final_hidden_backward = hidden[-1, :, :] # [bacth_size, hidden_dim]\n",
    "\n",
    "        # print(f\"Final hidden forward shape: {final_hidden_forward.shape}\") # Iska shape is \n",
    "        # print(f\"Final hidden backward shape: {final_hidden_backward.shape}\")\n",
    "        \n",
    "        # Concat the final forward and hidden backward states \n",
    "        hidden = torch.cat((final_hidden_forward, final_hidden_backward), dim=1)\n",
    "        # print(f\"Hidden shape after concatenation: {hidden.shape}\")\n",
    "                \n",
    "        # Dense Linear Layers \n",
    "        dense_outputs_1 = self.fc1(hidden)\n",
    "        dense_outputs_1 = nn.ReLU()(dense_outputs_1) \n",
    "        # Dropout layer \n",
    "        dense_outputs_1 = self.dropout(dense_outputs_1) \n",
    "        dense_outputs_2 = self.fc2(dense_outputs_1)\n",
    "     #   dense_outputs_2 = self.dropout(dense_outputs_2)\n",
    "        dense_outputs_2 = nn.ReLU()(dense_outputs_2) \n",
    "        dense_outputs_3 = self.fc3(dense_outputs_2)\n",
    "        dense_outputs_3 = nn.ReLU()(dense_outputs_3)\n",
    "     #  dense_outputs_3 = self.dropout(dense_outputs_3)\n",
    "\n",
    "        # Final output classification layer\n",
    "        # Applying the Softmax layer \n",
    "        final_output = (self.out(dense_outputs_3))\n",
    "        # print(f\"Final output shape: {final_output.shape}\")\n",
    "    \n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/saggysimmba/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 204, 1268, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([[  15,  204, 1268,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]])\n",
      "tensor([7])\n",
      "['support']\n",
      "tensor([[0.3045, 0.1428, 0.0000, 0.9742, 0.5081, 0.5360, 0.3562, 1.0000, 0.0246]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:52: SyntaxWarning: invalid escape sequence '\\:'\n",
      "<>:57: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:61: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:52: SyntaxWarning: invalid escape sequence '\\:'\n",
      "<>:57: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:61: SyntaxWarning: invalid escape sequence '\\w'\n",
      "/var/folders/m0/nhpw880n2pbdfh3k943xczbr0000gn/T/ipykernel_84625/1899063686.py:52: SyntaxWarning: invalid escape sequence '\\:'\n",
      "  pattern = \"(https\\:)*\\/*\\/*(www\\.)?(\\w+)(\\.\\w+)\\/*\\w*\"\n",
      "/var/folders/m0/nhpw880n2pbdfh3k943xczbr0000gn/T/ipykernel_84625/1899063686.py:57: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  text = re.sub(\"@\\S+\", \"\", text)\n",
      "/var/folders/m0/nhpw880n2pbdfh3k943xczbr0000gn/T/ipykernel_84625/1899063686.py:61: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  text = re.sub(\"#\\w+\", \"\", text)\n"
     ]
    }
   ],
   "source": [
    "## initialize_intent_classifier.py \n",
    "# Importing the necessary libraries\n",
    "import re \n",
    "import string \n",
    "import contractions as cm\n",
    "from nltk.tokenize import TweetTokenizer #type: ignore\n",
    "import pickle as pkl \n",
    "import torch\n",
    "import joblib\n",
    "# from src.models.define_model import IntentClassifier\n",
    "# from src.models.define_model import IntentClassifier\n",
    "# Define the sequence length\n",
    "SEQ_LEN = 32\n",
    "\n",
    "# Load the embedding matrix\n",
    "with open(\"../objects/embedding_matrix.pkl\", \"rb\") as file:\n",
    "    embedding_matrix = pkl.load(file)\n",
    "    \n",
    "# Load the vocabulary\n",
    "with open(\"../objects/vocabulary.pkl\", \"rb\") as file:\n",
    "    vocabulary = pkl.load(file)\n",
    "    \n",
    "# Load the label encoder\n",
    "with open(\"../objects/label_encoder.joblib\", \"rb\") as file:\n",
    "    label_encoder = joblib.load(file)\n",
    "    \n",
    "# Initialize and load the model \n",
    "model = IntentClassifier(embedding_matrix)\n",
    "checkpoint = torch.load(\"../models/intent_classification_model.pt\")  \n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "\n",
    "# Create a blank Tokenizer with just the English vocab\n",
    "tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "\n",
    "def clean_text(\n",
    "        text, words=True, stops=True, urls=True, tags=True, hashtags = True, punctuations=True,  \n",
    "        newLine=True, ellipsis=True, special_chars=True, condensed=True, non_breaking_space=True, \n",
    "        character_encodings=True, stopwords=True, only_words=True) -> str:\n",
    "    \n",
    "    \"\"\" Clean tweets after extracting all hashtags and username tags\n",
    "    Not comprehensive enough to capture all idiosyncrasies, but works for most of the time\n",
    "    \"\"\"\n",
    "    \n",
    "    # Capture only words and no numbers\n",
    "    if words:\n",
    "        pattern = r\"\\d\"\n",
    "        text = re.sub(pattern, \"\", text)\n",
    "        \n",
    "    # Remove URLs \n",
    "    if urls:\n",
    "        pattern = \"(https\\:)*\\/*\\/*(www\\.)?(\\w+)(\\.\\w+)\\/*\\w*\"\n",
    "        text = re.sub(pattern, \"\", text)\n",
    "        \n",
    "    # Remove tags \n",
    "    if tags:\n",
    "        text = re.sub(\"@\\S+\", \"\", text)\n",
    "        \n",
    "    # Remove hashtags \n",
    "    if hashtags: \n",
    "        text = re.sub(\"#\\w+\", \"\", text)\n",
    "        \n",
    "    # Remove punctuations\n",
    "    if punctuations:\n",
    "        for punct in list(string.punctuation): \n",
    "            text = text.replace(punct, \"\")\n",
    "        \n",
    "    # Replacing one or more occurrences of '\\n' with ''\n",
    "    # Replacing multiple occurrences, i.e., >=2 occurrences with '.'\n",
    "    if newLine:\n",
    "        text = re.sub(\"\\n+\", \"\", text)\n",
    "        text = re.sub(r'\\.\\s+', '.', text)\n",
    "        \n",
    "    # Fix contractions\n",
    "    if condensed:\n",
    "        try:\n",
    "            text = cm.fix(text)\n",
    "        except: \n",
    "            print(text)\n",
    "        \n",
    "    # Remove non-breaking space \n",
    "    if non_breaking_space: \n",
    "        pattern = r\"(\\xa0|&nbsp)\"\n",
    "        text = re.sub(pattern, \"\", text)\n",
    "        \n",
    "    # Remove stopwords\n",
    "    # if stopwords:\n",
    "    #     text = text.lower()\n",
    "    #     # print(f\"Original Shape of the Data is {.shape}\")\n",
    "        \n",
    "    #     # Splitting with NLTK's Tweet tokenizer. This limits repeated characters to \n",
    "    #     # three with the reduce lens parameter and strips all the \"@'s\". It also splits \n",
    "    #     # it into 1-gram tokens         \n",
    "    #     words = tokenizer.tokenize(text)\n",
    "    #     filtered_words = [word for word in words if word not in eng_stopwords]\n",
    "    #     text = \" \".join(words)\n",
    "    #     text = text.strip()  # Add further checks for cleaning \n",
    "    \n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    def basic_preprocess_tokens(tokens): \n",
    "        # Convert to lowercase\n",
    "            \n",
    "        # Convert string representation of list to actual list\n",
    "        # tokens = ast.literal_eval(tokens)\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        tokens = [token.lower() for token in tokens]\n",
    "        \n",
    "        # Remove punctuation\n",
    "        tokens = [token.translate(str.maketrans('', '', string.punctuation)) for token in tokens]\n",
    "        \n",
    "        # Remove stopwords\n",
    "        tokens = [token for token in tokens if token not in manual_stopwords]\n",
    "        \n",
    "        return tokens\n",
    "    \n",
    "    return basic_preprocess_tokens(tokens)\n",
    "\n",
    "\n",
    "def model_inference(tokens): \n",
    "    indices = [vocabulary.get(token, vocabulary[\"<unknown>\"]) for token in tokens]  # Use 0 for unknown words\n",
    "    padded_indices = indices[:SEQ_LEN] + [0] * max(0, SEQ_LEN - len(indices))  # Pad with zeros\n",
    "    print(padded_indices)\n",
    "    input_tensor = torch.tensor(padded_indices).unsqueeze(0)  # Add batch dimension\n",
    "    print(input_tensor)\n",
    "    # print(input_tensor.shape)\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        label = torch.argmax(output, 1)\n",
    "        label_text = label_encoder.inverse_transform(label)\n",
    "        \n",
    "        # Normalize the output\n",
    "        min_val = torch.min(output)\n",
    "        max_val = torch.max(output)\n",
    "        normalized_output = (output - min_val) / (max_val - min_val)\n",
    "        \n",
    "    return (label, label_text, normalized_output)\n",
    "\n",
    "# Write down all the stopwords and punctuation marks for removal \n",
    "manual_stopwords = {\n",
    "'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', \n",
    "'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', \n",
    "'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', \n",
    "'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', \n",
    "'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \n",
    "'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', \n",
    "'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', \n",
    "'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', \n",
    "'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', \n",
    "'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', \n",
    "'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', \n",
    "'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now'\n",
    "}\n",
    "\n",
    "# Punctuation marks to remove\n",
    "# Test the inference function\n",
    "text = '''\n",
    "The product quality ain't up to the mark\n",
    "'''\n",
    "tokens = clean_text(text)\n",
    "label, label_text, output = model_inference(tokens)\n",
    "print(label)\n",
    "print(label_text)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/saggysimmba/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>tokens</th>\n",
       "      <th>cleaned_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>challenge_robot</td>\n",
       "      <td>['are', 'you', 'virtual', 'assistant']</td>\n",
       "      <td>['virtual', 'assistant']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>track</td>\n",
       "      <td>['no', 'email', 'received']</td>\n",
       "      <td>['email', 'received']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>goodbye</td>\n",
       "      <td>['appreciate', 'that']</td>\n",
       "      <td>['appreciate']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>track</td>\n",
       "      <td>['find', 'my', 'delivery', 'status']</td>\n",
       "      <td>['find', 'delivery', 'status']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>challenge_robot</td>\n",
       "      <td>['are', 'you', 'software']</td>\n",
       "      <td>['software']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13397</th>\n",
       "      <td>discount</td>\n",
       "      <td>['low', 'price', 'discount']</td>\n",
       "      <td>['low', 'price', 'discount']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13398</th>\n",
       "      <td>greeting</td>\n",
       "      <td>['hello', 'there']</td>\n",
       "      <td>['hello']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13399</th>\n",
       "      <td>track</td>\n",
       "      <td>['find', 'my', 'order', 'tracking', 'number']</td>\n",
       "      <td>['find', 'order', 'tracking', 'number']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13400</th>\n",
       "      <td>goodbye</td>\n",
       "      <td>['thank', 'you', 'for', 'your', 'help']</td>\n",
       "      <td>['thank', 'help']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13401</th>\n",
       "      <td>support</td>\n",
       "      <td>['charged', 'me', 'rs', 'more', 'than', 'the',...</td>\n",
       "      <td>['charged', 'rs', 'printed', 'mrp', 'product',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13402 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                intent                                             tokens  \\\n",
       "0      challenge_robot             ['are', 'you', 'virtual', 'assistant']   \n",
       "1                track                        ['no', 'email', 'received']   \n",
       "2              goodbye                             ['appreciate', 'that']   \n",
       "3                track               ['find', 'my', 'delivery', 'status']   \n",
       "4      challenge_robot                         ['are', 'you', 'software']   \n",
       "...                ...                                                ...   \n",
       "13397         discount                       ['low', 'price', 'discount']   \n",
       "13398         greeting                                 ['hello', 'there']   \n",
       "13399            track      ['find', 'my', 'order', 'tracking', 'number']   \n",
       "13400          goodbye            ['thank', 'you', 'for', 'your', 'help']   \n",
       "13401          support  ['charged', 'me', 'rs', 'more', 'than', 'the',...   \n",
       "\n",
       "                                          cleaned_tokens  \n",
       "0                               ['virtual', 'assistant']  \n",
       "1                                  ['email', 'received']  \n",
       "2                                         ['appreciate']  \n",
       "3                         ['find', 'delivery', 'status']  \n",
       "4                                           ['software']  \n",
       "...                                                  ...  \n",
       "13397                       ['low', 'price', 'discount']  \n",
       "13398                                          ['hello']  \n",
       "13399            ['find', 'order', 'tracking', 'number']  \n",
       "13400                                  ['thank', 'help']  \n",
       "13401  ['charged', 'rs', 'printed', 'mrp', 'product',...  \n",
       "\n",
       "[13402 rows x 3 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df = pd.read_csv(\"../data/processed/train_intents.csv\")\n",
    "shuffled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"><br>                        I talked to the Amazon \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    representative\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">HUMAN</span>\n",
       "</mark>\n",
       " earlier in the day but no one responded. The \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    operator\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">HUMAN</span>\n",
       "</mark>\n",
       " isn't \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    human\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">HUMAN</span>\n",
       "</mark>\n",
       " I guess. <br>                        The \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    chat\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">HUMAN</span>\n",
       "</mark>\n",
       " ended soon and the \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    support\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">HUMAN</span>\n",
       "</mark>\n",
       " was just awful. I love California. And I love people. <br>                        <br>                  </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('representative', 48, 62, 'HUMAN'), ('operator', 108, 116, 'HUMAN'), ('human', 123, 128, 'HUMAN'), ('chat', 167, 171, 'HUMAN'), ('support', 191, 198, 'HUMAN')]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Is it a \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    bot\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ROBOT_AI</span>\n",
       "</mark>\n",
       " ? I thought I have been talking to a fellow human being. The \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    AI\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ROBOT_AI</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    system\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ROBOT_AI</span>\n",
       "</mark>\n",
       " is so freaking good!!!</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bot', 8, 11, 'ROBOT_AI'), ('AI', 73, 75, 'ROBOT_AI'), ('system', 76, 82, 'ROBOT_AI')]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I don't know why my \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    delivery\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PACKAGE</span>\n",
       "</mark>\n",
       " hasn't arrived yet. \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    It\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PACKAGE</span>\n",
       "</mark>\n",
       " was supposed to arrive 3 days back. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "## NER.py\n",
    "# Data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "# NER\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import random\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from pathlib import Path\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"ticks\", color_codes=True)\n",
    "import collections\n",
    "import yaml\n",
    "import pickle\n",
    "import streamlit as st\n",
    "# import imgkit\n",
    "\n",
    "# Read in the training data \n",
    "train_data = pd.read_pickle(\"../objects/train.pkl\")\n",
    "\n",
    "# Wrapper to load in the results \n",
    "HTML_WRAPPER = \"\"\"<div style=\"overflow-x: auto; border: 1px solid #e6e9ef; border-radius: 0.25rem; padding: 1rem; margin-bottom: 2.5rem\">{}</div>\"\"\"\n",
    "\n",
    "# Test out the NER\n",
    "test_text_human = '''\n",
    "                        I talked to the Amazon representative earlier in the day but no one responded. The operator isn't human I guess. \n",
    "                        The chat ended soon and the support was just awful. I love California. And I love people. \n",
    "                        \n",
    "                  '''\n",
    "\n",
    "test_text_robot = \"Is it a bot ? I thought I have been talking to a fellow human being. The AI system is so freaking good!!!\" \n",
    "\n",
    "test_text_package = \"I don't know why my delivery hasn't arrived yet. It was supposed to arrive 3 days back. \"\n",
    "\n",
    "def extract_human(user_input, visualize=False): \n",
    "    \"\"\"\n",
    "        Takes as input user input, and outputs all the entities extracted. Also made a toggler for visualizing with displacy.''' \n",
    "    \"\"\"\n",
    "    \n",
    "    # Load in the trained model\n",
    "    human_nlp = spacy.load(\"../models/human_nlp\")\n",
    "    doc = human_nlp(user_input)\n",
    "    \n",
    "    extracted_entities = []\n",
    "    \n",
    "    # Extract the intents from the user input\n",
    "    for ent in doc.ents: \n",
    "        extracted_entities.append((ent.text, ent.start_char, ent.end_char, ent.label_))\n",
    "        \n",
    "    # If I want to visualize \n",
    "    if visualize:\n",
    "        # Visualizing with displacy how the document had its entity tagged \n",
    "        colors = {\"HUMAN\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\"}\n",
    "        options = {\"ents\": [\"HUMAN\"], \"colors\": colors}\n",
    "        \n",
    "        # Saves to HTML string \n",
    "        html = displacy.render(doc, style=\"ent\", options=options)\n",
    "        # html = html.replace(\"\\n\\n\", \"\\n\")\n",
    "        # st.write(HTML_WRAPPER.format(html), unsafe_allow_html=True)\n",
    "        \n",
    "    return extracted_entities\n",
    "\n",
    "def extract_robot(user_input, visualize=False):\n",
    "    \"\"\"Takes as input the user input, and outputs all the entities ext\"\"\"\n",
    "    \n",
    "    # Loading it in\n",
    "    robot_nlp = spacy.load(\"../models/robot_nlp\")\n",
    "    doc = robot_nlp(user_input)\n",
    "\n",
    "    extracted_entities = []\n",
    "\n",
    "    # These are the objects you can take out\n",
    "    for ent in doc.ents:\n",
    "        extracted_entities.append((ent.text, ent.start_char, ent.end_char, ent.label_))\n",
    "\n",
    "    # If you want to visualize\n",
    "    if visualize == True:\n",
    "        # Visualizing with displaCy how the document had it's entity tagged (runs a server)\n",
    "        colors = {\"ROBOT_AI\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\"}\n",
    "        options = {\"ents\": [\"ROBOT_AI\"], \"colors\": colors}\n",
    "        html = displacy.render(doc, style=\"ent\", options=options)\n",
    "        # with open(\"displacy/hardware.html\", \"a\") as out:\n",
    "        #     out.write(html + \"\\n\")\n",
    "        # Double newlines seem to mess with the rendering\n",
    "        # html = html.replace(\"\\n\\n\", \"\\n\")\n",
    "        # st.write(HTML_WRAPPER.format(html), unsafe_allow_html=True)\n",
    "\n",
    "    return extracted_entities\n",
    "\n",
    "def extract_package(user_input, visualize=False):\n",
    "    \"\"\"Takes as input the user input, and outputs all the entities ext\"\"\"\n",
    "    \n",
    "    # Loading it in\n",
    "    package_nlp = spacy.load(\"../models/package_nlp\")\n",
    "    doc = package_nlp(user_input)\n",
    "\n",
    "    extracted_entities = []\n",
    "\n",
    "    # These are the objects you can take out\n",
    "    for ent in doc.ents:\n",
    "        extracted_entities.append((ent.text, ent.start_char, ent.end_char, ent.label_))\n",
    "\n",
    "    # If you want to visualize\n",
    "    if visualize == True:\n",
    "        # Visualizing with displaCy how the document had it's entity tagged (runs a server)\n",
    "        colors = {\"PACKAGE\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\"}\n",
    "        options = {\"ents\": [\"PACKAGE\"], \"colors\": colors}\n",
    "        html = displacy.render(doc, style=\"ent\", options=options)\n",
    "        # with open(\"displacy/hardware.html\", \"a\") as out:\n",
    "        #     out.write(html + \"\\n\")\n",
    "        # Double newlines seem to mess with the rendering\n",
    "        # html = html.replace(\"\\n\\n\", \"\\n\")\n",
    "        # st.write(HTML_WRAPPER.format(html), unsafe_allow_html=True)\n",
    "\n",
    "def extract_default(user_input): \n",
    "    pass \n",
    "\n",
    "# Test out the NER\n",
    "print(extract_human(test_text_human, visualize=True))\n",
    "print()\n",
    "print(extract_robot(test_text_robot, visualize=True))\n",
    "print()\n",
    "print(extract_package(test_text_package, visualize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sequence length\n",
    "SEQ_LEN = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank Tokenizer with just the English vocab\n",
    "tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the bot \n",
    "# Import the necessary libraries\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import yaml \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy \n",
    "\n",
    "# Loading in the entities \n",
    "entity_dict = yaml.load(open(\"../objects/entities_non_span.yml\"), Loader=yaml.FullLoader)\n",
    "\n",
    "# Load in the training data \n",
    "train = pd.read_pickle(\"../objects/train.pkl\")\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "# Define stopwords \n",
    "manual_stopwords = { 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', \n",
    "    'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', \n",
    "    'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', \n",
    "    'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', \n",
    "    'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \n",
    "    'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', \n",
    "    'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', \n",
    "    'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', \n",
    "    'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', \n",
    "    'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', \n",
    "    'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', \n",
    "    'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now'}\n",
    "\n",
    "# Define intent list \n",
    "intent_lst = ['account',\n",
    " 'challenge_robot',\n",
    " 'discount',\n",
    " 'goodbye',\n",
    " 'greeting',\n",
    " 'quality',\n",
    " 'speak_representative',\n",
    " 'support',\n",
    " 'track']\n",
    "\n",
    "# Response template \n",
    "respond = lambda response: f\"Saggy AI: {response}\"\n",
    "\n",
    "# Load the human_nlp model \n",
    "human_nlp = spacy.load(\"../models/human_nlp\") # Refactor the code later to see if there is no redundancy \n",
    "\n",
    "# Load the robot_nlp model\n",
    "robot_nlp = spacy.load(\"../models/robot_nlp\")\n",
    "\n",
    "# Load the package_nlp model\n",
    "package_nlp = spacy.load(\"../models/package_nlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entity_dict[\"ROBOT_AI\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entity_dict[\"HUMAN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entity_dict[\"PACKAGE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_row(human, robot, package, normalized_output):\n",
    "    \n",
    "    \"\"\"Yahan pe specifically likho ki hrr ek ka type kya hai\"\"\"\n",
    "    row = []\n",
    "    \n",
    "    # HUMAN\n",
    "    if human is None or human == \"none\": \n",
    "        for i in range(len(entity_dict[\"HUMAN\"])):\n",
    "            row.append(0)\n",
    "            \n",
    "    else:\n",
    "        print(human)\n",
    "        for entity in entity_dict[\"HUMAN\"]:\n",
    "            if human[0][0] == entity: \n",
    "                row.append(1)\n",
    "            else: \n",
    "                row.append(0) \n",
    "                \n",
    "                \n",
    "    # ROBOT\n",
    "    if robot is None or robot == \"none\":\n",
    "        for i in range(len(entity_dict[\"ROBOT_AI\"])):\n",
    "            row.append(0)\n",
    "            \n",
    "    else:\n",
    "        print(robot)\n",
    "        for entity in entity_dict[\"ROBOT_AI\"]:\n",
    "            if robot[0][0] == entity: \n",
    "                row.append(1)\n",
    "            else: \n",
    "                row.append(0)\n",
    "                \n",
    "    # PACKAGE\n",
    "    if package is None or package == \"none\":\n",
    "        for i in range(len(entity_dict[\"PACKAGE\"])):\n",
    "            row.append(0)\n",
    "            \n",
    "    else:\n",
    "        print(package)\n",
    "        for entity in entity_dict[\"PACKAGE\"]:\n",
    "            if package[0][0] == entity: \n",
    "                row.append(1)\n",
    "            else: \n",
    "                row.append(0)\n",
    "                \n",
    "    # Prediction - inserting all the probabilities \n",
    "    print(normalized_output)\n",
    "    for val in list(normalized_output[0]):\n",
    "        row.append(val)\n",
    "        \n",
    "    # Converting to dataframe \n",
    "    print(len(row))\n",
    "    columns = entity_dict[\"HUMAN\"] + entity_dict[\"ROBOT_AI\"] + entity_dict[\"PACKAGE\"] + intent_lst\n",
    "    print(len(columns))\n",
    "    row = np.array(row).reshape(1, -1)\n",
    "    df = pd.DataFrame(columns=columns, data=row)\n",
    "    print(df.shape)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(user_input): # Abhi ke liye it seems sorted. Check on it again later \n",
    "    \"\"\"Initializes the conversation by extracting the entities and intents from the user input\"\"\"\n",
    "    \n",
    "    # Intent classification \n",
    "    intents = model_inference(user_input)\n",
    "    \n",
    "    # Extract the entities \n",
    "    human = extract_human(user_input)\n",
    "    robot = extract_robot(user_input)\n",
    "    package = extract_package(user_input)\n",
    "    \n",
    "    # Extract the intents \n",
    "    if human == []: \n",
    "        human = \"none\"\n",
    "        \n",
    "    if robot == []: \n",
    "        robot = \"none\"\n",
    "        \n",
    "    if package == []:\n",
    "        package = \"none\"\n",
    "    \n",
    "    return (intents, human, robot, package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def talk(prompt):\n",
    "    \"\"\"Goes through the entire conversation flow and returns\n",
    "    Represents one entire flow of a conversation that takes in an Actions object to know what prompt to start with:\n",
    "    User_input: string \n",
    "    human: List of strings containing extracted entities\n",
    "    robot: List of strings containing extracted entities\n",
    "    package: List of strings containing extracted entities\n",
    "    Intents: A tuple containing the user input and labelled intent with the maximum probability\n",
    "        - User Input \n",
    "        - Predictions: Dictionary containing intents as keys and prediction probabilities (0-1) as values\n",
    "    \"\"\"\n",
    "    # user_input = st.text_input(prompt)\n",
    "    \n",
    "    # Intents \n",
    "    intents, human, robot, package = initialize(prompt)\n",
    "    \n",
    "    # Clean the user input\n",
    "    _, _, normalized_output = intents\n",
    "    \n",
    "    # Initializing \n",
    "    column_vals = entity_dict[\"HUMAN\"] + entity_dict[\"ROBOT_AI\"] + entity_dict[\"PACKAGE\"] + intent_lst\n",
    "    history_df = pd.DataFrame(columns=column_vals, data=np.zeros((1, len(column_vals))))\n",
    "    print(history_df.shape)\n",
    "    \n",
    "    # Convert to dialogue entry history, and update the history data_frame\n",
    "    new_row = to_row(human, robot, package, normalized_output)\n",
    "    print(new_row.shape)\n",
    "    history_df = pd.concat([history_df, new_row], axis = 0, ignore_index=True)\n",
    "    \n",
    "    return (prompt, human, robot, package, intents, history_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   column1 column2  column3\n",
      "0        1   value     3.14\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the data for the single row\n",
    "data = {\n",
    "    'column1': [1],\n",
    "    'column2': ['value'],\n",
    "    'column3': [3.14]\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('column1', 1), ('column2', 'value'), ('column3', 3.14)]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [*zip(list(df.columns), list(df.values[0]))]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listener(max_intent, entity, reaction):\n",
    "    \"\"\"Takes in dialogue state and maps that to a response\"\"\"\n",
    "    \n",
    "    # Nested function for follow up \n",
    "    def follow_up(prompt=\"Could you please rephrase?\"):\n",
    "        \"\"\"Business logic for follow up\"\"\"\n",
    "        \n",
    "        # Boolean to know if conversation has ended \n",
    "        end = None \n",
    "        \n",
    "        # st.text(\"Did that solve your problem?\")\n",
    "        print(\"Did that solve your problem?\\n\")\n",
    "        \n",
    "        yes = input(\"Press 'Y/y' for Yes: \").strip().lower() == 'y'\n",
    "       \n",
    "        if yes: \n",
    "            print(\"Did that solve your problem?\")\n",
    "            end = True \n",
    "            \n",
    "        else:\n",
    "            # Continues to the next conversation \n",
    "            end = False \n",
    "            \n",
    "        return end\n",
    "    \n",
    "    # Initializing actions object \n",
    "    a = Actions(reaction)\n",
    "    \n",
    "    # Initializing end \n",
    "    end = None \n",
    "    \n",
    "    if max_intent == \"account\":\n",
    "        print(a.account_issues())\n",
    "        end = follow_up()\n",
    "                \n",
    "    elif max_intent == \"challenge_robot\":\n",
    "        print(a.customer_support())\n",
    "        end = follow_up()\n",
    "        \n",
    "    elif max_intent == \"discount\":\n",
    "        print(a.discounts_promotions())\n",
    "        end = follow_up()\n",
    "        \n",
    "    elif max_intent == \"goodbye\":\n",
    "        print(a.utter_goodbye())\n",
    "        end = follow_up()\n",
    "        \n",
    "    elif max_intent == \"greeting\": \n",
    "        print(a.utter_greet())\n",
    "        end = follow_up()\n",
    "        \n",
    "    elif max_intent == \"quality\":\n",
    "        print(a.faulty_product())\n",
    "        end = follow_up()\n",
    "        \n",
    "    elif max_intent == \"speak_representative\":\n",
    "        print(a.link_to_human())\n",
    "        end = follow_up()\n",
    "        \n",
    "    elif max_intent == \"support\":\n",
    "        print(a.customer_support())\n",
    "        end = follow_up()\n",
    "        \n",
    "    elif max_intent == \"track\":\n",
    "        print(a.check_order_status())\n",
    "        end = follow_up()\n",
    "        \n",
    "    else:\n",
    "        print(a.fallback())\n",
    "        \n",
    "    return end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backend_dash(): \n",
    "    # Visualize the data yourself \n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_mapper(history_df): \n",
    "    \"\"\" Simply maps a history state to: \n",
    "    A max intent: string \n",
    "    Entities: List of extracted entities\n",
    "\n",
    "    \"\"\"   \n",
    "    prediction_probs = history_df.iloc[-1:, len(set(shuffled_df[\"intent\"])): ]\n",
    "    predictions = [*zip(list(prediction_probs.columns), list(prediction_probs.values[0]))]\n",
    "    \n",
    "    # Finding the entities \n",
    "    entities = history_df.iloc[-1:, : -len(set(shuffled_df[\"intent\"]))]\n",
    "    mask = [True if i==1.0 else False for i in entities.values[0]]\n",
    "    extracted_entities = [b for a, b in zip(mask, list(entities.columns)) if a]\n",
    "    \n",
    "    # Finding the max intent\n",
    "    predictions.sort(key=lambda x: x[1])\n",
    "    max_intent = predictions[-1][0]\n",
    "    \n",
    "    return (max_intent, extracted_entities) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I am the Saggy AI robot. How may I assist you today?\n"
     ]
    }
   ],
   "source": [
    "a = Actions(\"Hello! I am the Saggy AI robot. How may I assist you today?\")\n",
    "print(a.startup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4704, 4563, 4704, 4704, 4704, 4704, 4704, 3042, 3042, 1998, 1260, 4704, 4704, 4704, 4704, 4704, 489, 4563, 4704, 2774, 4704, 492, 3042, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([[4704, 4563, 4704, 4704, 4704, 4704, 4704, 3042, 3042, 1998, 1260, 4704,\n",
      "         4704, 4704, 4704, 4704,  489, 4563, 4704, 2774, 4704,  492, 3042,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]])\n",
      "(1, 33)\n",
      "tensor([[0.7440, 0.1315, 0.8975, 0.4674, 0.1953, 1.0000, 0.0000, 0.8597, 0.5897]])\n",
      "33\n",
      "33\n",
      "(1, 33)\n",
      "(1, 33)\n",
      "   human  operator  chat  person  representative  support  bot  real   ai  \\\n",
      "0    0.0       0.0   0.0     0.0             0.0      0.0  0.0   0.0  0.0   \n",
      "1    0.0       0.0   0.0     0.0             0.0      0.0  0.0   0.0  0.0   \n",
      "\n",
      "   computer  ...  delivery   account  challenge_robot  discount   goodbye  \\\n",
      "0       0.0  ...       0.0  0.000000         0.000000  0.000000  0.000000   \n",
      "1       0.0  ...       0.0  0.744017         0.131546  0.897452  0.467389   \n",
      "\n",
      "   greeting  quality  speak_representative   support     track  \n",
      "0  0.000000      0.0                   0.0  0.000000  0.000000  \n",
      "1  0.195299      1.0                   0.0  0.859738  0.589667  \n",
      "\n",
      "[2 rows x 33 columns]\n",
      "quality\n",
      "[]\n",
      "I'm truly sorry to hear that you've received a faulty product. To make things right, you can follow our return instructions by visiting the link below:  https://www.amazon.com/gp/help/customer/display.html?nodeId=GP7Z9RS868ZP5J9F\n",
      "Did that solve your problem?\n",
      "\n",
      "Intents: (tensor([5]), array(['quality'], dtype='<U20'), tensor([[0.7440, 0.1315, 0.8975, 0.4674, 0.1953, 1.0000, 0.0000, 0.8597, 0.5897]]))\n",
      "User Input: Tell Saggybot something\n",
      "History:    human  operator  chat  person  representative  support  bot  real   ai  \\\n",
      "0    0.0       0.0   0.0     0.0             0.0      0.0  0.0   0.0  0.0   \n",
      "1    0.0       0.0   0.0     0.0             0.0      0.0  0.0   0.0  0.0   \n",
      "\n",
      "   computer  ...  delivery   account  challenge_robot  discount   goodbye  \\\n",
      "0       0.0  ...       0.0  0.000000         0.000000  0.000000  0.000000   \n",
      "1       0.0  ...       0.0  0.744017         0.131546  0.897452  0.467389   \n",
      "\n",
      "   greeting  quality  speak_representative   support     track  \n",
      "0  0.000000      0.0                   0.0  0.000000  0.000000  \n",
      "1  0.195299      1.0                   0.0  0.859738  0.589667  \n",
      "\n",
      "[2 rows x 33 columns]\n",
      "End: False\n",
      "[4704, 4704, 4563, 4704, 4704, 4563, 4704, 2774, 4563, 4704, 3223, 4704, 489, 4563, 4704, 4704, 4704, 4704, 4704, 2785, 4704, 989, 4704, 4704, 2774, 4563, 4704, 2785, 4704, 4704, 4704, 4704]\n",
      "tensor([[4704, 4704, 4563, 4704, 4704, 4563, 4704, 2774, 4563, 4704, 3223, 4704,\n",
      "          489, 4563, 4704, 4704, 4704, 4704, 4704, 2785, 4704,  989, 4704, 4704,\n",
      "         2774, 4563, 4704, 2785, 4704, 4704, 4704, 4704]])\n",
      "(1, 33)\n",
      "tensor([[0.7122, 0.1164, 0.8617, 0.4863, 0.1984, 1.0000, 0.0000, 0.8718, 0.5669]])\n",
      "33\n",
      "33\n",
      "(1, 33)\n",
      "(1, 33)\n",
      "   human  operator  chat  person  representative  support  bot  real   ai  \\\n",
      "0    0.0       0.0   0.0     0.0             0.0      0.0  0.0   0.0  0.0   \n",
      "1    0.0       0.0   0.0     0.0             0.0      0.0  0.0   0.0  0.0   \n",
      "\n",
      "   computer  ...  delivery   account  challenge_robot  discount   goodbye  \\\n",
      "0       0.0  ...       0.0  0.000000         0.000000  0.000000  0.000000   \n",
      "1       0.0  ...       0.0  0.712176         0.116392  0.861699  0.486295   \n",
      "\n",
      "   greeting  quality  speak_representative   support     track  \n",
      "0  0.000000      0.0                   0.0  0.000000  0.000000  \n",
      "1  0.198434      1.0                   0.0  0.871807  0.566927  \n",
      "\n",
      "[2 rows x 33 columns]\n",
      "quality\n",
      "[]\n",
      "I am sorry to hear that you received a faulty product. For details on how to return the product, please refer to the following link: https://www.amazon.com/gp/help/customer/display.html?nodeId=GP7Z9RS868ZP5J9F\n",
      "Did that solve your problem?\n",
      "\n",
      "Intents: (tensor([5]), array(['quality'], dtype='<U20'), tensor([[0.7122, 0.1164, 0.8617, 0.4863, 0.1984, 1.0000, 0.0000, 0.8718, 0.5669]]))\n",
      "User Input: Please help me out for the faulty product\n",
      "History:    human  operator  chat  person  representative  support  bot  real   ai  \\\n",
      "0    0.0       0.0   0.0     0.0             0.0      0.0  0.0   0.0  0.0   \n",
      "1    0.0       0.0   0.0     0.0             0.0      0.0  0.0   0.0  0.0   \n",
      "\n",
      "   computer  ...  delivery   account  challenge_robot  discount   goodbye  \\\n",
      "0       0.0  ...       0.0  0.000000         0.000000  0.000000  0.000000   \n",
      "1       0.0  ...       0.0  0.712176         0.116392  0.861699  0.486295   \n",
      "\n",
      "   greeting  quality  speak_representative   support     track  \n",
      "0  0.000000      0.0                   0.0  0.000000  0.000000  \n",
      "1  0.198434      1.0                   0.0  0.871807  0.566927  \n",
      "\n",
      "[2 rows x 33 columns]\n",
      "End: False\n",
      "[4704, 4704, 4704, 2774, 4704, 492, 517, 4704, 4704, 4704, 4704, 489, 4704, 745, 4704, 492, 4563, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([[4704, 4704, 4704, 2774, 4704,  492,  517, 4704, 4704, 4704, 4704,  489,\n",
      "         4704,  745, 4704,  492, 4563,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]])\n",
      "(1, 33)\n",
      "tensor([[0.7634, 0.0932, 0.8810, 0.4212, 0.1535, 1.0000, 0.0000, 0.8715, 0.6044]])\n",
      "33\n",
      "33\n",
      "(1, 33)\n",
      "(1, 33)\n",
      "   human  operator  chat  person  representative  support  bot  real   ai  \\\n",
      "0    0.0       0.0   0.0     0.0             0.0      0.0  0.0   0.0  0.0   \n",
      "1    0.0       0.0   0.0     0.0             0.0      0.0  0.0   0.0  0.0   \n",
      "\n",
      "   computer  ...  delivery   account  challenge_robot  discount   goodbye  \\\n",
      "0       0.0  ...       0.0  0.000000         0.000000  0.000000  0.000000   \n",
      "1       0.0  ...       0.0  0.763444         0.093191  0.881041  0.421201   \n",
      "\n",
      "   greeting  quality  speak_representative   support     track  \n",
      "0  0.000000      0.0                   0.0  0.000000  0.000000  \n",
      "1  0.153486      1.0                   0.0  0.871549  0.604375  \n",
      "\n",
      "[2 rows x 33 columns]\n",
      "quality\n",
      "[]\n",
      "I'm truly sorry to hear that you've received a faulty product. To make things right, you can follow our return instructions by visiting the link below:  https://www.amazon.com/gp/help/customer/display.html?nodeId=GP7Z9RS868ZP5J9F\n",
      "Did that solve your problem?\n",
      "\n",
      "Intents: (tensor([5]), array(['quality'], dtype='<U20'), tensor([[0.7634, 0.0932, 0.8810, 0.4212, 0.1535, 1.0000, 0.0000, 0.8715, 0.6044]]))\n",
      "User Input: I think I am done\n",
      "History:    human  operator  chat  person  representative  support  bot  real   ai  \\\n",
      "0    0.0       0.0   0.0     0.0             0.0      0.0  0.0   0.0  0.0   \n",
      "1    0.0       0.0   0.0     0.0             0.0      0.0  0.0   0.0  0.0   \n",
      "\n",
      "   computer  ...  delivery   account  challenge_robot  discount   goodbye  \\\n",
      "0       0.0  ...       0.0  0.000000         0.000000  0.000000  0.000000   \n",
      "1       0.0  ...       0.0  0.763444         0.093191  0.881041  0.421201   \n",
      "\n",
      "   greeting  quality  speak_representative   support     track  \n",
      "0  0.000000      0.0                   0.0  0.000000  0.000000  \n",
      "1  0.153486      1.0                   0.0  0.871549  0.604375  \n",
      "\n",
      "[2 rows x 33 columns]\n",
      "End: False\n",
      "[4704, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([[4704,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]])\n",
      "(1, 33)\n",
      "tensor([[0.1156, 1.0000, 0.5703, 0.2293, 0.9699, 0.1355, 0.0000, 0.5695, 0.2601]])\n",
      "33\n",
      "33\n",
      "(1, 33)\n",
      "(1, 33)\n",
      "   human  operator  chat  person  representative  support  bot  real   ai  \\\n",
      "0    0.0       0.0   0.0     0.0             0.0      0.0  0.0   0.0  0.0   \n",
      "1    0.0       0.0   0.0     0.0             0.0      0.0  0.0   0.0  0.0   \n",
      "\n",
      "   computer  ...  delivery   account  challenge_robot  discount   goodbye  \\\n",
      "0       0.0  ...       0.0  0.000000              0.0  0.000000  0.000000   \n",
      "1       0.0  ...       0.0  0.115582              1.0  0.570317  0.229342   \n",
      "\n",
      "   greeting   quality  speak_representative   support     track  \n",
      "0   0.00000  0.000000                   0.0  0.000000  0.000000  \n",
      "1   0.96987  0.135539                   0.0  0.569526  0.260067  \n",
      "\n",
      "[2 rows x 33 columns]\n",
      "challenge_robot\n",
      "[]\n",
      "I apologize for the poor customer support you've received. I urge you to email your experience at: experience@amazon.com \n",
      "Did that solve your problem?\n",
      "\n",
      "Did that solve your problem?\n",
      "Intents: (tensor([1]), array(['challenge_robot'], dtype='<U20'), tensor([[0.1156, 1.0000, 0.5703, 0.2293, 0.9699, 0.1355, 0.0000, 0.5695, 0.2601]]))\n",
      "User Input: Y\n",
      "History:    human  operator  chat  person  representative  support  bot  real   ai  \\\n",
      "0    0.0       0.0   0.0     0.0             0.0      0.0  0.0   0.0  0.0   \n",
      "1    0.0       0.0   0.0     0.0             0.0      0.0  0.0   0.0  0.0   \n",
      "\n",
      "   computer  ...  delivery   account  challenge_robot  discount   goodbye  \\\n",
      "0       0.0  ...       0.0  0.000000              0.0  0.000000  0.000000   \n",
      "1       0.0  ...       0.0  0.115582              1.0  0.570317  0.229342   \n",
      "\n",
      "   greeting   quality  speak_representative   support     track  \n",
      "0   0.00000  0.000000                   0.0  0.000000  0.000000  \n",
      "1   0.96987  0.135539                   0.0  0.569526  0.260067  \n",
      "\n",
      "[2 rows x 33 columns]\n",
      "End: True\n",
      "Exiting the conversation.\n"
     ]
    }
   ],
   "source": [
    "def conversation(starter):\n",
    "    \"\"\" \n",
    "    Represents one entire flow of a conversation that takes in the Actions \n",
    "    object to know what prompt to start with \n",
    "    \"\"\"\n",
    "    \n",
    "    user_input, human, robot, package, intents, history_df = talk(prompt=starter.startup)\n",
    "    print(history_df.head())\n",
    "    \n",
    "    # Storing current state \n",
    "    max_intent, extracted_entities = action_mapper(history_df)\n",
    "    print(max_intent)\n",
    "    print(extracted_entities)\n",
    "    \n",
    "    if extracted_entities != []: \n",
    "        if len(extracted_entities) == 1: \n",
    "            entity = extracted_entities[0]\n",
    "            print(f\"Found 1 entity: {entity}\")\n",
    "        elif len(extracted_entities) == 2: \n",
    "            entity = extracted_entities[ :2]\n",
    "            print(f\"Found more than 1 entity: {entity}\")\n",
    "        else: \n",
    "            entity = extracted_entities[ :3]\n",
    "            print(f\"Found more than 1 entity: {entity}\")\n",
    "            \n",
    "    else:\n",
    "        entity = None\n",
    "            \n",
    "    end = listener(max_intent, entity, starter)\n",
    "    \n",
    "    return (intents, user_input, history_df, end) \n",
    "    \n",
    "def main(phrase=\"Tell Saggybot something\"):\n",
    "    while True:\n",
    "        # Instantiate the class object for this conversation \n",
    "        a = Actions(phrase)\n",
    "        \n",
    "        intents, user_input, history_df, end = conversation(a)\n",
    "        print(f\"Intents: {intents}\")\n",
    "        print(f\"User Input: {user_input}\")\n",
    "        print(f\"History: {history_df}\")\n",
    "        print(f\"End: {end}\")\n",
    "        \n",
    "        if end:\n",
    "            print(\"Exiting the conversation.\")\n",
    "            break\n",
    "        \n",
    "        phrase = input(\"Could you please rephrase? \")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amazon_support",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

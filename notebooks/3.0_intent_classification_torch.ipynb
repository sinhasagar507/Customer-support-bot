{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intent Classification With PyTorch\n",
    "Previously, my focus in the notebooks was on obtaining labeled data for my chatbot. However, this current notebook is centered around utilizing PyTorch for the classification of intents within fresh, unseen user-generated data. The model has transitioned to a supervised learning approach, leveraging the labels derived from the unsupervised learning conducted in the preceding notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RASA Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rasa trains this intent classification step with SVM and GridsearchCV because they can try different configurations ([source](https://medium.com/bhavaniravi/intent-classification-demystifying-rasanlu-part-4-685fc02f5c1d)). When deploying preprocessing pipeline should remain same between train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.17.3)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /Users/saggysimmba/Library/Python/3.12/lib/python/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /Users/saggysimmba/Library/Python/3.12/lib/python/site-packages (from wandb) (4.2.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wandb) (4.25.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /Users/saggysimmba/Library/Python/3.12/lib/python/site-packages (from wandb) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wandb) (2.7.1)\n",
      "Requirement already satisfied: setproctitle in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wandb) (69.5.1)\n",
      "Requirement already satisfied: six>=1.4.0 in /Users/saggysimmba/Library/Python/3.12/lib/python/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "import wandb\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "\n",
    "# Create a blank Tokenizer with just the English vocab\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas: 2.2.2\n",
      "Numpy: 1.26.4\n",
      "Sklearn: 1.4.2\n",
      "Training data:                                              support  \\\n",
      "0  [very, poor, feedback, very, disappointing, se...   \n",
      "1  [already, done, i, am, frankly, fed, up, with,...   \n",
      "2  [very, poor, feedback, very, disappointing, se...   \n",
      "3  [can, see, you, have, replied, to, others, who...   \n",
      "4  [my, issue, is, not, resolved, really, should,...   \n",
      "\n",
      "                                         account           greeting  \\\n",
      "0                      [email, account, details]               [hi]   \n",
      "1                      [email, account, details]            [hello]   \n",
      "2                      [email, account, details]     [what, is, up]   \n",
      "3  [the, credit, card, information, is, correct]    [good, morning]   \n",
      "4                        [account, email, email]  [good, afternoon]   \n",
      "\n",
      "     goodbye                      speak_representative  \\\n",
      "0  [goodbye]                     [talk, human, please]   \n",
      "1      [bye]              [let, me, talk, to, support]   \n",
      "2    [thank]            [can, i, speak, agent, person]   \n",
      "3   [thanks]               [connect, me, to, a, human]   \n",
      "4     [done]  [need, to, speak, to, a, representative]   \n",
      "\n",
      "             challenge_robot                                 quality  \\\n",
      "0         [are, you, a, bot]               [product, quality, issue]   \n",
      "1           [are, you, real]  [quality, concerns, product, received]   \n",
      "2         [are, you, an, AI]      [received, item, quality, problem]   \n",
      "3    [are, you, a, computer]    [need, help, with, product, quality]   \n",
      "4  [who, am, I, talking, to]   [product, not, as, expected, quality]   \n",
      "\n",
      "                        track               discount  \n",
      "0          [track, my, order]      [offer, discount]  \n",
      "1    [where, is, my, package]       [sale, discount]  \n",
      "2      [locate, my, shipment]      [price, discount]  \n",
      "3        [find, my, delivery]  [promotion, discount]  \n",
      "4  [check, my, order, status]       [deal, discount]  \n"
     ]
    }
   ],
   "source": [
    "# Standard \n",
    "import collections\n",
    "import yaml\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Data science\n",
    "import pandas as pd\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "import numpy as np\n",
    "print(f\"Numpy: {np.__version__}\")\n",
    "\n",
    "# Machine Learning\n",
    "import sklearn\n",
    "print(f\"Sklearn: {sklearn.__version__}\")\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Visualization \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "# Preprocessing and Torch\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from torchtext.data.utils import get_tokenizer\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "# from torchtext.vocab import build_vocab_from_iterator\n",
    "# from torchtext.data import get_tokenizer\n",
    "\n",
    "# Reading in training data\n",
    "train = pd.read_pickle('../objects/train.pkl')\n",
    "print(f'Training data: {train.head()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msinhasagar507\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10d30ca70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration for training\n",
    "# Change all of the following configurations as per the specifications in the original repo \n",
    "# Set a seed value \n",
    "seed_value = 12321 \n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set `pytorch` pseudo-random generator at a fixed value\n",
    "torch.manual_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.melt(train)\n",
    "train.columns = [\"intent\", \"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>discount</td>\n",
       "      <td>[sale, discount]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>discount</td>\n",
       "      <td>[special, offer, discount]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>account</td>\n",
       "      <td>[delayed, orders, in, the, last, weeks, also, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>challenge_robot</td>\n",
       "      <td>[is, this, an, automated, assistant]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>discount</td>\n",
       "      <td>[as, i, purchased, a, product, from, amazon, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>account</td>\n",
       "      <td>[customer, service, tell, me, i, need, to, use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>speak_representative</td>\n",
       "      <td>[can, i, get, a, live, representative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>speak_representative</td>\n",
       "      <td>[can, you, put, me, through, to, a, representa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>track</td>\n",
       "      <td>[track, my, order, status]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>speak_representative</td>\n",
       "      <td>[i, need, to, talk, to, support]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    intent                                             tokens\n",
       "0                 discount                                   [sale, discount]\n",
       "1                 discount                         [special, offer, discount]\n",
       "2                  account  [delayed, orders, in, the, last, weeks, also, ...\n",
       "3          challenge_robot               [is, this, an, automated, assistant]\n",
       "4                 discount  [as, i, purchased, a, product, from, amazon, o...\n",
       "...                    ...                                                ...\n",
       "8995               account  [customer, service, tell, me, i, need, to, use...\n",
       "8996  speak_representative             [can, i, get, a, live, representative]\n",
       "8997  speak_representative  [can, you, put, me, through, to, a, representa...\n",
       "8998                 track                         [track, my, order, status]\n",
       "8999  speak_representative                   [i, need, to, talk, to, support]\n",
       "\n",
       "[9000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df = train.sample(frac=1).reset_index(drop=True)\n",
    "shuffled_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [very, poor, feedback, very, disappointing, se...\n",
       "1       [already, done, i, am, frankly, fed, up, with,...\n",
       "2       [very, poor, feedback, very, disappointing, se...\n",
       "3       [can, see, you, have, replied, to, others, who...\n",
       "4       [my, issue, is, not, resolved, really, should,...\n",
       "                              ...                        \n",
       "8995    [prime, member, bought, prime, products, deliv...\n",
       "8996    [m, not, interested, in, email, replies, do, l...\n",
       "8997                             [really, disappointment]\n",
       "8998                           [mrp, rs, selling, at, rs]\n",
       "8999    [bought, a, lenovo, z, delivered, on, th, nove...\n",
       "Name: tokens, Length: 9000, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['very', 'poor', 'feedback', 'very', 'disappointing', 'services']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"tokens\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>tokens</th>\n",
       "      <th>cleaned_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>discount</td>\n",
       "      <td>[sale, discount]</td>\n",
       "      <td>[sale discount]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>discount</td>\n",
       "      <td>[special, offer, discount]</td>\n",
       "      <td>[special offer discount]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>account</td>\n",
       "      <td>[delayed, orders, in, the, last, weeks, also, ...</td>\n",
       "      <td>[delayed, orders, last, weeks, also, pkg, deli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>challenge_robot</td>\n",
       "      <td>[is, this, an, automated, assistant]</td>\n",
       "      <td>[automated, assistant]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>discount</td>\n",
       "      <td>[as, i, purchased, a, product, from, amazon, o...</td>\n",
       "      <td>[purchased, product, amazon, th, oct, purchasi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            intent                                             tokens  \\\n",
       "0         discount                                   [sale, discount]   \n",
       "1         discount                         [special, offer, discount]   \n",
       "2          account  [delayed, orders, in, the, last, weeks, also, ...   \n",
       "3  challenge_robot               [is, this, an, automated, assistant]   \n",
       "4         discount  [as, i, purchased, a, product, from, amazon, o...   \n",
       "\n",
       "                                      cleaned_tokens  \n",
       "0                                    [sale discount]  \n",
       "1                           [special offer discount]  \n",
       "2  [delayed, orders, last, weeks, also, pkg, deli...  \n",
       "3                             [automated, assistant]  \n",
       "4  [purchased, product, amazon, th, oct, purchasi...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of common stopwords\n",
    "manual_stopwords = {\n",
    "    'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', \n",
    "    'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', \n",
    "    'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', \n",
    "    'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', \n",
    "    'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \n",
    "    'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', \n",
    "    'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', \n",
    "    'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', \n",
    "    'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', \n",
    "    'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', \n",
    "    'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', \n",
    "    'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def basic_preprocess_tokens(tokens):\n",
    "    \n",
    "    # Convert string representation of list to actual list\n",
    "    # tokens = ast.literal_eval(tokens)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove punctuation\n",
    "    tokens = [token.translate(str.maketrans('', '', string.punctuation)) for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in manual_stopwords]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Apply basic preprocessing to the tokens column\n",
    "shuffled_df['cleaned_tokens'] = shuffled_df['tokens'].apply(basic_preprocess_tokens)\n",
    "\n",
    "shuffled_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['customer',\n",
       " 'care',\n",
       " 'amazon',\n",
       " 'india',\n",
       " 'unprofessional',\n",
       " 'use',\n",
       " 'return',\n",
       " 'pick',\n",
       " 'may',\n",
       " 'problem',\n",
       " 'blue',\n",
       " 'dart',\n",
       " 'nobody',\n",
       " 'interested',\n",
       " 'go',\n",
       " 'thru',\n",
       " 'fb',\n",
       " 'page',\n",
       " 'huge',\n",
       " 'complain',\n",
       " 'careful',\n",
       " 'deal',\n",
       " 'amazon',\n",
       " 'expecting',\n",
       " 'mnc',\n",
       " 'sorry',\n",
       " 'state',\n",
       " 'pl',\n",
       " 'go',\n",
       " 'indepth']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df['cleaned_tokens'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_lens = [len(tokens) for tokens in shuffled_df['cleaned_tokens']]\n",
    "sns.histplot(seq_lens, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df.to_csv(\"../data/processed/train_intents.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intent            object\n",
      "tokens            object\n",
      "cleaned_tokens    object\n",
      "dtype: object\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Print the data types of the columns\n",
    "print(shuffled_df.dtypes)\n",
    "\n",
    "# Check the data types of each row in the \"tokens\" column and if its not a list, highlight the the error \n",
    "# Don't print it, log it \n",
    "print(\" \")\n",
    "for index, row in shuffled_df.iterrows():\n",
    "    if not isinstance(row[\"tokens\"], list):\n",
    "        print(f\"Error: {row['tokens']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [token_lst for token_lst in shuffled_df['cleaned_tokens']]\n",
    "X = [*X]\n",
    "y = [*shuffled_df['intent'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/saggysimmba/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/saggysimmba/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torchtext Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torchtext tokenizer \n",
    "- Add description later "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan of Action\n",
    "- Prepare the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Applications/saggydev/projects_learning/amazon_support/notebooks'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Steps taken\n",
    "    -   the words would involve creating a vocabulary dictionary to map words to indices \n",
    "    -   For each sequence, the words are converted into their corresponding indices based on the word dictionary \n",
    "    - When feeding sentences into the model, ensure a consistent sequence length is crucial \n",
    "    - To achieve this, sequences are padded with zeros until they reach the length of the longest sequence \n",
    "    - This padding ensures uniformity, and shorter maximum lengths are typically preferred for ease of training, as longer sequences can pose challenges \n",
    "    - This padding ensures uniformity, and shorter maximum lengths are typically preferred for ease of training, as longer sequences can pose challenges \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Use glove word embeddings \n",
    "embeddings_index = {}\n",
    "f = open(\"../models/glove.twitter.27B/glove.twitter.27B.200d.txt\", \"r\", encoding=\"utf-8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now build a vocabulary: This is something I hadve just added \n",
    "from collections import Counter\n",
    "word_counts = Counter(token for sentence in X for token in sentence)\n",
    "vocabulary = {word: i+1 for i, (word, _) in enumerate(word_counts.items())}  # Reserve 0 for padding \n",
    "vocabulary[\"<UNK>\"] = len(vocabulary) + 1  # Reserve for unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding matrix\n",
    "embedding_dim = 200\n",
    "vocab_size = len(vocabulary) + 1  # +1 for unknown token \n",
    "\n",
    "# Option for <UNK> embedding: Average of all embeddings\n",
    "#unk_embedding = np.mean(list(embeddings_index.values()), axis=0)\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in vocabulary.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encocde sentences as sequences of integers: This is something I have just added\n",
    "def encode_sequences(tokenized_sentences, vocab):\n",
    "    sequences = []\n",
    "    for sentence in tokenized_sentences:\n",
    "        sequence = [vocab.get(word, 0) for word in sentence]  # 0 for unknown words\n",
    "        sequences.append(sequence)\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = encode_sequences(X, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Label encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split dataset into stratified train and test sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.2, shuffle=True, random_state=seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Convert the target variable to a tensor\n",
    "X_train_tensors = [torch.tensor(sequence, dtype=torch.long) for sequence in X_train]\n",
    "X_val_tensors = [torch.tensor(sequence, dtype=torch.long) for sequence in X_val]\n",
    "\n",
    "# Pad the sequences\n",
    "X_train_tensor = pad_sequence(X_train_tensors, batch_first=True)\n",
    "X_val_tensor = pad_sequence(X_val_tensors, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7200, 30]), torch.Size([1800, 30]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape, X_val_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def re_pad_sequences(tensor, fixed_length):\n",
    "#     # Calculate the difference in length\n",
    "#     length_diff = fixed_length - tensor.shape[1]\n",
    "    \n",
    "#     if length_diff > 0:\n",
    "#         # If the tensor is shorter, pad it\n",
    "#         padding = torch.zeros((tensor.shape[0], length_diff), dtype=tensor.dtype)\n",
    "#         padded_tensor = torch.cat([tensor, padding], dim=1)\n",
    "#     elif length_diff < 0:\n",
    "#         # If the tensor is longer, truncate it\n",
    "#         padded_tensor = tensor[:, :fixed_length]\n",
    "#     else:\n",
    "#         # If the tensor is already at the desired length, do nothing\n",
    "#         padded_tensor = tensor\n",
    "    \n",
    "#     return padded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import LongTensor\n",
    "train_seq_lengths = LongTensor(list(map(len, X_train_tensors)))\n",
    "val_seq_lengths = LongTensor(list(map(len, X_val_tensors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort sequences by lengths in descending order (if not already sorted)\n",
    "X_train_sorted, train_lengths_sorted = X_train_tensor[train_seq_lengths.sort(descending=True)[1]], train_seq_lengths[train_seq_lengths.sort(descending=True)[1]]\n",
    "X_val_sorted, val_lengths_sorted = X_val_tensor[val_seq_lengths.sort(descending=True)[1]], val_seq_lengths[val_seq_lengths.sort(descending=True)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pack the padded sequences \n",
    "# X_train_packed = pack_padded_sequence(X_train_sorted, train_lengths_sorted, batch_first=True, enforce_sorted=False)\n",
    "# X_val_packed = pack_padded_sequence(X_val_sorted, val_lengths_sorted, batch_first=True, enforce_sorted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collate_fn(batch):\n",
    "#     sequences, labels = zip(*batch)\n",
    "#     lengths = torch.tensor([len(seq) for seq in sequences])\n",
    "#     padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "#     labels = torch.tensor(labels)\n",
    "#     return padded_sequences, labels, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test datasets\n",
    "# train_dataset = Subset(TensorDataset(X_tensor, y_tensor), train_indices)\n",
    "# test_dataset = Subset(TensorDataset(X_tensor, y_tensor), val_indices)\n",
    "\n",
    "# DataLoader for train and test datasets\n",
    "train_dataloader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(TensorDataset(X_val_tensor, y_val_tensor), batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'train' is a DataFrame containing 'Utterance' and 'Intent' columns\n",
    "\n",
    "# Tokenize the text data using PyTorch's tokenizer\n",
    "# The text already seems to be tokenized \n",
    "\n",
    "# Split the data into train and validation sets\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, \n",
    "#                                                   shuffle=True, stratify=y, random_state=seed_value)\n",
    "\n",
    "# # Label encode the target variable\n",
    "# label_encoder = LabelEncoder()\n",
    "# y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "# y_val_encoded = label_encoder.transform(y_val)\n",
    "\n",
    "\n",
    "# # Convert encoded targets to PyTorch tensors\n",
    "# y_train_encoded = torch.tensor(y_train_encoded, dtype=torch.long) \n",
    "# y_val_encoded = torch.tensor(y_val_encoded, dtype=torch.long)\n",
    "\n",
    "# print(f'\\nShape checks:\\nX_train: {len(X_train)} X_val: {len(X_val)}\\ny_train: {len(y_train_encoded)} y_val: {len(y_val_encoded)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_X_train = encode_sequences(X_train, vocabulary)\n",
    "# encoded_X_val = encode_sequences(X_val, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to a fixed length: This is something I have just added\n",
    "\n",
    "# Convert encoded sequences to PyTorch tensors\n",
    "# encoded_X_train_tensors = [torch.tensor(seq) for seq in encoded_X_train]\n",
    "# encoded_X_val_tensors = [torch.tensor(seq) for seq in encoded_X_val]\n",
    "\n",
    "# Pad sequences\n",
    "# Set batch_first=True to have the batch dimension first\n",
    "# padded_X_train = pad_sequence(encoded_X_train_tensors, batch_first=True, padding_value=0)\n",
    "# padded_X_val = pad_sequence(encoded_X_val_tensors, batch_first=True, padding_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Custom collate function to pad sequences \n",
    "# def collate_fn(batch):\n",
    "#     sequences, labels = zip(*batch)\n",
    "#     lengths = torch.tensor([len(seq) for seq in sequences])\n",
    "#     padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "#     labels = torch.tensor(labels)\n",
    "#     return padded_sequences, lengths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just an experimental check\n",
    "from torch.nn import Embedding  \n",
    "# embedding_layer = Embedding(num_embeddings=embedding_matrix_tensor.size(0), \n",
    "#                             embedding_dim=embedding_matrix_tensor.size(1), \n",
    "#                             _weight=embedding_matrix_tensor)\n",
    "\n",
    "# # Freeze the embedding layer\n",
    "# embedding_layer.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming padded_X_train and padded_X_val are NumPy arrays\n",
    "# padded_X_train_tensor = torch.LongTensor(padded_X_train)\n",
    "# padded_X_val_tensor = torch.LongTensor(padded_X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12600, 32])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padded_X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padded_X_val_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repad the data\n",
    "# Assuming you've decided on a fixed sequence length, for example, the max length found in the training set\n",
    "# fixed_seq_length = 32\n",
    "\n",
    "# Function to re-pad tensors to a fixed length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_len = padded_X_train_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-pad both the training and validation tensors\n",
    "# padded_X_train_tensor = re_pad_sequences(padded_X_train_tensor, fixed_seq_length)\n",
    "# padded_X_val_tensor = re_pad_sequences(padded_X_val_tensor, fixed_seq_length)\n",
    "\n",
    "# Now both tensors should have the same shape in terms of sequence length\n",
    "# print(padded_X_train_tensor.shape)\n",
    "# print(padded_X_val_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding layer\n",
    "embedding_matrix_tensor = torch.FloatTensor(embedding_matrix)\n",
    "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "embedding.weight = nn.Parameter(embedding_matrix_tensor)\n",
    "embedding.weight.requires_grad = False  # To not train the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msinhasagar507\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Applications/saggydev/projects_learning/amazon_support/notebooks/wandb/run-20240710_192520-ebugfgf9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sinhasagar507/intent-classification/runs/ebugfgf9' target=\"_blank\">still-plant-70</a></strong> to <a href='https://wandb.ai/sinhasagar507/intent-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sinhasagar507/intent-classification' target=\"_blank\">https://wandb.ai/sinhasagar507/intent-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sinhasagar507/intent-classification/runs/ebugfgf9' target=\"_blank\">https://wandb.ai/sinhasagar507/intent-classification/runs/ebugfgf9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/sinhasagar507/intent-classification/runs/ebugfgf9?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x316692f90>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"intent-classification\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"epochs\": 30,\n",
    "    \"batch_size\": 32, \n",
    "    \"embedding_size\": 200,\n",
    "    \"hidden_size\": 256,\n",
    "    \"output_size\": 9,\n",
    "    \"num_layers\": 3,\n",
    "   # \"dropout\": 0.1,\n",
    "    \"eval_metric\": \"accuracy\", \n",
    "    # \"weight_decay\": 1e-6,\n",
    "    \"scheduler_lambda_epoch_threshold\": 10,\n",
    "    \"scheduler_decay_rate\": -0.1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sweep config \n",
    "# sweep_config = {\n",
    "#     \"method\": \"random\",\n",
    "#     \"metric\": {\"goal\": \"maximize\", \"name\": \"val_accuracy\"}, \n",
    "#     \"parameters\": {\n",
    "#                     \"learning_rate\": {\"values\": [0.01, 0.001, 0.0001]},\n",
    "#                     \"epochs\": {\"values\": [30]},\n",
    "#                     \"batch_size\": {\"values\": [32, 64, 128]},\n",
    "#                     \"embedding_size\": {\"values\": [100]},\n",
    "#                     \"hidden_size\": {\"values\": [64, 128, 256]},\n",
    "#                     \"output_size\": {\"values\": [9]},\n",
    "#                     \"num_layers\": {\"values\": [1, 2, 3]},\n",
    "#                     \"dropout\": {\"values\": [0.1, 0.2, 0.3]}, \n",
    "#                     \"weight_decay\": {\"values\": [1e-3, 1e-4, 1e-5]},\n",
    "#                     \"scheduler_lambda_epoch_threshold\": {\"values\": [10]},\n",
    "#                     \"scheduler_decay_rate\": {\"values\": [-0.1]},\n",
    "#                 }\n",
    "# }\n",
    "\n",
    "# sweep_defaults = {\n",
    "#     \"learning_rate\": 0.001,\n",
    "#     \"epochs\": 30,\n",
    "#     \"batch_size\": 16, \n",
    "#     \"embedding_size\": 100,\n",
    "#     \"hidden_size\": 128,\n",
    "#     \"output_size\": 9,\n",
    "#     \"num_layers\": 3,\n",
    "#     \"dropout\": 0.05,\n",
    "#     \"eval_metric\": \"accuracy\", \n",
    "#     \"weight_decay\": 1e-3,\n",
    "#     \"scheduler_lambda_epoch_threshold\": 10,\n",
    "#     \"scheduler_decay_rate\": -0.1\n",
    "# }\n",
    "\n",
    "# sweep_id = wandb.sweep(sweep_config, project=\"intent-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MODEL_EVAL_METRIC:\n",
    "    accuracy = \"accuracy\"\n",
    "    f1_score = \"f1_score\"\n",
    "    \n",
    "class Config: \n",
    "    VOCAB_SIZE = 0\n",
    "    BATCH_SIZE = 32 \n",
    "    EMB_SIZE = 300 \n",
    "    OUT_SIZE = 9 # Corresponds to the number of intents\n",
    "    NUM_FOLDS = 5 \n",
    "    NUM_EPOCHS = 5\n",
    "    NUM_WORKERS = 8\n",
    "    \n",
    "    # I want to update the pretrainhttps://wandb.ai/sinhasagar507/intent-classification/sweeps/4sd3drrded embedding weights during training process \n",
    "    # I want to use a pretrained embedding\n",
    "    OPTIMIZER = \"Adam\"\n",
    "    EMB_WT_UPDATE = True\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    MODEL_EVAL_METRIC = MODEL_EVAL_METRIC.accuracy\n",
    "    FAST_DEV_RUN = False \n",
    "    PATIENCE = 6 \n",
    "    IS_BIDIRECTIONAL = True \n",
    "    \n",
    "     \n",
    "    # Model hyperparameters\n",
    "    MODEL_PARAMS = {\n",
    "        \"hidden_size\": 128,\n",
    "        \"num_layers\": 2,\n",
    "        \"drop_out\": 0.4258,\n",
    "        \"lr\": 0.000366,\n",
    "        \"weight_decay\": 0.00001\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just an experimental check\n",
    "# from torch.nn import Embedding  \n",
    "# embedding_layer = Embedding(num_embeddings=embedding_matrix_tensor.size(0), \n",
    "#                             embedding_dim=embedding_matrix_tensor.size(1), \n",
    "#                             _weight=embedding_matrix_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhance the architecture later \n",
    "class IntentClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, seq_len, embedding_matrix): \n",
    "        super().__init__()\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding_dim = wandb.config[\"embedding_size\"]\n",
    "        embedding_matrix_tensor = torch.FloatTensor(embedding_matrix)\n",
    "        self.embedding = nn.Embedding(seq_len, self.embedding_dim)\n",
    "        self.embedding.weight = nn.Parameter(embedding_matrix_tensor)\n",
    "        self.embedding.weight.requires_grad = False  # To not train the embedding layer\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.hidden_dim = wandb.config[\"hidden_size\"]\n",
    "        self.num_layers = wandb.config[\"num_layers\"]\n",
    "       # self.dropout = wandb.config[\"dropout\"]\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_dim, \n",
    "                            hidden_size=self.hidden_dim, \n",
    "                            num_layers=self.num_layers, \n",
    "                            bidirectional=True, \n",
    "                          #  dropout=self.dropout, \n",
    "                            batch_first=True)\n",
    "        \n",
    "        # The output of this operation should be \n",
    "        \n",
    "        # Dense layers \n",
    "\n",
    "        self.fc1 = nn.Linear(self.hidden_dim*2, 1024)  # 2 for bidirectional. Over here, its (128*2) = 256, 1024 is the output dimension of the first dense layer\n",
    "        self.fc2 = nn.Linear(1024, 512) \n",
    "        self.fc3 = nn.Linear(512, 256) \n",
    "        \n",
    "        # Dropout layer\n",
    "       # self.dropout = nn.Dropout(self.dropout)  \n",
    "        \n",
    "        # Output layer\n",
    "        self.output_dim = wandb.config[\"output_size\"]\n",
    "        self.out = nn.Linear(256, self.output_dim) ## Yaar idhr output hoga RNN ya LSTM ka (batch_size output_dim, no_of_classes) aayega kya? \n",
    "        # self.out_2 = nn.Linear(output_dim, 9)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        # text = [batch_size, embed_length]\n",
    "        \n",
    "        # embeddings = self.dropout(self.embedding(inputs))\n",
    "        \n",
    "        # embedded = [batch_size, sent_length, emb_dim]\n",
    "\n",
    "        # if self.embedding_matrix is not None: \n",
    "        #     assert self.embeddings.shape == (inputs.shape[0], inputs.shape[1], self.embedding_dim)\n",
    "         \n",
    "        # pack_padded_sequence before feeding to the LSTM. This is required so PyTorch knows \n",
    "        # which elements of the sequence are padded and ignores them in the computation \n",
    "        # Accomplished only after the embedding step \n",
    "        # embeds_pack = pack_padded_sequence(embeddings, inputs_lengths, batch_first=True)\n",
    "        \n",
    "        # Get the dimensions of the packed sequence \n",
    "        # dimensions = embeds_pack.data.size()\n",
    "\n",
    "        # Assert the shape of input sequence \n",
    "        # assert inputs.shape == (Config.BATCH_SIZE, 1000)\n",
    "\n",
    "        embeddings = self.embedding(inputs)\n",
    "        # print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "        _, (hidden, _) = self.lstm(embeddings)\n",
    "\n",
    "        # hidden shape: [num_layers*num_directions, batch_size, hidden_dim]\n",
    "        # print(f\"Hidden shape: {hidden.shape}\n",
    "        \n",
    "        # Ours task being a classification model, we are only interested in the final hidden state and not the LSTM output \n",
    "        # h_n and c_n = [num_directions * num_layers, batch_size, hidden_size]\n",
    "        final_hidden_forward = hidden[-2, :, :] # [batch_size, hidden_dim]\n",
    "        final_hidden_backward = hidden[-1, :, :] # [bacth_size, hidden_dim]\n",
    "\n",
    "        # print(f\"Final hidden forward shape: {final_hidden_forward.shape}\") # Iska shape is \n",
    "        # print(f\"Final hidden backward shape: {final_hidden_backward.shape}\")\n",
    "        \n",
    "        # Concat the final forward and hidden backward states \n",
    "        hidden = torch.cat((final_hidden_forward, final_hidden_backward), dim=1)\n",
    "        # print(f\"Hidden shape after concatenation: {hidden.shape}\")\n",
    "                \n",
    "        # Dense Linear Layers \n",
    "        dense_outputs_1 = self.fc1(hidden)\n",
    "        dense_outputs_1 = nn.ReLU()(dense_outputs_1)  \n",
    "        dense_outputs_2 = self.fc2(dense_outputs_1)\n",
    "     #   dense_outputs_2 = self.dropout(dense_outputs_2)\n",
    "        dense_outputs_2 = nn.ReLU()(dense_outputs_2) \n",
    "        dense_outputs_3 = self.fc3(dense_outputs_2)\n",
    "        dense_outputs_3 = nn.ReLU()(dense_outputs_3)\n",
    "     #  dense_outputs_3 = self.dropout(dense_outputs_3)\n",
    "\n",
    "        # Final output classification layer\n",
    "        # Applying the Softmax layer \n",
    "        final_output = (self.out(dense_outputs_3))\n",
    "        # print(f\"Final output shape: {final_output.shape}\")\n",
    "    \n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, seq_len):\n",
    "        self.seq_len = seq_len\n",
    "        self.embedding_dim = wandb.config[\"embedding_size\"]\n",
    "        self.embedding_matrix = embedding_matrix   \n",
    "        self.hidden_dim = wandb.config[\"hidden_size\"]\n",
    "        self.output_dim = wandb.config[\"output_size\"]\n",
    "        self.n_layers = wandb.config[\"num_layers\"]\n",
    "        self.batch_size = wandb.config[\"batch_size\"]\n",
    "        self.epochs = wandb.config[\"epochs\"]\n",
    "     #   self.dropout = wandb.config[\"dropout\"]\n",
    "        # Assuming IntentClassifier is defined elsewhere and matches these parameters\n",
    "        # print(self.seq_len, self.embedding_dim, self.hidden_dim, self.output_dim, self.embedding_matrix)\n",
    "        self.model = IntentClassifier(self.seq_len, self.embedding_matrix)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        # Assuming Config.OPTIMIZER is a valid PyTorch optimizer class\n",
    "        self.learning_rate = wandb.config[\"learning_rate\"]\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        self.scheduler_epoch_threshold = wandb.config[\"scheduler_lambda_epoch_threshold\"]\n",
    "        self.scheduler_decay_rate = wandb.config[\"scheduler_decay_rate\"]\n",
    "        self.epoch_lst = []\n",
    "\n",
    "    def train(self, train_dataloader, val_dataloader):\n",
    "        #TODO: Change the function format afterwards \n",
    "        # X_train = torch.tensor(X_train, dtype=torch.float)\n",
    "        # X_val = torch.tensor(X_val, dtype=torch.float)\n",
    "        # y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "        # y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "        # Assuming X_train, y_train, X_val, y_val are already tensors\n",
    "        # Ensure they have matching first dimensions\n",
    "        # assert X_train.shape[0] == y_train.shape[0], \"Training feature and label count mismatch\"\n",
    "        # assert X_val.shape[0] == y_val.shape[0], \"Validation feature and label count mismatch\"\n",
    "        \n",
    "       \n",
    "        train_accuracies_epoch, val_accuracies_epoch = [], []\n",
    "        self.valid_loss_min = np.Inf\n",
    "\n",
    "        # Assuming `optimizer` is already defined\n",
    "        # Define the lambda function for learning rate adjustment using W&B config\n",
    "        # lambda_lr = lambda epoch: 1 if epoch < self.scheduler_epoch_threshold else torch.exp(torch.tensor(-self.scheduler_decay_rate))\n",
    "\n",
    "        # Initialize the LambdaLR scheduler with the optimizer and lambda function\n",
    "        # scheduler = torch.optim.lr_scheduler.LambdaLR(self.optimizer, lr_lambda=lambda_lr)\n",
    "\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            train_loss, valid_loss = 0.0, 0.0\n",
    "            correct, total = 0, 0\n",
    "\n",
    "            self.model.train()\n",
    "            for data, target in train_dataloader:\n",
    "                # Log the shape of the data and target tensors\n",
    "                # assert data.shape == (self.batch_size, self.embedding_dim), f\"Data shape mismatch: {data.shape}\"\n",
    "                # assert target.shape == (self.batch_size,), f\"Target shape mismatch: {target.shape}\"\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(data)\n",
    "                loss = self.criterion(output, target)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # print(output.shape)\n",
    "                pred_labels = torch.argmax(output, 1)\n",
    "                correct += (pred_labels == target).sum().item()\n",
    "                total += target.size(0)\n",
    "                train_loss += loss.item() * data.size(0)\n",
    "\n",
    "\n",
    "            train_accuracy = 100 * correct / total\n",
    "            train_accuracies_epoch.append(train_accuracy)\n",
    "\n",
    "            # Log the training loss and accuracy\n",
    "            # wandb.log({\"Training Accuracy\": train_accuracy, \"Training Loss\": train_loss})\n",
    "\n",
    "            self.model.eval()\n",
    "            correct, total = 0, 0\n",
    "            for data, target in val_dataloader:\n",
    "                output = self.model(data)\n",
    "                loss = self.criterion(output, target)\n",
    "\n",
    "                pred_labels = torch.argmax(output, 1)\n",
    "                correct += (pred_labels == target).sum().item()\n",
    "                total += target.size(0)\n",
    "                valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "            valid_accuracy = 100 * correct / total\n",
    "            val_accuracies_epoch.append(valid_accuracy)\n",
    "\n",
    "            # Log the validation loss and accuracy\n",
    "            # print(f\"Epoch: {epoch+1}/{self.epochs}.. Training Accuracy: {train_accuracy:.3f}.. Validation Accuracy: {valid_accuracy:.3f}\")\n",
    "\n",
    "            # Log epoch-wise accuracies\n",
    "            wandb.log({\"epoch\": epoch, \"Training Accuracy\": train_accuracy, \"Validation Accuracy\": valid_accuracy, \"Training Loss\": train_loss, \"Validation Loss\": valid_loss})\n",
    "\n",
    "            if valid_loss <= self.valid_loss_min:\n",
    "                print(f\"Validation loss decreased ({self.valid_loss_min:.3f} --> {valid_loss:.3f}). Saving model...\")\n",
    "                \n",
    "                # Log the model and its parameters \n",
    "                # wandb.log_artifact(self.model)\n",
    "                state = {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"state_dict\": self.model.state_dict(),\n",
    "                    \"optimizer\": self.optimizer.state_dict(),\n",
    "                    \"loss\": valid_loss\n",
    "                }\n",
    "                torch.save(state, \"../models/intent_classification_model.pt\")\n",
    "                self.valid_loss_min = valid_loss\n",
    "\n",
    "            self.epoch_lst.append(epoch + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things I Need to Add\n",
    "- WandB table\n",
    "- Log artifact (model)\n",
    "- For now, include all the basic elements (then we can improve upon this in the future)\n",
    "- Ability to track across multiple hyperparameters\n",
    "- Set the configuration after the run is complete\n",
    "- Sweeps (...) AND Improvisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# trainer = ModelTrainer(padded_X_train.shape[1])\n",
    "# train_features, val_features = padded_X_train, padded_X_val\n",
    "# trainer.train(train_features, y_train_encoded, val_features, y_val_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset needs extensive cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 2016.308). Saving model...\n",
      "Validation loss decreased (2016.308 --> 1574.185). Saving model...\n",
      "Validation loss decreased (1574.185 --> 1405.929). Saving model...\n",
      "Validation loss decreased (1405.929 --> 1375.049). Saving model...\n",
      "Validation loss decreased (1375.049 --> 1346.075). Saving model...\n",
      "Validation loss decreased (1346.075 --> 1245.105). Saving model...\n",
      "Validation loss decreased (1245.105 --> 1213.583). Saving model...\n",
      "Validation loss decreased (1213.583 --> 1206.395). Saving model...\n",
      "Validation loss decreased (1206.395 --> 1155.383). Saving model...\n",
      "Validation loss decreased (1155.383 --> 1134.614). Saving model...\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "seq_len = 30\n",
    "trainer = ModelTrainer(seq_len)\n",
    "trainer.train(train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the Training Function\n",
    "# def train():\n",
    "#     # Initialize a new wandb run\n",
    "#     wandb.init(config=sweep_defaults)\n",
    "    \n",
    "#     # Modify the trainer initialization and training process to use config parameters\n",
    "#     trainer = ModelTrainer(padded_X_train.shape[1])\n",
    "#     train_features, val_features = padded_X_train, padded_X_val\n",
    "    \n",
    "#     # Assuming the trainer.train method is modified to accept epochs and batch_size\n",
    "#     trainer.train(train_features, y_train_encoded, val_features, y_val_encoded)\n",
    "        \n",
    "# # Step 4: Start the Sweep Agent\n",
    "# wandb.agent(sweep_id, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer, filename='../models/intent_classification_model.pt'):\n",
    "    # Note: Input model & optimizer should be pre-defined.  This routine only updates their states.\n",
    "    start_epoch = 15\n",
    "    if os.path.isfile(filename):\n",
    "        print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "        checkpoint = torch.load(filename)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        losslogger = checkpoint['loss']\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(filename, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(filename))\n",
    "\n",
    "    return model, optimizer, start_epoch, losslogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '../models/intent_classification_model.pt'\n",
      "=> loaded checkpoint '../models/intent_classification_model.pt' (epoch 13)\n"
     ]
    }
   ],
   "source": [
    "model = IntentClassifier(seq_len, embedding_matrix)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "model, optimizer, start_epoch, losslogger = load_checkpoint(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 5181.697). Saving model...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Continue training the model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model_trainer \u001b[38;5;241m=\u001b[39m ModelTrainer(seq_len)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadded_X_train_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadded_X_val_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[106], line 66\u001b[0m, in \u001b[0;36mModelTrainer.train\u001b[0;34m(self, X_train, y_train, X_val, y_val, model)\u001b[0m\n\u001b[1;32m     64\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(data)\n\u001b[1;32m     65\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(output, target)\n\u001b[0;32m---> 66\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# print(output.shape)\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Continue training the model\n",
    "model_trainer = ModelTrainer(seq_len)\n",
    "model_trainer.train(padded_X_train_tensor, y_train_encoded, padded_X_val_tensor, y_val_encoded, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 616,  410,    0,  ...,    0,    0,    0],\n",
       "        [1449,    0,    0,  ...,    0,    0,    0],\n",
       "        [ 191,  833,  122,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [1056,    0,    0,  ...,    0,    0,    0],\n",
       "        [1272,    0,    0,  ...,    0,    0,    0],\n",
       "        [ 115,    0,    0,  ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_X_train_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the data and related information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01, 'epochs': 30, 'batch_size': 64, 'embedding_size': 100, 'hidden_size': 256, 'output_size': 9, 'num_layers': 3, 'dropout': 0.3, 'eval_metric': 'accuracy', 'scheduler_lambda_epoch_threshold': 10, 'scheduler_decay_rate': -0.1}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "IntentClassifier.__init__() takes 3 positional arguments but 6 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mIntentClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membedding_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhidden_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/intent_classification_model.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mTypeError\u001b[0m: IntentClassifier.__init__() takes 3 positional arguments but 6 were given"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = IntentClassifier(seq_len, embedding_matrix)\n",
    "model.load_state_dict(torch.load(\"../models/intent_classification_model.pt\"))\n",
    "model.eval()\n",
    "\n",
    "def inference(text):\n",
    "    \"\"\"\n",
    "    Perform preprocessing and inference on the input text using the trained model.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The trained PyTorch model for intent classification.\n",
    "    - text: The input text string.\n",
    "    - vocabulary: A dictionary mapping tokens to indices.\n",
    "    - seq_len: The fixed sequence length expected by the model.\n",
    "    \n",
    "    Returns:\n",
    "    - pred_label: The predicted label index.\n",
    "    \"\"\"\n",
    "    # Preprocess the text\n",
    "    tokens = text.split()\n",
    "    indices = [vocabulary.get(token, 0) for token in tokens]  # Use 0 for unknown words\n",
    "    padded_indices = indices[:seq_len] + [0] * max(0, seq_len - len(indices))  # Pad with zeros\n",
    "    input_tensor = torch.tensor(padded_indices).unsqueeze(0)  # Add batch dimension\n",
    "    print(input_tensor.shape)\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        pred_label = output\n",
    "    \n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 61])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4125, -3.6488, -1.7868, -3.2215, -5.8661,  1.0337, -4.6215, -0.6400,\n",
       "         -0.6101]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(\"I want to book a flight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['quality'], dtype='<U20')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_label = label_encoder.inverse_transform([5])\n",
    "original_label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amazon_support",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

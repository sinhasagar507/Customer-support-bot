{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intent Classification With PyTorch\n",
    "Previously, my focus in the notebooks was on obtaining labeled data for my chatbot. However, this current notebook is centered around utilizing PyTorch for the classification of intents within fresh, unseen user-generated data. The model has transitioned to a supervised learning approach, leveraging the labels derived from the unsupervised learning conducted in the preceding notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RASA Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rasa trains this intent classification step with SVM and GridsearchCV because they can try different configurations ([source](https://medium.com/bhavaniravi/intent-classification-demystifying-rasanlu-part-4-685fc02f5c1d)). When deploying preprocessing pipeline should remain same between train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.17.3)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /Users/saggysimmba/Library/Python/3.12/lib/python/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /Users/saggysimmba/Library/Python/3.12/lib/python/site-packages (from wandb) (4.2.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wandb) (4.25.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /Users/saggysimmba/Library/Python/3.12/lib/python/site-packages (from wandb) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wandb) (2.7.1)\n",
      "Requirement already satisfied: setproctitle in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wandb) (69.5.1)\n",
      "Requirement already satisfied: six>=1.4.0 in /Users/saggysimmba/Library/Python/3.12/lib/python/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasttext-langdetect in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.0.5)\n",
      "Requirement already satisfied: fasttext>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from fasttext-langdetect) (0.9.3)\n",
      "Requirement already satisfied: requests>=2.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from fasttext-langdetect) (2.31.0)\n",
      "Requirement already satisfied: pybind11>=2.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from fasttext>=0.9.1->fasttext-langdetect) (2.13.1)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from fasttext>=0.9.1->fasttext-langdetect) (69.5.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from fasttext>=0.9.1->fasttext-langdetect) (1.26.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.22.0->fasttext-langdetect) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.22.0->fasttext-langdetect) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.22.0->fasttext-langdetect) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.22.0->fasttext-langdetect) (2024.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install fasttext-langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "import wandb\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "\n",
    "# Create a blank Tokenizer with just the English vocab\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas: 2.2.2\n",
      "Numpy: 1.26.4\n",
      "Sklearn: 1.4.2\n",
      "Training data:                                              support  \\\n",
      "0  [very, poor, feedback, very, disappointing, se...   \n",
      "1  [already, done, i, am, frankly, fed, up, with,...   \n",
      "2  [very, poor, feedback, very, disappointing, se...   \n",
      "3  [can, see, you, have, replied, to, others, who...   \n",
      "4  [my, issue, is, not, resolved, really, should,...   \n",
      "\n",
      "                                         account           greeting  \\\n",
      "0                      [email, account, details]    [good, morning]   \n",
      "1                      [email, account, details]  [good, afternoon]   \n",
      "2                      [email, account, details]    [good, evening]   \n",
      "3  [the, credit, card, information, is, correct]      [good, night]   \n",
      "4                        [account, email, email]        [good, day]   \n",
      "\n",
      "            goodbye     speak_representative            challenge_robot  \\\n",
      "0         [goodbye]    [talk, human, please]            [are, you, bot]   \n",
      "1      [thank, you]     [let, talk, support]           [are, you, real]   \n",
      "2  [thanks, a, lot]   [speak, agent, person]             [are, you, AI]   \n",
      "3            [done]         [connect, human]       [are, you, computer]   \n",
      "4        [see, you]  [speak, representative]  [who, am, I, talking, to]   \n",
      "\n",
      "                                  quality                       track  \\\n",
      "0               [product, quality, issue]          [track, my, order]   \n",
      "1  [quality, concerns, product, received]    [where, is, my, package]   \n",
      "2      [received, item, quality, problem]      [locate, my, shipment]   \n",
      "3    [need, help, with, product, quality]        [find, my, delivery]   \n",
      "4   [product, not, as, expected, quality]  [check, my, order, status]   \n",
      "\n",
      "                discount  \n",
      "0      [offer, discount]  \n",
      "1       [sale, discount]  \n",
      "2      [price, discount]  \n",
      "3  [promotion, discount]  \n",
      "4       [deal, discount]  \n"
     ]
    }
   ],
   "source": [
    "# Standard \n",
    "import collections\n",
    "import yaml\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Data science\n",
    "import pandas as pd\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "import numpy as np\n",
    "print(f\"Numpy: {np.__version__}\")\n",
    "\n",
    "# Machine Learning\n",
    "import sklearn\n",
    "print(f\"Sklearn: {sklearn.__version__}\")\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Save and load the jobs \n",
    "import joblib\n",
    "\n",
    "# Visualization \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "# Preprocessing and Torch\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "# from torchtext.data.utils import get_tokenizer\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "# from torchtext.vocab import build_vocab_from_iterator\n",
    "# from torchtext.data import get_tokenizer\n",
    "\n",
    "# Warnings \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Reading in training data\n",
    "train = pd.read_pickle('../objects/train.pkl')\n",
    "print(f'Training data: {train.head()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
      "Aborted!\n"
     ]
    }
   ],
   "source": [
    "!wandb login --relogin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for training\n",
    "# Change all of the following configurations as per the specifications in the original repo \n",
    "# Set a seed value \n",
    "seed_value = 12321 \n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set `pytorch` pseudo-random generator at a fixed value\n",
    "torch.manual_seed(seed_value)\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msinhasagar507\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Applications/saggydev/projects_learning/amazon_support/notebooks/wandb/run-20240728_143837-6c88j5dw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sinhasagar507/intent-classification/runs/6c88j5dw' target=\"_blank\">atomic-bird-87</a></strong> to <a href='https://wandb.ai/sinhasagar507/intent-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sinhasagar507/intent-classification' target=\"_blank\">https://wandb.ai/sinhasagar507/intent-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sinhasagar507/intent-classification/runs/6c88j5dw' target=\"_blank\">https://wandb.ai/sinhasagar507/intent-classification/runs/6c88j5dw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/sinhasagar507/intent-classification/runs/6c88j5dw?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1758e18b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"intent-classification\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"epochs\": 30,\n",
    "    \"batch_size\": 32, \n",
    "    \"embedding_size\": 200,\n",
    "    \"hidden_size\": 128,\n",
    "    \"output_size\": 9,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.2,\n",
    "    \"eval_metric\": \"accuracy\", \n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"scheduler_lambda_epoch_threshold\": 10,\n",
    "    \"scheduler_decay_rate\": -0.1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.melt(train)\n",
    "train.columns = [\"intent\", \"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>challenge_robot</td>\n",
       "      <td>[are, you, virtual, assistant]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>track</td>\n",
       "      <td>[no, email, received]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>goodbye</td>\n",
       "      <td>[appreciate, that]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>track</td>\n",
       "      <td>[find, my, delivery, status]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>challenge_robot</td>\n",
       "      <td>[are, you, software]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13495</th>\n",
       "      <td>discount</td>\n",
       "      <td>[low, price, discount]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13496</th>\n",
       "      <td>greeting</td>\n",
       "      <td>[hello, there]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13497</th>\n",
       "      <td>track</td>\n",
       "      <td>[find, my, order, tracking, number]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13498</th>\n",
       "      <td>goodbye</td>\n",
       "      <td>[thank, you, for, your, help]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13499</th>\n",
       "      <td>support</td>\n",
       "      <td>[charged, me, rs, more, than, the, printed, mr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                intent                                             tokens\n",
       "0      challenge_robot                     [are, you, virtual, assistant]\n",
       "1                track                              [no, email, received]\n",
       "2              goodbye                                 [appreciate, that]\n",
       "3                track                       [find, my, delivery, status]\n",
       "4      challenge_robot                               [are, you, software]\n",
       "...                ...                                                ...\n",
       "13495         discount                             [low, price, discount]\n",
       "13496         greeting                                     [hello, there]\n",
       "13497            track                [find, my, order, tracking, number]\n",
       "13498          goodbye                      [thank, you, for, your, help]\n",
       "13499          support  [charged, me, rs, more, than, the, printed, mr...\n",
       "\n",
       "[13500 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df = train.sample(frac=1).reset_index(drop=True)\n",
    "shuffled_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'account',\n",
       " 'challenge_robot',\n",
       " 'discount',\n",
       " 'goodbye',\n",
       " 'greeting',\n",
       " 'quality',\n",
       " 'speak_representative',\n",
       " 'support',\n",
       " 'track'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(shuffled_df[\"intent\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [very, poor, feedback, very, disappointing, se...\n",
       "1        [already, done, i, am, frankly, fed, up, with,...\n",
       "2        [very, poor, feedback, very, disappointing, se...\n",
       "3        [can, see, you, have, replied, to, others, who...\n",
       "4        [my, issue, is, not, resolved, really, should,...\n",
       "                               ...                        \n",
       "13495    [please, unblock, my, account, i, need, to, pu...\n",
       "13496    [i, know, that, amazon, did, not, manufacture,...\n",
       "13497    [friend, do, not, use, amazon, pay, its, not, ...\n",
       "13498                                              [india]\n",
       "13499    [can, you, see, which, type, of, service, the,...\n",
       "Name: tokens, Length: 13500, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['very', 'poor', 'feedback', 'very', 'disappointing', 'services']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"tokens\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>tokens</th>\n",
       "      <th>cleaned_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>challenge_robot</td>\n",
       "      <td>[are, you, virtual, assistant]</td>\n",
       "      <td>[virtual, assistant]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>track</td>\n",
       "      <td>[no, email, received]</td>\n",
       "      <td>[email, received]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>goodbye</td>\n",
       "      <td>[appreciate, that]</td>\n",
       "      <td>[appreciate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>track</td>\n",
       "      <td>[find, my, delivery, status]</td>\n",
       "      <td>[find, delivery, status]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>challenge_robot</td>\n",
       "      <td>[are, you, software]</td>\n",
       "      <td>[software]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            intent                          tokens            cleaned_tokens\n",
       "0  challenge_robot  [are, you, virtual, assistant]      [virtual, assistant]\n",
       "1            track           [no, email, received]         [email, received]\n",
       "2          goodbye              [appreciate, that]              [appreciate]\n",
       "3            track    [find, my, delivery, status]  [find, delivery, status]\n",
       "4  challenge_robot            [are, you, software]                [software]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of common stopwords\n",
    "manual_stopwords = {\n",
    "    'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', \n",
    "    'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', \n",
    "    'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', \n",
    "    'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', \n",
    "    'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \n",
    "    'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', \n",
    "    'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', \n",
    "    'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', \n",
    "    'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', \n",
    "    'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', \n",
    "    'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', \n",
    "    'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def basic_preprocess_tokens(tokens):\n",
    "    \n",
    "    # Convert string representation of list to actual list\n",
    "    # tokens = ast.literal_eval(tokens)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove punctuation\n",
    "    tokens = [token.translate(str.maketrans('', '', string.punctuation)) for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in manual_stopwords]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Apply basic preprocessing to the tokens column\n",
    "shuffled_df['cleaned_tokens'] = shuffled_df['tokens'].apply(basic_preprocess_tokens)\n",
    "\n",
    "shuffled_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13402, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wherever the length of the tokens is 0, we will remove those rows\n",
    "shuffled_df = shuffled_df[shuffled_df['cleaned_tokens'].apply(len) > 0]\n",
    "shuffled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intent\n",
       "challenge_robot         1500\n",
       "track                   1500\n",
       "goodbye                 1500\n",
       "speak_representative    1500\n",
       "discount                1499\n",
       "account                 1495\n",
       "support                 1494\n",
       "quality                 1489\n",
       "greeting                1425\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df[\"intent\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkcAAAGgCAYAAACg6sNQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsq0lEQVR4nO3de1TVdb7/8RfI3dtRFDaNYxmGxqSiuU3OLxwHizwTdQ7R5ZjYpKkc81J61Km0JnU0V+Jl0kwZb5laWVJNOTNazJzT1FEEJ7UJybtZchFF8cJFZP/+cO09nx0IW1C+IM/HWq4ln9t++3W798vv9/Pd28vhcDgEAAAASZK31QUAAAA0JoQjAAAAA+EIAADAQDgCAAAwEI4AAAAMhCMAAAAD4QgAAMDgY3UBTVHfvn1VXl6ujh07Wl0KAADw0IkTJ+Tn56esrKwaxxGO6qCsrEyXLl2yugwAAHAVKioq5MlnXxOO6iAkJESSlJ6ebnElAADAU4MGDfJoHHuOAAAADIQjAAAAA+EIAADAQDgCAAAwEI4AAAAMhCMAAAAD4QgAAMBAOAIAADAQjgAAAAyEIwAAAAPhCAAAwEA4AgAAMDSKcPThhx/ql7/8pXr06KH7779ff/rTn1x933//vZKTk9WnTx/dfffdWrRokS5duuQ2f/369Ro0aJB69uypxx9/XNnZ2W79nqwBAAAgNYJw9NFHH2natGkaOnSoNm/erPj4eE2aNElfffWVLl68qKeeekqS9M477+jll1/W22+/rddff901/4MPPtCrr76qZ555RmlpaerUqZOGDx+uU6dOSZJHawAAADj5WPngDodDv/vd7/TEE09o6NChkqQxY8YoKytLO3bs0A8//KDjx49r48aNatu2rSIiInTy5Em9+uqr+q//+i/5+flp2bJlSkpK0oMPPihJmjNnju655x699957Sk5O1pYtW2pdAwAAwMnSM0eHDx/WDz/8oAceeMCtfeXKlUpOTlZWVpZ+9rOfqW3btq6+/v3769y5c9q7d69OnjypI0eOKDo62tXv4+Ojvn37KjMzU5JqXQMAAMBk6Zmjw4cPS5IuXLigp556StnZ2erUqZPGjBmj2NhY5eXlyWazuc0JCQmRJOXm5srH53L5YWFhVcbk5ORIUq1r9OrVq9raBg0adMW6c3NzqzzmtVJZ6ZC3t1eDzwUAAJdZGo7OnTsnSfr1r3+tcePGafLkydqyZYuefvpprV69WqWlpWrTpo3bHH9/f0lSWVmZSkpKJKnKpTF/f3+VlZVJUq1rNDbe3l5699N9OlF04armdWwXpMfujbhOVQEA0HxYGo58fX0lSU899ZQSEhIkSbfffruys7O1evVqBQQEqLy83G2OM9AEBQUpICBAkqodExgYKEm1rnEl6enpV+yr6azStXCi6IKOF56/ro8BAACqZ+meo9DQUElSRIT7GY+uXbvq+++/l81mU0FBgVuf8+fQ0FDXpa3qxjjXrm0NAAAAk6Xh6Gc/+5latmyp3bt3u7Xv27dPnTt3lt1uV3Z2tuvymyRt375dLVu2VPfu3RUcHKwuXbooIyPD1V9RUaGsrCzZ7XZJqnUNAAAAk6XhKCAgQCNHjtTrr7+uTz75RN99953eeOMNffnllxo+fLjuuecedezYUc8++6xycnL02WefacGCBRoxYoRrn9GIESO0evVqffDBBzpw4IBeeOEFlZaW6uGHH5Ykj9YAAABwsnTPkSQ9/fTTCgwM1MKFC5Wfn6/w8HAtXrxYd911lyRpxYoVmjFjhh599FG1bdtWjz/+uJ5++mnX/EcffVRnz57VokWLdPr0ad1xxx1avXq12rdvL+ny5uva1gAAAHDycjgcDquLaGqcG7Jr2rRdH0s27rrqDdk3dWipcY9GXZd6AAC4EXj6/m3514cAAAA0JoQjAAAAA+EIAADAQDgCAAAwEI4AAAAMhCMAAAAD4QgAAMBAOAIAADAQjgAAAAyEIwAAAAPhCAAAwEA4AgAAMBCOAAAADIQjAAAAA+EIAADAQDgCAAAwEI4AAAAMhCMAAAAD4QgAAMBAOAIAADAQjgAAAAyEIwAAAAPhCAAAwEA4AgAAMBCOAAAADIQjAAAAA+EIAADAQDgCAAAwEI4AAAAMhCMAAAAD4QgAAMBAOAIAADAQjgAAAAyEIwAAAAPhCAAAwEA4AgAAMBCOAAAADIQjAAAAA+EIAADAQDgCAAAwEI4AAAAMhCMAAAAD4QgAAMBAOAIAADAQjgAAAAyEIwAAAIPl4Sg/P1/dunWr8istLU2StHfvXiUlJSkqKkqxsbFau3at2/zKykq99tpriomJUVRUlEaNGqVjx465jaltDQAAACcfqwvIycmRv7+/PvvsM3l5ebnaW7duraKiIg0fPlyxsbGaMWOGdu3apRkzZqhly5ZKTEyUJC1dulQbNmzQ3LlzZbPZNG/ePI0cOVIff/yx/Pz8PFoDAADAyfJwtG/fPt1yyy0KCQmp0vfmm2/K19dXM2fOlI+Pj8LDw3X06FGlpqYqMTFR5eXlWrVqlSZPnqyBAwdKkhYuXKiYmBht3bpV8fHx2rhxY41rAAAAmCy/rPbtt98qPDy82r6srCz169dPPj7/zHD9+/fXkSNHVFhYqJycHJ0/f17R0dGu/jZt2igyMlKZmZkerQEAAGBqFGeO2rVrp6FDh+rw4cO6+eabNWbMGA0YMEB5eXmKiIhwG+88w5Sbm6u8vDxJUlhYWJUxzr7a1ujQoUO1dQ0aNOiKNefm5lZ5TAAAcGOw9MxRRUWFDh06pDNnzmj8+PFKTU1VVFSURo8erW3btqm0tFR+fn5uc/z9/SVJZWVlKikpkaRqx5SVlUlSrWsAAACYLD1z5OPjo4yMDLVo0UIBAQGSpDvuuEP79+/XypUrFRAQoPLycrc5zkATFBTkmlNeXu76vXNMYGCgJNW6xpWkp6dfsa+ms0oAAKBps3zPUcuWLd2CjSTddtttys/Pl81mU0FBgVuf8+fQ0FDXpa3qxoSGhkpSrWsAAACYLA1H+/fvV58+fZSRkeHW/o9//ENdu3aV3W7Xzp07denSJVff9u3b1aVLFwUHB6t79+5q1aqV2/zi4mJlZ2fLbrdLUq1rAAAAmCwNR+Hh4br11ls1c+ZMZWVl6eDBg3rllVe0a9cujRkzRomJiTp37pymTZumAwcOKC0tTWvWrFFycrKky3uNkpKSlJKSovT0dOXk5GjixImy2WyKi4uTpFrXAAAAMFm658jb21vLli3T/Pnz9eyzz6q4uFiRkZFavXq16w6zFStWaPbs2UpISFDHjh01depUJSQkuNaYMGGCKioqNH36dJWWlsput2vlypXy9fWVJAUHB9e6BgAAgJOXw+FwWF1EU+PckF3Tpu36WLJxl44Xnr+qOTd1aKlxj0Zdl3oAALgRePr+bfmGbAAAgMaEcAQAAGAgHAEAABgIRwAAAAbCEQAAgIFwBAAAYCAcAQAAGAhHAAAABsIRAACAgXAEAABgIBwBAAAYCEcAAAAGwhEAAICBcAQAAGAgHAEAABgIRwAAAAbCEQAAgIFwBAAAYCAcAQAAGAhHAAAABsIRAACAgXAEAABgIBwBAAAYCEcAAAAGwhEAAICBcAQAAGAgHAEAABgIRwAAAAbCEQAAgIFwBAAAYCAcAQAAGAhHAAAABsIRAACAgXAEAABgIBwBAAAYCEcAAAAGwhEAAICBcAQAAGAgHAEAABgIRwAAAAbCEQAAgIFwBAAAYCAcAQAAGAhHAAAABsIRAACAgXAEAABgIBwBAAAYGlU4Onz4sHr37q20tDRX2969e5WUlKSoqCjFxsZq7dq1bnMqKyv12muvKSYmRlFRURo1apSOHTvmNqa2NQAAAJwaTTi6ePGiJk+erAsXLrjaioqKNHz4cHXu3FmbNm3S2LFjlZKSok2bNrnGLF26VBs2bNCsWbP0zjvvqLKyUiNHjlR5ebnHawAAADj5WF2A0+LFi9WqVSu3to0bN8rX11czZ86Uj4+PwsPDdfToUaWmpioxMVHl5eVatWqVJk+erIEDB0qSFi5cqJiYGG3dulXx8fG1rgEAAGBqFGeOMjMz9e6772ru3Llu7VlZWerXr598fP6Z4fr3768jR46osLBQOTk5On/+vKKjo139bdq0UWRkpDIzMz1aAwAAwGT5maPi4mJNnTpV06dPV1hYmFtfXl6eIiIi3NpCQkIkSbm5ucrLy5OkKvNCQkJcfbWt0aFDh2rrGjRo0BVrzs3NrfKYAADgxmD5maOXX35ZvXv31gMPPFClr7S0VH5+fm5t/v7+kqSysjKVlJRIUrVjysrKPFoDAADAZOmZow8//FBZWVn6+OOPq+0PCAhwbax2cgaaoKAgBQQESJLKy8tdv3eOCQwM9GiNK0lPT79iX01nlQAAQNNmaTjatGmTTp486dpM7fSb3/xGf/zjH2Wz2VRQUODW5/w5NDRUFRUVrrbOnTu7jenWrZsk1boGAACAydJwlJKSotLSUre2uLg4TZgwQQ8++KA++ugjvfPOO7p06ZJatGghSdq+fbu6dOmi4OBgtW7dWq1atVJGRoYrHBUXFys7O1tJSUmSJLvdXuMaAAAAJkv3HIWGhurmm292+yVJwcHBCg0NVWJios6dO6dp06bpwIEDSktL05o1a5ScnCzp8l6jpKQkpaSkKD09XTk5OZo4caJsNpvi4uIkqdY1AAAATJbfrVaT4OBgrVixQrNnz1ZCQoI6duyoqVOnKiEhwTVmwoQJqqio0PTp01VaWiq73a6VK1fK19fX4zUAAACcvBwOh8PqIpoa54bsmjZt18eSjbt0vPD8Vc25qUNLjXs06rrUAwDAjcDT92/Lb+UHAABoTAhHAAAABsIRAACAgXAEAABgIBwBAAAYCEcAAAAGwhEAAICBcAQAAGAgHAEAABgIRwAAAAbCEQAAgIFwBAAAYCAcAQAAGAhHAAAABsIRAACAgXAEAABgIBwBAAAYCEcAAAAGwhEAAICBcAQAAGAgHAEAABgIRwAAAIbrEo7y8vKux7IAAADXXZ3C0e233649e/ZU25eVlaV/+7d/q1dRAAAAVvHxdOCqVat04cIFSZLD4dB7772nzz//vMq4r776Sn5+fteuQgAAgAbkcTgqKyvTkiVLJEleXl567733qozx9vZW69atNWbMmGtXIQAAQAPyOByNGTPGFXq6d++ujRs3qmfPntetMAAAACt4HI5MOTk517oOAACARqFO4UiSvvzyS/31r39VSUmJKisr3fq8vLw0Z86cehcHAADQ0OoUjlatWqVXX31V/v7+at++vby8vNz6f/wzAABAU1GncLRu3To98MADmj17NnemAQCAG0qdPueosLBQDz/8MMEIAADccOoUjiIjI7V///5rXQsAAIDl6nRZ7YUXXtCzzz6roKAg9erVS4GBgVXG3HTTTfUuDgAAoKHVKRwNGTJElZWVeuGFF664+Xrv3r31KgwAAMAKdQpHs2bN4o40AABwQ6pTOHrooYeudR0AAACNQp3CUWZmZq1j7HZ7XZYGAACwVJ3C0bBhw+Tl5SWHw+Fq+/FlNvYcAQCApqhO4Wjt2rVV2i5cuKCsrCx99NFHWrx4cb0LAwAAsEKdwlG/fv2qbR84cKCCgoL0xhtvaPny5fUqDAAAwAp1+hDImvTt21c7duy41ssCAAA0iGsejv7yl7+oZcuW13pZAACABlGny2pPPPFElbbKykrl5eXphx9+0KhRo+pdGAAAgBXqFI7Mu9ScvL29FRERoeTkZCUmJta7MAAAACvUKRy99dZb17oOAACARqFO4cjp888/144dO1RcXKz27dvrzjvvVExMzLWqDQAAoMHVaUN2eXm5Ro4cqdGjR2v16tX6y1/+ot///vcaPXq0hg8frvLyco/XOnnypKZMmaL+/furd+/eGj16tA4ePOjq37t3r5KSkhQVFaXY2Ngqn7FUWVmp1157TTExMYqKitKoUaN07NgxtzG1rQEAAOBUp3C0ePFi7dy5U6+++qr27NmjL774Qrt379Yrr7yiXbt26Y033vB4rbFjx+ro0aNKTU3V+++/r4CAAD355JMqKSlRUVGRhg8frs6dO2vTpk0aO3asUlJStGnTJtf8pUuXasOGDZo1a5beeecdVVZWauTIka6A5skaAAAATnW6rPbJJ59o3LhxevDBB/+5kI+P/uM//kMnT57U22+/rWeeeabWdc6cOaOf/OQnSk5OVkREhCTp6aef1r//+79r//792rZtm3x9fTVz5kz5+PgoPDzcFaQSExNVXl6uVatWafLkyRo4cKAkaeHChYqJidHWrVsVHx+vjRs31rgGAACAqU7h6NSpU4qMjKy2LzIyUvn5+R6t07ZtW82fP99t3TVr1shms6lr165avHix+vXrJx+ff5bZv39/LV++XIWFhTp+/LjOnz+v6OhoV3+bNm0UGRmpzMxMxcfHKysrq8Y1OnToUG1tgwYNumLdubm5CgsL8+jPCAAAmpY6XVbr3Lmzdu7cWW1fZmZmnYLDiy++qOjoaG3evFmzZ89WUFCQ8vLyZLPZ3MaFhIRIuhxQ8vLyJKnK44WEhLj6alsDAADAVKczR//5n/+puXPnKiAgQPfff786dOigwsJCffLJJ/r973+vcePGXfWav/rVr/TYY49p/fr1Gjt2rDZs2KDS0lL5+fm5jfP395cklZWVqaSkRJKqHXPmzBlJqnWNK0lPT79iX01nlQAAQNNWp3A0ZMgQZWdnKyUlxe2ymMPhUEJCgkaPHn3Va3bt2lWSNHv2bO3evVvr1q1TQEBAlTvfnIEmKChIAQEBki7fPef8vXNMYGCgJNW6BgAAgKlO4ai8vFyzZ8/WiBEjtGPHDp05c0ZeXl665557FB4e7vE6p06d0rZt23Tfffe59gR5e3ura9euKigokM1mU0FBgdsc58+hoaGqqKhwtXXu3NltTLdu3SSp1jUAAABMV7Xn6Ntvv1ViYqJWr14tSQoPD9eQIUP0+OOP63e/+50mTZqkw4cPe7xeYWGhJk2apG3btrnaLl68qOzsbIWHh8tut2vnzp26dOmSq3/79u3q0qWLgoOD1b17d7Vq1UoZGRmu/uLiYmVnZ8tut0tSrWsAAACYPA5H33//vZ544gkVFhaqS5cubn2+vr6aOnWqTp8+rccff9zju9UiIiI0YMAA/fa3v1VmZqb27dun5557TsXFxXryySeVmJioc+fOadq0aTpw4IDS0tK0Zs0aJScnS7q81ygpKUkpKSlKT09XTk6OJk6cKJvNpri4OEmqdQ0AAACTx+EoNTVV//Iv/6IPPvhAgwcPdusLDAzUk08+qffff1/+/v5avny5xwUsWLBA0dHRmjhxoh555BGdPn1a69ev10033aTg4GCtWLFChw8fVkJCgpYsWaKpU6cqISHBNX/ChAl6+OGHNX36dA0ZMkQtWrTQypUr5evrK0kerQEAAODk5XA4HJ4MvPfeezV69Gg98sgjNY5bu3at1q9fry1btlyTAhsj591qNd3RVh9LNu7S8cLzVzXnpg4tNe7RqOtSDwAANwJP3789PnNUUFCgW265pdZxERERrs8YAgAAaGo8Dkft27evctdXdYqKitS2bdt6FYWr1yrIV5WVHp0ErFZ95gIAcCPx+FZ+u92utLQ03X///TWO+/DDD6/41SK4fgL9fOTt7aV3P92nE0UXrmpux3ZBeuzeiOtUGQAATYvH4WjYsGEaMmSI5s6dq4kTJ7o+ZdqpvLxcixYt0ueff67U1NRrXig8c6LowlXvVwIAAP/kcTjq0aOHnn/+ec2ZM0cfffSRoqOj1alTJ126dEnHjx9XRkaGioqK9MwzzygmJuZ61gwAAHDdXNUnZA8dOlTdu3fXypUrlZ6e7voajpYtW+ruu+/WiBEj1KtXr+tSKAAAQEO46q8PufPOO3XnnXdKuvz1Hz4+PmrTps01LwwAAMAKdfpuNaf27dtfqzoAAAAahav6bjUAAIAbHeEIAADAQDgCAAAwEI4AAAAMhCMAAAAD4QgAAMBAOAIAADAQjgAAAAyEIwAAAAPhCAAAwEA4AgAAMBCOAAAADIQjAAAAA+EIAADAQDgCAAAwEI4AAAAMhCMAAAAD4QgAAMBAOAIAADAQjgAAAAyEIwAAAAPhCAAAwEA4AgAAMBCOAAAADIQjAAAAA+EIAADAQDgCAAAwEI4AAAAMhCMAAAAD4QgAAMBAOAIAADAQjgAAAAyEIwAAAAPhCAAAwEA4AgAAMBCOAAAADIQjAAAAA+EIAADAYHk4On36tF566SUNGDBAffr00ZAhQ5SVleXq37Ztmx566CH16tVLgwcP1ubNm93ml5WVacaMGYqOjlbv3r313//93zp16pTbmNrWAAAAcLI8HE2aNElfffWVFixYoE2bNun222/XU089pUOHDungwYNKTk5WTEyM0tLS9Mgjj2jq1Knatm2ba/7LL7+sL774QosXL9abb76pQ4cOacKECa5+T9YAAABw8rHywY8ePaovv/xSGzZs0J133ilJevHFF/W3v/1NH3/8sU6ePKlu3bpp4sSJkqTw8HBlZ2drxYoVio6OVn5+vj788EMtW7ZMffv2lSQtWLBAgwcP1ldffaXevXvrzTffrHENAAAAk6Vnjtq1a6fU1FT16NHD1ebl5SUvLy8VFxcrKyurSoDp37+/du7cKYfDoZ07d7ranLp06aLQ0FBlZmZKUq1rAAAAmCw9c9SmTRv9/Oc/d2vbsmWLjh49qhdeeEEffPCBbDabW39ISIhKSkpUVFSk/Px8tWvXTv7+/lXG5OXlSZLy8vJqXKN9+/bV1jZo0KAr1p2bm6uwsDCP/5wAAKDpsHzPkenvf/+7nn/+ecXFxWngwIEqLS2Vn5+f2xjnz+Xl5SopKanSL0n+/v4qKyuTpFrXAAAAMFl65sj02WefafLkyerTp49SUlIkXQ45Pw4wzp8DAwMVEBBQbcApKytTYGCgR2tcSXp6+hX7ajqrBAAAmrZGceZo3bp1Gj9+vH7xi19o2bJlrstkYWFhKigocBtbUFCgoKAgtW7dWjabTadPn64SfgoKChQaGurRGgAAACbLw9GGDRs0a9YsDR06VAsWLHC7BNa3b1/t2LHDbfz27dvVp08feXt7684771RlZaVrY7YkHT58WPn5+bLb7R6tAQAAYLI0HRw+fFhz5szRvffeq+TkZBUWFurEiRM6ceKEzp49q2HDhmnPnj1KSUnRwYMHtWrVKv35z3/WyJEjJUmhoaG6//77NX36dGVkZGjPnj2aNGmS+vXrp6ioKEmqdQ0AAACTpXuOtmzZoosXL+rTTz/Vp59+6taXkJCguXPnaunSpZo3b57efPNNderUSfPmzXO7NX/WrFmaM2eOxo0bJ0kaMGCApk+f7uq/7bbbal0DAADAycvBh/1cNeeG7Jo2bdfHko27dLzw/FXN6dW1gx6L61anuTd1aKlxj0Zd1RwAAJoaT9+/2XQDAABgIBwBAAAYCEcAAAAGwhEAAICBcAQAAGAgHAEAABgIRwAAAAbCEQAAgIFwBAAAYCAcAQAAGAhHAAAABsIRAACAgXAEAABgIBwBAAAYCEcAAAAGwhEAAICBcAQAAGAgHAEAABgIRwAAAAbCEQAAgIFwBAAAYCAcAQAAGAhHAAAABsIRAACAgXAEAABgIBwBAAAYCEcAAAAGwhEAAICBcAQAAGAgHAEAABgIRwAAAAbCEQAAgIFwBAAAYCAcAQAAGAhHAAAABsIRAACAgXAEAABgIBwBAAAYCEcAAAAGwhEAAICBcAQAAGAgHAEAABgIRwAAAAbCEQAAgIFwBAAAYCAcAQAAGAhHAAAAhkYVjpYvX65hw4a5te3du1dJSUmKiopSbGys1q5d69ZfWVmp1157TTExMYqKitKoUaN07Nixq1oDAADAqdGEo/Xr12vRokVubUVFRRo+fLg6d+6sTZs2aezYsUpJSdGmTZtcY5YuXaoNGzZo1qxZeuedd1RZWamRI0eqvLzc4zUAAACcfKwuID8/X7/5zW+UkZGhW265xa1v48aN8vX11cyZM+Xj46Pw8HAdPXpUqampSkxMVHl5uVatWqXJkydr4MCBkqSFCxcqJiZGW7duVXx8fK1rAAAAmCwPR9988418fX31hz/8Qa+//rp++OEHV19WVpb69esnH59/ltm/f38tX75chYWFOn78uM6fP6/o6GhXf5s2bRQZGanMzEzFx8fXukaHDh2qrWvQoEFXrDk3N1dhYWH1+WMDAIBGyvJwFBsbq9jY2Gr78vLyFBER4dYWEhIi6XJAycvLk6QqQSUkJMTVV9saVwpHAACgebI8HNWktLRUfn5+bm3+/v6SpLKyMpWUlEhStWPOnDnj0RpXkp6efsW+ms4qAQCApq3RbMiuTkBAgGtjtZMz0AQFBSkgIECSqh0TGBjo0RoAAACmRh2ObDabCgoK3NqcP4eGhroup1U3JjQ01KM1AAAATI06HNntdu3cuVOXLl1ytW3fvl1dunRRcHCwunfvrlatWikjI8PVX1xcrOzsbNntdo/WAAAAMDXqcJSYmKhz585p2rRpOnDggNLS0rRmzRolJydLurzXKCkpSSkpKUpPT1dOTo4mTpwom82muLg4j9YAAAAwNeoN2cHBwVqxYoVmz56thIQEdezYUVOnTlVCQoJrzIQJE1RRUaHp06ertLRUdrtdK1eulK+vr8drAAAAODWqcDR37twqbT179tS77757xTktWrTQlClTNGXKlCuOqW0NAAAAp0Z9WQ0AAKChEY4AAAAMhCMAAAAD4QgAAMBAOAIAADAQjgAAAAyEIwAAAAPhCAAAwEA4AgAAMBCOAAAADIQjAAAAA+EIAADAQDgCAAAwEI4AAAAMhCMAAAAD4QgAAMBAOAIAADAQjqBWQb6qrHTUa436zgcAoLHwsboAWC/Qz0fe3l5699N9OlF04arnd2wXpMfujbgOlQEA0PAIR3A5UXRBxwvPW10GAACW4rIaAACAgXAEAABgIBwBAAAYCEcAAAAGwhEAAICBcAQAAGAgHAEAABgIR0ATUp9PIudTzAHAM3wIJNDAKisd8vb2qtPcun6SOZ9iDgCeIxyh3pzfzVbXN/z6zG2K6hpwIjq3U1z/m+v0Seb8HQGA5whHqLf6fDdbUz2jUd+wUJeA0/FfAuv8eM3x7wgA6opwhGumqX03mxWXt5xnf6zS1P6OAMAKhCM0W1Zc3qrP2R8AQMMgHKFZI+AAAH6MW/nRpHF7+vXn3MxdV/wdAWhqOHMES9X3LqqmuvenKWEzN4DmhnAES9XnjZe9Pw2LzdwAmgvCERoFAg4AoLFgzxGA64b9SgCaIs4cAbhu2K8EoCkiHAG47tivBKAp4bIaAACAgXAEAABgIBwBAAAYCEcAGiXudANgFTZkA2iUuNMNgFWaTTiqrKzUkiVL9N577+ns2bOy2+166aWX9NOf/tTq0gDUoC53utX3a2nqMxdA09dswtHSpUu1YcMGzZ07VzabTfPmzdPIkSP18ccfy8/Pz+ryAFxD9TnrdHNYG93//7rU+bGtCmVNcS7QWDWLcFReXq5Vq1Zp8uTJGjhwoCRp4cKFiomJ0datWxUfH29tgQCui7p+LU19v+/PilDWFGsmlKGxahbhKCcnR+fPn1d0dLSrrU2bNoqMjFRmZibhCEAV9fm+P6tCWVOsuamFMjQPXg6H44a/pWPr1q0aP368du/erYCAAFf7M888o9LSUi1fvrzKnEGDBl1xve+//14tWrRQWFjYdan3fMlFXbrKO218fbwV6O/T4HOtfGzmMpe5zXtuSVmFKq/yLayFt7cC/Fpc1RzcOHJzc9WiRQt9/fXXNY5rFmeOSkpKJKnK3iJ/f3+dOXPmqtfz8vKSj8+VD11ubq4k1Tk8tQz0rdM8K+de7fwfH6Om+Ge+nnNreg411pobeq4n/84aW80NPfdqXosaS81XI9C//m9h9X29vtHdaMfHx8fHo33GzSIcOc8WlZeXu505KisrU2BgYLVz0tPT6/x4zrNO9VnjRscxqhnHp3Yco9pxjGrHMapZcz0+zeJDIJ2Jt6CgwK29oKBAoaGhVpQEAAAaqWYRjrp3765WrVopIyPD1VZcXKzs7GzZ7XYLKwMAAI1Ns7is5ufnp6SkJKWkpKh9+/b6yU9+onnz5slmsykuLs7q8gAAQCPSLMKRJE2YMEEVFRWaPn26SktLZbfbtXLlSvn61m8TMgAAuLE0m3DUokULTZkyRVOmTLG6FAAA0Ig1iz1HAAAAnmoWHwIJAADgKc4cAQAAGAhHAAAABsIRAACAgXAEAABgIBwBAAAYCEfXUGVlpV577TXFxMQoKipKo0aN0rFjx6wuq1HJz89Xt27dqvxKS0uzurRGYfny5Ro2bJhb2969e5WUlKSoqCjFxsZq7dq1FlVnveqOz/Tp06s8n2JjYy2q0BqnT5/WSy+9pAEDBqhPnz4aMmSIsrKyXP3btm3TQw89pF69emnw4MHavHmzhdU2vNqOz/Dhw6s8h378PLvRnTx5UlOmTFH//v3Vu3dvjR49WgcPHnT1N7vXIQeumcWLFzvuuusux1//+lfH3r17HSNGjHDExcU5ysrKrC6t0fif//kfR48ePRz5+fmOgoIC16+SkhKrS7PcunXrHN27d3ckJSW52k6dOuW46667HM8//7zjwIEDjvfff9/Ro0cPx/vvv29hpdao7vg4HA7Hww8/7FiwYIHb8+nkyZMWVWmN4cOHO+Lj4x2ZmZmOQ4cOOWbMmOHo2bOn4+DBg44DBw44evTo4ViwYIHjwIEDjhUrVjgiIyMd//d//2d12Q2mpuPjcDgc0dHRjg0bNrg9h4qKiqwtuoE99thjjkceecSxe/dux4EDBxzjx4933H333Y4LFy40y9chwtE1UlZW5ujdu7dj/fr1rrYzZ844evbs6fj4448trKxxSU1NdTzwwANWl9Go5OXlOZKTkx1RUVGOwYMHu735L1u2zHH33Xc7Ll686GqbP3++Iy4uzopSLVHT8amsrHRERUU5tm7damGF1jpy5IgjIiLCkZWV5WqrrKx03HPPPY5FixY5XnzxRcfDDz/sNmfSpEmOESNGNHSplqjt+BQWFjoiIiIc33zzjYVVWuv06dOOSZMmOb799ltX2969ex0RERGO3bt3N8vXIS6rXSM5OTk6f/68oqOjXW1t2rRRZGSkMjMzLayscfn2228VHh5udRmNyjfffCNfX1/94Q9/UK9evdz6srKy1K9fP/n4/PObfvr3768jR46osLCwoUu1RE3H57vvvtOFCxd06623WlSd9dq1a6fU1FT16NHD1ebl5SUvLy8VFxcrKyvL7XVJuvwc2rlzpxzN4DOAazs+3377rby8vNSlSxcLq7RW27ZtNX/+fEVEREiSTp06pTVr1shms6lr167N8nWIcHSN5OXlSZLCwsLc2kNCQlx9kPbt26dTp05p6NCh+td//VcNGTJEn3/+udVlWSo2NlaLFy/WT3/60yp9eXl5stlsbm0hISGSpNzc3Aapz2o1HZ99+/ZJkt566y3Fxsbqnnvu0cyZM3X27NmGLtMybdq00c9//nP5+fm52rZs2aKjR48qJibmis+hkpISFRUVNXS5Da6247Nv3z61bt1aM2fO1IABAzR48GAtWrRI5eXlFlZtnRdffFHR0dHavHmzZs+eraCgoGb5OkQ4ukZKSkokye0foCT5+/urrKzMipIanYqKCh06dEhnzpzR+PHjlZqaqqioKI0ePVrbtm2zurxGqbS0tNrnlCSeV7ocjry9vRUSEqJly5bpueee0xdffKGnn35alZWVVpdnib///e96/vnnFRcXp4EDB1b7HHL+3BwDwI+Pz759+1RWVqaePXtqxYoVGjNmjN577z1Nnz7d6lIt8atf/UqbNm1SfHy8xo4dq2+++aZZvg751D4EnggICJB0+cXG+Xvp8hMnMDDQqrIaFR8fH2VkZKhFixauY3THHXdo//79WrlyZZVT/7j8vPrxG5jzxSgoKMiKkhqVMWPG6PHHH1e7du0kSREREerYsaMeffRRff3111Uuw93oPvvsM02ePFl9+vRRSkqKpMtvYj9+Djl/bm6vTdUdn5kzZ+rXv/612rZtK+nyc8jX11cTJ07U1KlT1aFDBytLbnBdu3aVJM2ePVu7d+/WunXrmuXrEGeOrhHn5bSCggK39oKCAoWGhlpRUqPUsmVLt/AoSbfddpvy8/Mtqqhxs9ls1T6nJPG8kuTt7e0KRk633XabJDW7y9nr1q3T+PHj9Ytf/ELLli1z/c8+LCys2udQUFCQWrdubUWplrjS8fHx8XEFI6fm9hw6deqUNm/erIqKClebt7e3unbtqoKCgmb5OkQ4uka6d++uVq1aKSMjw9VWXFys7Oxs2e12CytrPPbv368+ffq4HSNJ+sc//uH63wrc2e127dy5U5cuXXK1bd++XV26dFFwcLCFlTUOU6dO1ZNPPunW9vXXX0tSs3pObdiwQbNmzdLQoUO1YMECt0sgffv21Y4dO9zGb9++XX369JG3d/N4C6jp+AwbNkzPP/+82/ivv/5avr6+uuWWWxq4UmsUFhZq0qRJbtsbLl68qOzsbIWHhzfL16Hm8S+jAfj5+SkpKUkpKSlKT09XTk6OJk6cKJvNpri4OKvLaxTCw8N16623aubMmcrKytLBgwf1yiuvaNeuXRozZozV5TVKiYmJOnfunKZNm6YDBw4oLS1Na9asUXJystWlNQr33Xeftm3bpiVLlui7777T//7v/+qFF15QfHx8s7kr8vDhw5ozZ47uvfdeJScnq7CwUCdOnNCJEyd09uxZDRs2THv27FFKSooOHjyoVatW6c9//rNGjhxpdekNorbjc9999+mjjz7S22+/rWPHjumPf/yjXn31VT311FNq1aqV1eU3iIiICA0YMEC//e1vlZmZqX379um5555TcXGxnnzyyWb5OuTlaA73cjaQS5cuacGCBUpLS1NpaansdrteeuklderUyerSGo3CwkLNnz9ff/vb31RcXKzIyEhNnjxZffv2tbq0RuG5557TDz/8oLfeesvVtmfPHs2ePVvZ2dnq2LGjRowYoaSkJAurtE51x+dPf/qTUlNTdejQIbVu3VoPPPCAnn32WddlkxvdsmXLtHDhwmr7EhISNHfuXH3++eeaN2+ejhw5ok6dOmn8+PH65S9/2cCVWsOT47N+/XqtX79ex44dc+1ZGz16dLM5syZJZ8+e1fz58/XZZ5/p7Nmz6tu3r5577jnXJcbm9jpEOAIAADA0n1gMAADgAcIRAACAgXAEAABgIBwBAAAYCEcAAAAGwhEAAICBcAQAAGAgHAEAABgIRwAAAAbCEQAAgIFwBAAAYPj/PNZrxCEEy0cAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_lens = [len(tokens) for tokens in shuffled_df['cleaned_tokens']]\n",
    "sns.histplot(seq_lens, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df.to_csv(\"../data/processed/train_intents.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intent            object\n",
      "tokens            object\n",
      "cleaned_tokens    object\n",
      "dtype: object\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Print the data types of the columns\n",
    "print(shuffled_df.dtypes)\n",
    "\n",
    "# Check the data types of each row in the \"tokens\" column and if its not a list, highlight the the error \n",
    "# Don't print it, log it \n",
    "print(\" \")\n",
    "for index, row in shuffled_df.iterrows():\n",
    "    if not isinstance(row[\"tokens\"], list):\n",
    "        print(f\"Error: {row['tokens']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [token_lst for token_lst in shuffled_df['cleaned_tokens']]\n",
    "X = [*X]\n",
    "y = [*shuffled_df['intent'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/saggysimmba/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/saggysimmba/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torchtext Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torchtext tokenizer \n",
    "- Add description later "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan of Action\n",
    "- Prepare the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Applications/saggydev/projects_learning/amazon_support/notebooks'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Steps taken\n",
    "    -   the words would involve creating a vocabulary dictionary to map words to indices \n",
    "    -   For each sequence, the words are converted into their corresponding indices based on the word dictionary \n",
    "    - When feeding sentences into the model, ensure a consistent sequence length is crucial \n",
    "    - To achieve this, sequences are padded with zeros until they reach the length of the longest sequence \n",
    "    - This padding ensures uniformity, and shorter maximum lengths are typically preferred for ease of training, as longer sequences can pose challenges \n",
    "    - This padding ensures uniformity, and shorter maximum lengths are typically preferred for ease of training, as longer sequences can pose challenges \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Use glove word embeddings \n",
    "embeddings_index = {}\n",
    "f = open(\"../models/glove.twitter.27B/glove.twitter.27B.200d.txt\", \"r\", encoding=\"utf-8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now build a vocabulary: This is something I hadve just added \n",
    "from collections import Counter\n",
    "word_counts = Counter(token for sentence in X for token in sentence)\n",
    "vocabulary = {word: i+1 for i, (word, _) in enumerate(word_counts.items())}  # Reserve 0 for padding \n",
    "vocabulary[\"<unknown>\"] = len(vocabulary) + 1  # Reserve for unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.20198  ,  0.41916  , -1.0054   , -0.84391  , -0.68951  ,\n",
       "        0.18279  , -0.23453  , -0.0052121,  0.45239  , -0.92015  ,\n",
       "       -0.13365  ,  0.040719 ,  0.072168 , -0.062865 , -1.3087   ,\n",
       "        0.27299  ,  0.52128  ,  0.57118  ,  0.29222  ,  0.33075  ,\n",
       "       -0.24459  , -0.37486  ,  1.1441   , -0.46274  , -0.076162 ,\n",
       "        0.82587  , -0.24807  , -0.944    ,  0.61853  , -0.39438  ,\n",
       "        0.59014  , -0.29744  , -0.35508  ,  0.53303  ,  0.44923  ,\n",
       "       -0.63778  , -0.15895  , -0.86348  , -0.49895  , -0.041426 ,\n",
       "        0.43123  ,  0.29367  , -1.2033   , -0.45566  , -0.34636  ,\n",
       "       -0.02048  , -1.7236   ,  0.5066   , -0.81875  , -0.21657  ,\n",
       "       -0.26766  ,  0.35248  ,  0.078784 , -0.66945  ,  1.1626   ,\n",
       "        0.0051163, -1.0655   ,  0.096867 ,  0.33572  ,  0.52233  ,\n",
       "        0.40273  ,  0.027763 , -0.58058  , -0.42969  , -0.22255  ,\n",
       "        0.51217  ,  0.011956 ,  0.043467 ,  0.3244   ,  1.0959   ,\n",
       "        0.11997  ,  0.60929  ,  0.068    ,  0.19848  , -0.46239  ,\n",
       "        0.7439   , -0.75058  , -0.018753 ,  0.58308  ,  0.058709 ,\n",
       "       -1.6619   ,  0.5988   ,  0.59503  , -0.90967  , -0.23844  ,\n",
       "        0.1871   ,  0.2298   , -0.61659  ,  0.72868  , -0.044096 ,\n",
       "       -0.093553 ,  1.0485   ,  0.43222  , -0.6701   ,  0.099832 ,\n",
       "       -0.57062  , -1.1275   , -0.25786  , -0.067018 ,  0.99043  ,\n",
       "       -0.16494  , -0.074319 , -0.20347  ,  0.50117  ,  0.99839  ,\n",
       "        0.027985 , -0.26679  ,  0.10414  , -0.1975   ,  0.53277  ,\n",
       "        0.59072  , -0.98284  , -0.41028  ,  0.86478  , -0.56606  ,\n",
       "        0.50508  ,  0.48191  , -0.83698  , -0.68231  ,  0.71701  ,\n",
       "        0.20375  ,  0.24835  ,  0.61261  , -0.82918  ,  0.1744   ,\n",
       "        0.51417  , -0.94267  , -0.22483  ,  0.82227  ,  0.64526  ,\n",
       "        0.77582  ,  0.081498 ,  0.14157  ,  0.57915  , -0.37718  ,\n",
       "        0.30407  ,  0.025211 ,  0.45323  , -0.033279 , -0.14454  ,\n",
       "       -0.16226  ,  0.44186  , -0.40837  ,  0.43568  ,  0.97894  ,\n",
       "       -0.36031  ,  0.051556 , -0.66336  ,  0.28641  , -0.018247 ,\n",
       "        0.25104  , -0.47485  ,  0.33419  ,  0.77673  ,  0.29789  ,\n",
       "       -0.097057 , -0.36122  ,  0.37737  ,  0.62324  , -0.47451  ,\n",
       "       -0.78616  ,  0.41789  ,  0.64583  , -0.89144  , -0.60993  ,\n",
       "       -0.43233  ,  0.525    ,  0.58204  , -0.32864  ,  0.39671  ,\n",
       "        0.74224  , -0.73897  ,  2.0081   ,  0.4678   , -1.4246   ,\n",
       "       -0.36199  ,  0.13764  , -0.18797  ,  0.23071  ,  0.56834  ,\n",
       "        0.072789 ,  0.49499  ,  1.0639   ,  0.67527  ,  0.98661  ,\n",
       "        0.76382  ,  0.96887  , -1.1163   ,  0.34554  ,  0.38176  ,\n",
       "        0.91244  , -0.52999  , -0.17728  ,  0.18612  ,  1.0075   ,\n",
       "       -0.29716  ,  0.27487  , -0.3182   ,  0.21931  , -0.64215  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index[\"<unknown>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.20198  ,  0.41916  , -1.0054   , -0.84391  , -0.68951  ,\n",
       "        0.18279  , -0.23453  , -0.0052121,  0.45239  , -0.92015  ,\n",
       "       -0.13365  ,  0.040719 ,  0.072168 , -0.062865 , -1.3087   ,\n",
       "        0.27299  ,  0.52128  ,  0.57118  ,  0.29222  ,  0.33075  ,\n",
       "       -0.24459  , -0.37486  ,  1.1441   , -0.46274  , -0.076162 ,\n",
       "        0.82587  , -0.24807  , -0.944    ,  0.61853  , -0.39438  ,\n",
       "        0.59014  , -0.29744  , -0.35508  ,  0.53303  ,  0.44923  ,\n",
       "       -0.63778  , -0.15895  , -0.86348  , -0.49895  , -0.041426 ,\n",
       "        0.43123  ,  0.29367  , -1.2033   , -0.45566  , -0.34636  ,\n",
       "       -0.02048  , -1.7236   ,  0.5066   , -0.81875  , -0.21657  ,\n",
       "       -0.26766  ,  0.35248  ,  0.078784 , -0.66945  ,  1.1626   ,\n",
       "        0.0051163, -1.0655   ,  0.096867 ,  0.33572  ,  0.52233  ,\n",
       "        0.40273  ,  0.027763 , -0.58058  , -0.42969  , -0.22255  ,\n",
       "        0.51217  ,  0.011956 ,  0.043467 ,  0.3244   ,  1.0959   ,\n",
       "        0.11997  ,  0.60929  ,  0.068    ,  0.19848  , -0.46239  ,\n",
       "        0.7439   , -0.75058  , -0.018753 ,  0.58308  ,  0.058709 ,\n",
       "       -1.6619   ,  0.5988   ,  0.59503  , -0.90967  , -0.23844  ,\n",
       "        0.1871   ,  0.2298   , -0.61659  ,  0.72868  , -0.044096 ,\n",
       "       -0.093553 ,  1.0485   ,  0.43222  , -0.6701   ,  0.099832 ,\n",
       "       -0.57062  , -1.1275   , -0.25786  , -0.067018 ,  0.99043  ,\n",
       "       -0.16494  , -0.074319 , -0.20347  ,  0.50117  ,  0.99839  ,\n",
       "        0.027985 , -0.26679  ,  0.10414  , -0.1975   ,  0.53277  ,\n",
       "        0.59072  , -0.98284  , -0.41028  ,  0.86478  , -0.56606  ,\n",
       "        0.50508  ,  0.48191  , -0.83698  , -0.68231  ,  0.71701  ,\n",
       "        0.20375  ,  0.24835  ,  0.61261  , -0.82918  ,  0.1744   ,\n",
       "        0.51417  , -0.94267  , -0.22483  ,  0.82227  ,  0.64526  ,\n",
       "        0.77582  ,  0.081498 ,  0.14157  ,  0.57915  , -0.37718  ,\n",
       "        0.30407  ,  0.025211 ,  0.45323  , -0.033279 , -0.14454  ,\n",
       "       -0.16226  ,  0.44186  , -0.40837  ,  0.43568  ,  0.97894  ,\n",
       "       -0.36031  ,  0.051556 , -0.66336  ,  0.28641  , -0.018247 ,\n",
       "        0.25104  , -0.47485  ,  0.33419  ,  0.77673  ,  0.29789  ,\n",
       "       -0.097057 , -0.36122  ,  0.37737  ,  0.62324  , -0.47451  ,\n",
       "       -0.78616  ,  0.41789  ,  0.64583  , -0.89144  , -0.60993  ,\n",
       "       -0.43233  ,  0.525    ,  0.58204  , -0.32864  ,  0.39671  ,\n",
       "        0.74224  , -0.73897  ,  2.0081   ,  0.4678   , -1.4246   ,\n",
       "       -0.36199  ,  0.13764  , -0.18797  ,  0.23071  ,  0.56834  ,\n",
       "        0.072789 ,  0.49499  ,  1.0639   ,  0.67527  ,  0.98661  ,\n",
       "        0.76382  ,  0.96887  , -1.1163   ,  0.34554  ,  0.38176  ,\n",
       "        0.91244  , -0.52999  , -0.17728  ,  0.18612  ,  1.0075   ,\n",
       "       -0.29716  ,  0.27487  , -0.3182   ,  0.21931  , -0.64215  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index.get(\"<unknown>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('virtual', 1), ('assistant', 2), ('email', 3), ('received', 4), ('appreciate', 5), ('find', 6), ('delivery', 7), ('status', 8), ('software', 9), ('connect', 10), ('live', 11), ('agent', 12), ('concern', 13), ('deliver', 14), ('product', 15), ('second', 16), ('instance', 17), ('calling', 18), ('confirming', 19), ('time', 20), ('yes', 21), ('course', 22), ('tried', 23), ('said', 24), ('dispatched', 25), ('could', 26), ('cancelled', 27), ('kind', 28), ('backwards', 29), ('system', 30), ('guys', 31), ('operate', 32), ('thanks', 33), ('surprised', 34), ('even', 35), ('hours', 36), ('availability', 37), ('place', 38), ('download', 39), ('option', 40), ('present', 41), ('titles', 42), ('one', 43), ('contacted', 44), ('cheap', 45), ('offer', 46), ('day', 47), ('shipping', 48), ('going', 49), ('within', 50), ('days', 51), ('much', 52), ('appreciated', 53), ('let', 54), ('talk', 55), ('support', 56), ('check', 57), ('parcel', 58), ('representative', 59), ('ordered', 60), ('since', 61), ('friday', 62), ('still', 63), ('shipped', 64), ('complained', 65), ('told', 66), ('wait', 67), ('replied', 68), ('back', 69), ('lousy', 70), ('dude', 71), ('pathetic', 72), ('service', 73), ('expected', 74), ('date', 75), ('oct', 76), ('delivered', 77), ('yet', 78), ('order', 79), ('number', 80), ('hi', 81), ('numbers', 82), ('cc', 83), ('giving', 84), ('away', 85), ('false', 86), ('assurances', 87), ('easy', 88), ('return', 89), ('bought', 90), ('iphone', 91), ('using', 92), ('amazon', 93), ('pay', 94), ('balance', 95), ('great', 96), ('evening', 97), ('th', 98), ('october', 99), ('tracking', 100), ('bye', 101), ('thank', 102), ('thats', 103), ('computer', 104), ('reduction', 105), ('discount', 106), ('track', 107), ('purchase', 108), ('need', 109), ('job', 110), ('resume', 111), ('cover', 112), ('letter', 113), ('writing', 114), ('samples', 115), ('marketing', 116), ('experience', 117), ('legal', 118), ('done', 119), ('hey', 120), ('please', 121), ('seller', 122), ('funds', 123), ('held', 124), ('customer', 125), ('care', 126), ('chennai', 127), ('delayed', 128), ('response', 129), ('intimation', 130), ('team', 131), ('executives', 132), ('lie', 133), ('refund', 134), ('keep', 135), ('saying', 136), ('sorry', 137), ('cut', 138), ('ice', 139), ('steal', 140), ('money', 141), ('transfer', 142), ('exactly', 143), ('point', 144), ('control', 145), ('orders', 146), ('fulfilled', 147), ('sellers', 148), ('az', 149), ('claim', 150), ('guarantee', 151), ('work', 152), ('case', 153), ('late', 154), ('amp', 155), ('refused', 156), ('cancel', 157), ('filed', 158), ('useless', 159), ('package', 160), ('cash', 161), ('payment', 162), ('courier', 163), ('picking', 164), ('calls', 165), ('pls', 166), ('help', 167), ('us', 168), ('stop', 169), ('waste', 170), ('somehow', 171), ('trying', 172), ('link', 173), ('account', 174), ('exist', 175), ('sloppy', 176), ('blame', 177), ('needful', 178), ('side', 179), ('pleaseee', 180), ('mail', 181), ('reply', 182), ('things', 183), ('rude', 184), ('missed', 185), ('already', 186), ('previously', 187), ('charged', 188), ('also', 189), ('phone', 190), ('rep', 191), ('reached', 192), ('clue', 193), ('reps', 194), ('canned', 195), ('stuff', 196), ('thought', 197), ('prime', 198), ('customers', 199), ('ahead', 200), ('queue', 201), ('digital', 202), ('item', 203), ('quality', 204), ('problem', 205), ('see', 206), ('speak', 207), ('wasting', 208), ('cardboards', 209), ('improve', 210), ('packaging', 211), ('seasonal', 212), ('sale', 213), ('note', 214), ('want', 215), ('replacement', 216), ('app', 217), ('contact', 218), ('human', 219), ('locate', 220), ('shipment', 221), ('honestly', 222), ('sure', 223), ('dm', 224), ('details', 225), ('month', 226), ('ago', 227), ('thru', 228), ('uncertain', 229), ('take', 230), ('responsibility', 231), ('paid', 232), ('expedited', 233), ('standard', 234), ('interesting', 235), ('seem', 236), ('anywhere', 237), ('loop', 238), ('later', 239), ('holiday', 240), ('hello', 241), ('everyone', 242), ('automated', 243), ('code', 244), ('infact', 245), ('range', 246), ('refurbished', 247), ('products', 248), ('delivers', 249), ('fraud', 250), ('site', 251), ('suggesting', 252), ('people', 253), ('trust', 254), ('selling', 255), ('mobiles', 256), ('name', 257), ('offers', 258), ('center', 259), ('proof', 260), ('give', 261), ('update', 262), ('updated', 263), ('sunday', 264), ('loyalty', 265), ('program', 266), ('information', 267), ('arriving', 268), ('today', 269), ('pm', 270), ('different', 271), ('representatives', 272), ('urs', 273), ('asking', 274), ('solution', 275), ('higher', 276), ('tell', 277), ('meif', 278), ('id', 279), ('called', 280), ('actual', 281), ('issue', 282), ('deliveries', 283), ('joke', 284), ('location', 285), ('charge', 286), ('bank', 287), ('idea', 288), ('rs', 289), ('next', 290), ('follow', 291), ('home', 292), ('news', 293), ('packages', 294), ('never', 295), ('get', 296), ('exclusive', 297), ('step', 298), ('provided', 299), ('invoice', 300), ('attaching', 301), ('printable', 302), ('version', 303), ('file', 304), ('xxx', 305), ('screenshot', 306), ('fedex', 307), ('found', 308), ('website', 309), ('page', 310), ('resolution', 311), ('cost', 312), ('sign', 313), ('rewards', 314), ('visa', 315), ('requested', 316), ('placed', 317), ('highlight', 318), ('im', 319), ('set', 320), ('good', 321), ('takes', 322), ('list', 323), ('meaning', 324), ('estimates', 325), ('tricky', 326), ('say', 327), ('november', 328), ('tomorrow', 329), ('unnecessary', 330), ('questions', 331), ('fix', 332), ('glitch', 333), ('instead', 334), ('teaching', 335), ('pincode', 336), ('gets', 337), ('delivrd', 338), ('waygo', 339), ('digitalisationuuttrly', 340), ('unprofessnl', 341), ('two', 342), ('member', 343), ('usually', 344), ('ship', 345), ('intelcom', 346), ('express', 347), ('problems', 348), ('without', 349), ('signature', 350), ('en', 351), ('route', 352), ('possible', 353), ('school', 354), ('real', 355), ('person', 356), ('would', 357), ('chased', 358), ('sometimes', 359), ('carrier', 360), ('report', 361), ('error', 362), ('four', 363), ('scheduled', 364), ('spend', 365), ('view', 366), ('friends', 367), ('wishlists', 368), ('reason', 369), ('might', 370), ('somewhere', 371), ('else', 372), ('robotic', 373), ('nobody', 374), ('came', 375), ('receive', 376), ('incorrectly', 377), ('assistance', 378), ('required', 379), ('special', 380), ('autumn', 381), ('due', 382), ('poor', 383), ('year', 384), ('end', 385), ('buddy', 386), ('weeks', 387), ('reported', 388), ('early', 389), ('asked', 390), ('another', 391), ('new', 392), ('either', 393), ('limited', 394), ('goodbye', 395), ('chat', 396), ('multiple', 397), ('marked', 398), ('waiting', 399), ('vague', 400), ('replies', 401), ('rd', 402), ('row', 403), ('failed', 404), ('continuous', 405), ('biz', 406), ('attempts', 407), ('items', 408), ('supposed', 409), ('months', 410), ('mails', 411), ('bother', 412), ('solve', 413), ('first', 414), ('emi', 415), ('got', 416), ('deducted', 417), ('cs', 418), ('disappointed', 419), ('irresponsible', 420), ('unauthorized', 421), ('interests', 422), ('buyer', 423), ('indian', 424), ('amzn', 425), ('india', 426), ('unhelpful', 427), ('operator', 428), ('like', 429), ('share', 430), ('info', 431), ('promotion', 432), ('business', 433), ('stoped', 434), ('times', 435), ('investigate', 436), ('alert', 437), ('scam', 438), ('tba', 439), ('long', 440), ('ai', 441), ('ever', 442), ('till', 443), ('executive', 444), ('talked', 445), ('language', 446), ('hang', 447), ('listening', 448), ('anything', 449), ('services', 450), ('chatampwas', 451), ('hrs', 452), ('investigating', 453), ('happened', 454), ('others', 455), ('week', 456), ('though', 457), ('word', 458), ('escalation', 459), ('unprofessional', 460), ('uneducated', 461), ('none', 462), ('actually', 463), ('resolved', 464), ('go', 465), ('office', 466), ('collect', 467), ('cheque', 468), ('wrong', 469), ('earliest', 470), ('promo', 471), ('bot', 472), ('chatbot', 473), ('many', 474), ('subscribe', 475), ('save', 476), ('far', 477), ('worst', 478), ('almost', 479), ('passed', 480), ('processed', 481), ('fake', 482), ('assurance', 483), ('every', 484), ('call', 485), ('handling', 486), ('may', 487), ('know', 488), ('m', 489), ('replyin', 490), ('stupid', 491), ('n', 492), ('paying', 493), ('monthly', 494), ('fee', 495), ('getting', 496), ('benefit', 497), ('good evening', 498), ('password', 499), ('correct', 500), ('wish', 501), ('charging', 502), ('emails', 503), ('grabbers', 504), ('🤬', 505), ('reach', 506), ('alright', 507), ('remains', 508), ('words', 509), ('action', 510), ('ive', 511), ('guyz', 512), ('fo', 513), ('way', 514), ('cheat', 515), ('price', 516), ('k', 517), ('buyprice', 518), ('changed', 519), ('cheaters', 520), ('diwali', 521), ('gifts', 522), ('staffs', 523), ('worth', 524), ('inr', 525), ('driver', 526), ('refusing', 527), ('safe', 528), ('message', 529), ('hundreds', 530), ('defeats', 531), ('⊙', 532), ('☉', 533), ('twitter', 534), ('completed', 535), ('signed', 536), ('last', 537), ('pick', 538), ('post', 539), ('subscription', 540), ('must', 541), ('world', 542), ('record', 543), ('lot', 544), ('amazing', 545), ('cheating', 546), ('think', 547), ('trending', 548), ('across', 549), ('psn', 550), ('fixed', 551), ('impatient', 552), ('😣', 553), ('experiencing', 554), ('issues', 555), ('damage', 556), ('merit', 557), ('rectifying', 558), ('really', 559), ('happy', 560), ('prices', 561), ('damaged', 562), ('purchased', 563), ('filled', 564), ('picked', 565), ('defective', 566), ('shared', 567), ('twice', 568), ('past', 569), ('answer', 570), ('usps', 571), ('delivering', 572), ('chance', 573), ('yous', 574), ('technical', 575), ('minutes', 576), ('fact', 577), ('party', 578), ('address', 579), ('buy', 580), ('ask', 581), ('reviews', 582), ('makes', 583), ('membership', 584), ('infuriating', 585), ('quoted', 586), ('old', 587), ('company', 588), ('handle', 589), ('logistics', 590), ('process', 591), ('requesting', 592), ('good morning', 593), ('shame', 594), ('fooling', 595), ('faulty', 596), ('tracked', 597), ('postal', 598), ('dublin', 599), ('depot', 600), ('dissatisfied', 601), ('retailer', 602), ('waited', 603), ('groceries', 604), ('come', 605), ('night', 606), ('communication', 607), ('promise', 608), ('cheats', 609), ('subscribeampsave', 610), ('beware', 611), ('talking', 612), ('rebate', 613), ('someone', 614), ('made', 615), ('open', 616), ('card', 617), ('attempted', 618), ('identity', 619), ('theft', 620), ('friend', 621), ('trace', 622), ('question', 623), ('ridiculous', 624), ('huge', 625), ('cheapest', 626), ('method', 627), ('nov', 628), ('arrived', 629), ('guaranteed', 630), ('full', 631), ('earth', 632), ('writes', 633), ('sympathetic', 634), ('verging', 635), ('sarcastic', 636), ('apologies', 637), ('parcels', 638), ('august', 639), ('neither', 640), ('shown', 641), ('messages', 642), ('🤷', 643), ('🏻', 644), ('♀', 645), ('️', 646), ('lenovo', 647), ('network', 648), ('discussion', 649), ('ruark', 650), ('feb', 651), ('text', 652), ('reversed', 653), ('event', 654), ('deal', 655), ('discounted', 656), ('everything', 657), ('greetings', 658), ('fire', 659), ('stick', 660), ('based', 661), ('uk', 662), ('settings', 663), ('informed', 664), ('via', 665), ('life', 666), ('extra', 667), ('savings', 668), ('canceled', 669), ('personal', 670), ('visible', 671), ('non', 672), ('sense', 673), ('sent', 674), ('jewellery', 675), ('hallmark', 676), ('defects', 677), ('taking', 678), ('initiated', 679), ('widin', 680), ('min', 681), ('dlvry', 682), ('pethetic', 683), ('sandisk', 684), ('gb', 685), ('visit', 686), ('unable', 687), ('cod', 688), ('eligible', 689), ('low', 690), ('helpline', 691), ('telephone', 692), ('use', 693), ('piece', 694), ('shopping', 695), ('shortage', 696), ('trees', 697), ('overkill', 698), ('condition', 699), ('helping', 700), ('rather', 701), ('resolving', 702), ('seems', 703), ('send', 704), ('shipments', 705), ('processes', 706), ('model', 707), ('escalated', 708), ('period', 709), ('reluctantly', 710), ('form', 711), ('happens', 712), ('hopeful', 713), ('sir', 714), ('spite', 715), ('repeated', 716), ('reminder', 717), ('sales', 718), ('falls', 719), ('deaf', 720), ('ears', 721), ('frustrating', 722), ('normally', 723), ('grandsons', 724), ('birthday', 725), ('payments', 726), ('declined', 727), ('rate', 728), ('working', 729), ('eta', 730), ('tuesday', 731), ('local', 732), ('complaint', 733), ('results', 734), ('bargain', 735), ('destroyed', 736), ('gift', 737), ('coupdnt', 738), ('believe', 739), ('temper', 740), ('glass', 741), ('vide', 742), ('tempered', 743), ('sold', 744), ('d', 745), ('salutations', 746), ('resolve', 747), ('quite', 748), ('ashamed', 749), ('nothing', 750), ('shows', 751), ('efficency', 752), ('fed', 753), ('copy', 754), ('brought', 755), ('notice', 756), ('earlier', 757), ('understand', 758), ('senior', 759), ('intervention', 760), ('issued', 761), ('loss', 762), ('ypu', 763), ('excuse', 764), ('fill', 765), ('left', 766), ('recent', 767), ('events', 768), ('seriously', 769), ('doubt', 770), ('level', 771), ('competency', 772), ('book', 773), ('friendly', 774), ('feel', 775), ('solving', 776), ('general', 777), ('saga', 778), ('continues', 779), ('promised', 780), ('lied', 781), ('hermes', 782), ('advised', 783), ('manager', 784), ('signin', 785), ('video', 786), ('goods', 787), ('music', 788), ('function', 789), ('sending', 790), ('endless', 791), ('singin', 792), ('cycle', 793), ('currently', 794), ('confusing', 795), ('csrs', 796), ('interacted', 797), ('amzl', 798), ('spoken', 799), ('keeps', 800), ('repeating', 801), ('managers', 802), ('locality', 803), ('inspite', 804), ('cashback', 805), ('credit', 806), ('able', 807), ('decided', 808), ('debit', 809), ('🙃', 810), ('yesterday', 811), ('grocery', 812), ('pantry', 813), ('plastic', 814), ('won', 815), ('quiz', 816), ('contest', 817), ('winner', 818), ('july', 819), ('dint', 820), ('mrp', 821), ('submitted', 822), ('review', 823), ('othets', 824), ('allowing', 825), ('ethics', 826), ('clearly', 827), ('lies', 828), ('bad', 829), ('frustrated', 830), ('additional', 831), ('charges', 832), ('satisfactory', 833), ('explanation', 834), ('coordination', 835), ('partners', 836), ('ongoing', 837), ('maybe', 838), ('giftcard', 839), ('went', 840), ('comp', 841), ('lessons', 842), ('learnt', 843), ('actions', 844), ('taken', 845), ('enough', 846), ('high', 847), ('tells', 848), ('longer', 849), ('hmmm', 850), ('posted', 851), ('allowed', 852), ('insulted', 853), ('description', 854), ('inhelpful', 855), ('bunch', 856), ('replying', 857), ('professionalism', 858), ('warning', 859), ('window', 860), ('available', 861), ('dissapointed', 862), ('coming', 863), ('sooner', 864), ('added', 865), ('coupon', 866), ('responded', 867), ('result', 868), ('approach', 869), ('specified', 870), ('million', 871), ('chatted', 872), ('explain', 873), ('samsung', 874), ('tv', 875), ('feedback', 876), ('look', 877), ('forward', 878), ('everytime', 879), ('robot', 880), ('wardrobe', 881), ('slow', 882), ('sounds', 883), ('drunk', 884), ('well', 885), ('aws', 886), ('maintenance', 887), ('accepting', 888), ('progress', 889), ('showing', 890), ('placing', 891), ('disgusting', 892), ('specify', 893), ('annoying', 894), ('fast', 895), ('anymore', 896), ('started', 897), ('regarding', 898), ('svc', 899), ('logged', 900), ('browse', 901), ('audiobooks', 902), ('checkout', 903), ('credits', 904), ('procedure', 905), ('confirmation', 906), ('sms', 907), ('wonderful', 908), ('various', 909), ('errors', 910), ('associated', 911), ('jurisdiction', 912), ('presumably', 913), ('com', 914), ('ca', 915), ('request', 916), ('access', 917), ('bothered', 918), ('permission', 919), ('add', 920), ('doorstep', 921), ('load', 922), ('upto', 923), ('famp', 924), ('hello there', 925), ('kidding', 926), ('proper', 927), ('expensive', 928), ('electronic', 929), ('device', 930), ('smh', 931), ('complain', 932), ('worse', 933), ('part', 934), ('hear', 935), ('earphones', 936), ('kindly', 937), ('inexcusable', 938), ('sorted', 939), ('panic', 940), ('☺', 941), ('notification', 942), ('total', 943), ('nonsense', 944), ('irritated', 945), ('complaints', 946), ('blue', 947), ('dart', 948), ('updates', 949), ('put', 950), ('restrictions', 951), ('adding', 952), ('😡', 953), ('value', 954), ('commitments', 955), ('nt', 956), ('responding', 957), ('provide', 958), ('drops', 959), ('written', 960), ('rural', 961), ('run', 962), ('overkilled', 963), ('pet', 964), ('chicken', 965), ('acceptable', 966), ('sort', 967), ('accountability', 968), ('credited', 969), ('despite', 970), ('complaining', 971), ('expecting', 972), ('type', 973), ('ss', 974), ('notifications', 975), ('given', 976), ('season', 977), ('dreadfully', 978), ('necessarily', 979), ('inconvenient', 980), ('reorder', 981), ('situation', 982), ('responsible', 983), ('totally', 984), ('everythingnothing', 985), ('serviceyour', 986), ('answers', 987), ('queries', 988), ('r', 989), ('making', 990), ('big', 991), ('trouble', 992), ('xbox', 993), ('x', 994), ('distribution', 995), ('united', 996), ('statescanada', 997), ('eu', 998), ('c', 999), ('power', 1000), ('cable', 1001), ('awesome', 1002), ('saving', 1003), ('arrive', 1004), ('dec', 1005), ('totals', 1006), ('purchases', 1007), ('dates', 1008), ('verification', 1009), ('centers', 1010), ('apparently', 1011), ('massive', 1012), ('wide', 1013), ('tens', 1014), ('thousands', 1015), ('dollars', 1016), ('assembled', 1017), ('original', 1018), ('frm', 1019), ('edd', 1020), ('bt', 1021), ('rqst', 1022), ('cncld', 1023), ('plz', 1024), ('markdown', 1025), ('speaking', 1026), ('registered', 1027), ('active', 1028), ('change', 1029), ('says', 1030), ('requires', 1031), ('ideas', 1032), ('mob', 1033), ('bill', 1034), ('always', 1035), ('understood', 1036), ('loosers', 1037), ('anyone', 1038), ('sensible', 1039), ('deliberately', 1040), ('free', 1041), ('man', 1042), ('catch', 1043), ('deffective', 1044), ('soon', 1045), ('transit', 1046), ('spoke', 1047), ('pf', 1048), ('clicking', 1049), ('steps', 1050), ('tweet', 1051), ('crm', 1052), ('tool', 1053), ('reference', 1054), ('disgusted', 1055), ('inefficient', 1056), ('unethical', 1057), ('centric', 1058), ('laughable', 1059), ('boy', 1060), ('unfortunately', 1061), ('guy', 1062), ('leave', 1063), ('cancle', 1064), ('promises', 1065), ('concerns', 1066), ('central', 1067), ('suspended', 1068), ('gives', 1069), ('sells', 1070), ('watch', 1071), ('creditcard', 1072), ('flipkart', 1073), ('shop', 1074), ('clues', 1075), ('facility', 1076), ('reaching', 1077), ('luck', 1078), ('bots', 1079), ('undwrstanding', 1080), ('hung', 1081), ('onyo', 1082), ('agree', 1083), ('police', 1084), ('clearance', 1085), ('continue', 1086), ('amd', 1087), ('fc', 1088), ('relevant', 1089), ('touch', 1090), ('estimate', 1091), ('troubleshooting', 1092), ('try', 1093), ('round', 1094), ('pl', 1095), ('advise', 1096), ('timeline', 1097), ('reverse', 1098), ('amount', 1099), ('per', 1100), ('der', 1101), ('wit', 1102), ('nd', 1103), ('acknowledge', 1104), ('conversation', 1105), ('computerized', 1106), ('three', 1107), ('wil', 1108), ('apple', 1109), ('providing', 1110), ('content', 1111), ('sub', 1112), ('soo', 1113), ('dumbampcheck', 1114), ('officials', 1115), ('canceling', 1116), ('deveshsali', 1117), ('removing', 1118), ('quantity', 1119), ('limit', 1120), ('unknown', 1121), ('anyway', 1122), ('food', 1123), ('stone', 1124), ('cold', 1125), ('books', 1126), ('revise', 1127), ('protection', 1128), ('plan', 1129), ('pending', 1130), ('packet', 1131), ('online', 1132), ('hanging', 1133), ('something', 1134), ('listen', 1135), ('replacing', 1136), ('flagged', 1137), ('monday', 1138), ('feels', 1139), ('fooled', 1140), ('purchasing', 1141), ('opt', 1142), ('subtracting', 1143), ('simply', 1144), ('mentioned', 1145), ('negative', 1146), ('mine', 1147), ('capable', 1148), ('utterly', 1149), ('cstmr', 1150), ('lodge', 1151), ('formal', 1152), ('nope', 1153), ('hour', 1154), ('occurred', 1155), ('irritatng', 1156), ('query', 1157), ('dog', 1158), ('stock', 1159), ('changes', 1160), ('english', 1161), ('pair', 1162), ('socks', 1163), ('happening', 1164), ('facing', 1165), ('supplied', 1166), ('returning', 1167), ('missing', 1168), ('camera', 1169), ('lens', 1170), ('box', 1171), ('empty', 1172), ('incompetent', 1173), ('employee', 1174), ('tc', 1175), ('write', 1176), ('st', 1177), ('rejectedso', 1178), ('improvement', 1179), ('thisthere', 1180), ('peoples', 1181), ('verry', 1182), ('escalate', 1183), ('vendor', 1184), ('disappointment', 1185), ('windows', 1186), ('closed', 1187), ('delay', 1188), ('figure', 1189), ('recover', 1190), ('pickup', 1191), ('rescheduled', 1192), ('returned', 1193), ('deliveryperson', 1194), ('neighbour', 1195), ('notes', 1196), ('mobile', 1197), ('😠', 1198), ('cheers', 1199), ('pals', 1200), ('fighting', 1201), ('laptop', 1202), ('battery', 1203), ('sony', 1204), ('radio', 1205), ('fail', 1206), ('boys', 1207), ('drones', 1208), ('decision', 1209), ('paygrade', 1210), ('internally', 1211), ('looking', 1212), ('associate', 1213), ('careless', 1214), ('area', 1215), ('yesi', 1216), ('upi', 1217), ('detail', 1218), ('sand', 1219), ('finished', 1220), ('folks', 1221), ('thrice', 1222), ('problemplease', 1223), ('undeliverable', 1224), ('exchange', 1225), ('normal', 1226), ('practice', 1227), ('best', 1228), ('lost', 1229), ('refuse', 1230), ('fluctuations', 1231), ('portal', 1232), ('voucher', 1233), ('material', 1234), ('lightly', 1235), ('advocate', 1236), ('face', 1237), ('court', 1238), ('q', 1239), ('subscriber', 1240), ('certain', 1241), ('movies', 1242), ('series', 1243), ('ahows', 1244), ('saudi', 1245), ('arabia', 1246), ('devices', 1247), ('haha', 1248), ('nowadays', 1249), ('less', 1250), ('gf', 1251), ('jokers', 1252), ('wt', 1253), ('sharing', 1254), ('interaction', 1255), ('hit', 1256), ('third', 1257), ('ringing', 1258), ('bell', 1259), ('b', 1260), ('msgs', 1261), ('morning', 1262), ('methods', 1263), ('linked', 1264), ('elses', 1265), ('texts', 1266), ('prefer', 1267), ('mark', 1268), ('consumer', 1269), ('myhome', 1270), ('exp', 1271), ('kapil', 1272), ('eyes', 1273), ('positive', 1274), ('allow', 1275), ('enquiry', 1276), ('seeking', 1277), ('renewed', 1278), ('winners', 1279), ('announced', 1280), ('metro', 1281), ('city', 1282), ('kolkata', 1283), ('cloudtail', 1284), ('start', 1285), ('sorting', 1286), ('urgently', 1287), ('otherwise', 1288), ('project', 1289), ('scorpio', 1290), ('edition', 1291), ('likely', 1292), ('refunds', 1293), ('opened', 1294), ('tampered', 1295), ('recvd', 1296), ('answered', 1297), ('treating', 1298), ('better', 1299), ('weekly', 1300), ('following', 1301), ('links', 1302), ('thing', 1303), ('tomm', 1304), ('headed', 1305), ('fulfilment', 1306), ('exec', 1307), ('floor', 1308), ('dear', 1309), ('clear', 1310), ('minor', 1311), ('hard', 1312), ('remember', 1313), ('smile', 1314), ('cust', 1315), ('cre', 1316), ('related', 1317), ('acreg', 1318), ('unblock', 1319), ('family', 1320), ('festive', 1321), ('escalates', 1322), ('thatpathetic', 1323), ('drop', 1324), ('intentionally', 1325), ('aware', 1326), ('public', 1327), ('bet', 1328), ('match', 1329), ('blocked', 1330), ('tired', 1331), ('years', 1332), ('fax', 1333), ('extended', 1334), ('placate', 1335), ('convenience', 1336), ('timely', 1337), ('weekend', 1338), ('despatched', 1339), ('nice', 1340), ('☹', 1341), ('chose', 1342), ('plenty', 1343), ('fingers', 1344), ('crossed', 1345), ('around', 1346), ('resent', 1347), ('recently', 1348), ('assured', 1349), ('notify', 1350), ('deals', 1351), ('looting', 1352), ('forcefully', 1353), ('discounts', 1354), ('stuck', 1355), ('netherlands', 1356), ('abut', 1357), ('asks', 1358), ('amazons', 1359), ('fba', 1360), ('lose', 1361), ('sell', 1362), ('goes', 1363), ('red', 1364), ('snatch', 1365), ('firm', 1366), ('display', 1367), ('defect', 1368), ('checked', 1369), ('estimated', 1370), ('saturday', 1371), ('miss', 1372), ('agents', 1373), ('delays', 1374), ('investigated', 1375), ('simple', 1376), ('helpful', 1377), ('satisfied', 1378), ('lack', 1379), ('clarity', 1380), ('opacity', 1381), ('looks', 1382), ('compromised', 1383), ('ups', 1384), ('unavailable', 1385), ('terms', 1386), ('conditions', 1387), ('fall', 1388), ('image', 1389), ('matching', 1390), ('members', 1391), ('harassing', 1392), ('foul', 1393), ('wants', 1394), ('jeff', 1395), ('bezos', 1396), ('wtf', 1397), ('harassment', 1398), ('chats', 1399), ('guides', 1400), ('echo', 1401), ('plus', 1402), ('house', 1403), ('speakers', 1404), ('heard', 1405), ('speaker', 1406), ('answering', 1407), ('government', 1408), ('funded', 1409), ('banco', 1410), ('de', 1411), ('llibres', 1412), ('ecommerce', 1413), ('players', 1414), ('love', 1415), ('irritating', 1416), ('injured', 1417), ('absolutely', 1418), ('horrible', 1419), ('pin', 1420), ('looked', 1421), ('history', 1422), ('worried', 1423), ('faced', 1424), ('customerstoday', 1425), ('dadagiri', 1426), ('platforms', 1427), ('farewell', 1428), ('purpose', 1429), ('discrimination', 1430), ('certainly', 1431), ('used', 1432), ('finally', 1433), ('valuable', 1434), ('colours', 1435), ('atoz', 1436), ('undelivered', 1437), ('compensates', 1438), ('interest', 1439), ('contacting', 1440), ('mailed', 1441), ('sept', 1442), ('octthen', 1443), ('thamp', 1444), ('dated', 1445), ('soonu', 1446), ('hold', 1447), ('forever', 1448), ('yup', 1449), ('webcam', 1450), ('choice', 1451), ('options', 1452), ('se', 1453), ('true', 1454), ('convenient', 1455), ('login', 1456), ('doesnt', 1457), ('meet', 1458), ('expectations', 1459), ('vice', 1460), ('versa', 1461), ('persons', 1462), ('confirm', 1463), ('stolen', 1464), ('authorisation', 1465), ('strange', 1466), ('requests', 1467), ('hacked', 1468), ('notified', 1469), ('blissfully', 1470), ('ignorant', 1471), ('couple', 1472), ('helped', 1473), ('make', 1474), ('consent', 1475), ('log', 1476), ('transperent', 1477), ('applicable', 1478), ('predominently', 1479), ('user', 1480), ('net', 1481), ('banking', 1482), ('concerned', 1483), ('rave', 1484), ('guess', 1485), ('pointless', 1486), ('leading', 1487), ('nowhere', 1488), ('anyhow', 1489), ('detaily', 1490), ('hemalatha', 1491), ('supervisor', 1492), ('purely', 1493), ('assigned', 1494), ('remark', 1495), ('git', 1496), ('correspondent', 1497), ('knowledge', 1498), ('misleading', 1499), ('ohhh', 1500), ('ondont', 1501), ('freakwho', 1502), ('kept', 1503), ('committing', 1504), ('whether', 1505), ('nokia', 1506), ('block', 1507), ('sucks', 1508), ('😤', 1509), ('uninstall', 1510), ('cotact', 1511), ('centre', 1512), ('faileddetectonline', 1513), ('identified', 1514), ('cartridges', 1515), ('manufacturer', 1516), ('provides', 1517), ('didcheck', 1518), ('comment', 1519), ('student', 1520), ('becomes', 1521), ('afford', 1522), ('noone', 1523), ('duping', 1524), ('scheme', 1525), ('dlvrd', 1526), ('matters', 1527), ('everyday', 1528), ('worthless', 1529), ('cares', 1530), ('drivers', 1531), ('saved', 1532), ('nite', 1533), ('exit', 1534), ('quantities', 1535), ('unsuccessful', 1536), ('fantastic', 1537), ('ended', 1538), ('van', 1539), ('replaced', 1540), ('social', 1541), ('media', 1542), ('attention', 1543), ('carriers', 1544), ('biggest', 1545), ('generic', 1546), ('teams', 1547), ('presence', 1548), ('avialability', 1549), ('letters', 1550), ('december', 1551), ('😳', 1552), ('instructions', 1553), ('accounts', 1554), ('ripping', 1555), ('justification', 1556), ('fair', 1557), ('😢', 1558), ('especially', 1559), ('machine', 1560), ('appalling', 1561), ('againweb', 1562), ('sends', 1563), ('straight', 1564), ('dey', 1565), ('good night', 1566), ('inspection', 1567), ('marketplace', 1568), ('initial', 1569), ('returnrefund', 1570), ('confused', 1571), ('apologize', 1572), ('picture', 1573), ('leaves', 1574), ('impression', 1575), ('reporting', 1576), ('inaccurate', 1577), ('searching', 1578), ('returns', 1579), ('ecr', 1580), ('askng', 1581), ('height', 1582), ('testing', 1583), ('patience', 1584), ('wherever', 1585), ('redirected', 1586), ('security', 1587), ('retype', 1588), ('half', 1589), ('tracker', 1590), ('tiring', 1591), ('keeping', 1592), ('repeatedly', 1593), ('failing', 1594), ('ll', 1595), ('yesno', 1596), ('warehouses', 1597), ('ohio', 1598), ('pitiful', 1599), ('apart', 1600), ('hassle', 1601), ('pre', 1602), ('god', 1603), ('knows', 1604), ('struggle', 1605), ('advertising', 1606), ('despatch', 1607), ('kudos', 1608), ('billed', 1609), ('landover', 1610), ('locations', 1611), ('assist', 1612), ('installation', 1613), ('pasted', 1614), ('arrival', 1615), ('scan', 1616), ('ar', 1617), ('good day', 1618), ('replace', 1619), ('subpar', 1620), ('headphones', 1621), ('similar', 1622), ('😞', 1623), ('personnel', 1624), ('ordering', 1625), ('applying', 1626), ('adjustment', 1627), ('feeling', 1628), ('fault', 1629), ('subscriptions', 1630), ('confirmed', 1631), ('manage', 1632), ('super', 1633), ('helps', 1634), ('artificial', 1635), ('intelligence', 1636), ('campaign', 1637), ('re', 1638), ('printer', 1639), ('print', 1640), ('label', 1641), ('raises', 1642), ('explaining', 1643), ('differently', 1644), ('servicd', 1645), ('train', 1646), ('polices', 1647), ('attempting', 1648), ('fresh', 1649), ('training', 1650), ('basket', 1651), ('assoc', 1652), ('wacct', 1653), ('fees', 1654), ('profit', 1655), ('discuss', 1656), ('read', 1657), ('cancellation', 1658), ('worry', 1659), ('bag', 1660), ('ka', 1661), ('kiya', 1662), ('lekin', 1663), ('nahin', 1664), ('hua', 1665), ('recommendation', 1666), ('introducing', 1667), ('chase', 1668), ('excuses', 1669), ('busy', 1670), ('behaviour', 1671), ('cancels', 1672), ('noted', 1673), ('hope', 1674), ('employer', 1675), ('consumers', 1676), ('consider', 1677), ('fakely', 1678), ('donewithout', 1679), ('attempt', 1680), ('edison', 1681), ('seemed', 1682), ('april', 1683), ('sleeping', 1684), ('entity', 1685), ('section', 1686), ('worste', 1687), ('porbandar', 1688), ('terrible', 1689), ('aftr', 1690), ('correspondence', 1691), ('receiving', 1692), ('trash', 1693), ('bit', 1694), ('orderno', 1695), ('sellerwithout', 1696), ('festival', 1697), ('excessive', 1698), ('overcharge', 1699), ('selll', 1700), ('willing', 1701), ('raised', 1702), ('server', 1703), ('queen', 1704), ('size', 1705), ('bed', 1706), ('accepted', 1707), ('untrue', 1708), ('reverted', 1709), ('separators', 1710), ('unusable', 1711), ('whatever', 1712), ('mistakes', 1713), ('wrote', 1714), ('handed', 1715), ('exact', 1716), ('toronto', 1717), ('according', 1718), ('elgato', 1719), ('capture', 1720), ('nightmare', 1721), ('flash', 1722), ('involved', 1723), ('accident', 1724), ('outside', 1725), ('vehicles', 1726), ('front', 1727), ('vans', 1728), ('direction', 1729), ('unlike', 1730), ('vehicle', 1731), ('stickers', 1732), ('policy', 1733), ('cm', 1734), ('loads', 1735), ('paper', 1736), ('filler', 1737), ('ludicrous', 1738), ('prior', 1739), ('loyal', 1740), ('clients', 1741), ('kendrick', 1742), ('duplicate', 1743), ('ios', 1744), ('bugs', 1745), ('prompts', 1746), ('proceeding', 1747), ('thus', 1748), ('solved', 1749), ('counted', 1750), ('transactional', 1751), ('tfw', 1752), ('mechanical', 1753), ('turk', 1754), ('configure', 1755), ('manufacture', 1756), ('hell', 1757), ('nonreturnable', 1758), ('force', 1759), ('substandard', 1760), ('hefty', 1761), ('mix', 1762), ('sister', 1763), ('incorrect', 1764), ('close', 1765), ('reimbursed', 1766), ('good afternoon', 1767), ('learn', 1768), ('regardless', 1769), ('named', 1770), ('resident', 1771), ('along', 1772), ('channels', 1773), ('laws', 1774), ('press', 1775), ('button', 1776), ('specific', 1777), ('wash', 1778), ('hands', 1779), ('defining', 1780), ('redeeming', 1781), ('claiming', 1782), ('considering', 1783), ('lodging', 1784), ('ceo', 1785), ('misbehaving', 1786), ('employees', 1787), ('bravo', 1788), ('👏', 1789), ('sue', 1790), ('google', 1791), ('alexa', 1792), ('calendars', 1793), ('means', 1794), ('large', 1795), ('withdrawn', 1796), ('count', 1797), ('fool', 1798), ('questionare', 1799), ('legally', 1800), ('printed', 1801), ('useful', 1802), ('authority', 1803), ('listed', 1804), ('circles', 1805), ('encounter', 1806), ('illogical', 1807), ('ruin', 1808), ('least', 1809), ('dozen', 1810), ('tovreply', 1811), ('ny', 1812), ('felt', 1813), ('tp', 1814), ('client', 1815), ('relationship', 1816), ('attitude', 1817), ('ill', 1818), ('speed', 1819), ('trend', 1820), ('ready', 1821), ('wid', 1822), ('cannotwill', 1823), ('guide', 1824), ('select', 1825), ('billing', 1826), ('recipients', 1827), ('disappears', 1828), ('recipient', 1829), ('blessing', 1830), ('roadblock', 1831), ('assume', 1832), ('sstore', 1833), ('however', 1834), ('xx', 1835), ('dd', 1836), ('interview', 1837), ('warehouse', 1838), ('lancaster', 1839), ('york', 1840), ('inn', 1841), ('quickly', 1842), ('cheated', 1843), ('cleverly', 1844), ('moving', 1845), ('usedits', 1846), ('irritate', 1847), ('rights', 1848), ('suffered', 1849), ('deceive', 1850), ('interested', 1851), ('packed', 1852), ('prevent', 1853), ('hence', 1854), ('struggling', 1855), ('closes', 1856), ('idle', 1857), ('breach', 1858), ('residence', 1859), ('amz', 1860), ('knew', 1861), ('insisting', 1862), ('impressed', 1863), ('crime', 1864), ('knock', 1865), ('slip', 1866), ('door', 1867), ('everybody', 1868), ('create', 1869), ('reasons', 1870), ('diyar', 1871), ('tel', 1872), ('mess', 1873), ('consistently', 1874), ('emailed', 1875), ('innovation', 1876), ('satisfaction', 1877), ('competitive', 1878), ('pricing', 1879), ('genuine', 1880), ('wanda', 1881), ('buyback', 1882), ('partner', 1883), ('show', 1884), ('tab', 1885), ('supportive', 1886), ('victim', 1887), ('hospitalized', 1888), ('surgery', 1889), ('kindle', 1890), ('locks', 1891), ('deregistered', 1892), ('uninstalled', 1893), ('reinstalled', 1894), ('tech', 1895), ('downloads', 1896), ('shut', 1897), ('morons', 1898), ('locker', 1899), ('desc', 1900), ('buysays', 1901), ('messaged', 1902), ('locked', 1903), ('mannered', 1904), ('supervisors', 1905), ('january', 1906), ('needed', 1907), ('right', 1908), ('emailid', 1909), ('bf', 1910), ('accept', 1911), ('mistake', 1912), ('credibility', 1913), ('respect', 1914), ('cond', 1915), ('suggestionbugcorrection', 1916), ('transportation', 1917), ('consignment', 1918), ('fraudulently', 1919), ('wake', 1920), ('unchanged', 1921), ('misleadcheat', 1922), ('carry', 1923), ('investigation', 1924), ('spent', 1925), ('emailing', 1926), ('directly', 1927), ('ads', 1928), ('commitment', 1929), ('classic', 1930), ('👋', 1931), ('🏼', 1932), ('broken', 1933), ('bottle', 1934), ('major', 1935), ('ducking', 1936), ('tickets', 1937), ('selected', 1938), ('asin', 1939), ('violated', 1940), ('guidelines', 1941), ('images', 1942), ('little', 1943), ('pans', 1944), ('telling', 1945), ('gone', 1946), ('apartment', 1947), ('boxes', 1948), ('simplier', 1949), ('respond', 1950), ('thinking', 1951), ('neighbours', 1952), ('compatible', 1953), ('jio', 1954), ('sim', 1955), ('awaiting', 1956), ('obviously', 1957), ('ultimately', 1958), ('elsewhere', 1959), ('couriers', 1960), ('laziness', 1961), ('soln', 1962), ('stated', 1963), ('rung', 1964), ('unused', 1965), ('portion', 1966), ('versus', 1967), ('confident', 1968), ('statement', 1969), ('interactions', 1970), ('department', 1971), ('solutions', 1972), ('cleaner', 1973), ('wasted', 1974), ('disappointing', 1975), ('enter', 1976), ('seen', 1977), ('regular', 1978), ('unless', 1979), ('tweets', 1980), ('move', 1981), ('cart', 1982), ('current', 1983), ('advance', 1984), ('traking', 1985), ('servers', 1986), ('genios', 1987), ('cracks', 1988), ('maquinas', 1989), ('idolos', 1990), ('putos', 1991), ('amos', 1992), ('nicely', 1993), ('oops', 1994), ('sry', 1995), ('happier', 1996), ('grievance', 1997), ('y', 1998), ('dealing', 1999), ('single', 2000), ('individual', 2001), ('prob', 2002), ('odd', 2003), ('turned', 2004), ('imitations', 2005), ('combined', 2006), ('random', 2007), ('sufficient', 2008), ('escalations', 2009), ('restrict', 2010), ('household', 2011), ('increased', 2012), ('minimum', 2013), ('ish', 2014), ('revert', 2015), ('contents', 2016), ('intend', 2017), ('polling', 2018), ('kannada', 2019), ('trusted', 2020), ('processing', 2021), ('hint', 2022), ('town', 2023), ('shift', 2024), ('crappy', 2025), ('promptly', 2026), ('ivr', 2027), ('expect', 2028), ('rescheduling', 2029), ('weird', 2030), ('powerbank', 2031), ('restock', 2032), ('fulfillment', 2033), ('doorsteps', 2034), ('sheer', 2035), ('whichever', 2036), ('advantage', 2037), ('crashing', 2038), ('loading', 2039), ('pages', 2040), ('jump', 2041), ('sureso', 2042), ('compensation', 2043), ('availablecan', 2044), ('guysbecause', 2045), ('patheticcan', 2046), ('contactbecause', 2047), ('sitting', 2048), ('quiet', 2049), ('soap', 2050), ('schedule', 2051), ('forms', 2052), ('numerous', 2053), ('surein', 2054), ('deliveryi', 2055), ('shirt', 2056), ('rcvd', 2057), ('remove', 2058), ('chargers', 2059), ('complete', 2060), ('cancelling', 2061), ('future', 2062), ('preorders', 2063), ('fluke', 2064), ('sad', 2065), ('whose', 2066), ('daysand', 2067), ('explained', 2068), ('imp', 2069), ('desperately', 2070), ('kills', 2071), ('owning', 2072), ('planned', 2073), ('click', 2074), ('needs', 2075), ('quicker', 2076), ('faster', 2077), ('correctlyno', 2078), ('dads', 2079), ('nearly', 2080), ('electronically', 2081), ('generated', 2082), ('sole', 2083), ('considered', 2084), ('secretprivate', 2085), ('surprisingly', 2086), ('reposed', 2087), ('cards', 2088), ('stored', 2089), ('hackers', 2090), ('rinse', 2091), ('lather', 2092), ('repeat', 2093), ('ha', 2094), ('😎', 2095), ('worries', 2096), ('😌', 2097), ('regards', 2098), ('marble', 2099), ('delaying', 2100), ('practical', 2101), ('pkg', 2102), ('rules', 2103), ('fools', 2104), ('includes', 2105), ('registration', 2106), ('honor', 2107), ('ignored', 2108), ('hallway', 2109), ('fine', 2110), ('w', 2111), ('deliveredst', 2112), ('shockedeven', 2113), ('shocking', 2114), ('cars', 2115), ('reordered', 2116), ('referred', 2117), ('harassed', 2118), ('rarely', 2119), ('yahoo', 2120), ('uses', 2121), ('affiliate', 2122), ('suspend', 2123), ('luckily', 2124), ('damages', 2125), ('countless', 2126), ('exausting', 2127), ('stating', 2128), ('warned', 2129), ('yiu', 2130), ('tht', 2131), ('acknnowledge', 2132), ('stucked', 2133), ('clueless', 2134), ('landmark', 2135), ('global', 2136), ('stream', 2137), ('standup', 2138), ('apv', 2139), ('australia', 2140), ('laakhon', 2141), ('mein', 2142), ('ek', 2143), ('fracking', 2144), ('baby', 2145), ('seals', 2146), ('ecofriendly', 2147), ('subject', 2148), ('addressing', 2149), ('short', 2150), ('larger', 2151), ('prevented', 2152), ('potentially', 2153), ('damaging', 2154), ('breaches', 2155), ('urgent', 2156), ('game', 2157), ('ww', 2158), ('😪', 2159), ('rply', 2160), ('ok', 2161), ('unattended', 2162), ('preference', 2163), ('neighbor', 2164), ('unlock', 2165), ('upset', 2166), ('doubting', 2167), ('map', 2168), ('cheater', 2169), ('somethingso', 2170), ('identify', 2171), ('bits', 2172), ('created', 2173), ('labels', 2174), ('mode', 2175), ('sensitivities', 2176), ('prints', 2177), ('played', 2178), ('everybodys', 2179), ('regret', 2180), ('basis', 2181), ('beacuse', 2182), ('demanding', 2183), ('halloween', 2184), ('psvr', 2185), ('headsets', 2186), ('bundle', 2187), ('refusal', 2188), ('double', 2189), ('pretty', 2190), ('redmi', 2191), ('customercentric', 2192), ('planet', 2193), ('grass', 2194), ('reality', 2195), ('competing', 2196), ('lifetime', 2197), ('mental', 2198), ('elapsed', 2199), ('ats', 2200), ('replacements', 2201), ('raise', 2202), ('metropolitan', 2203), ('currency', 2204), ('resorted', 2205), ('contract', 2206), ('attends', 2207), ('cleared', 2208), ('commercial', 2209), ('break', 2210), ('gettin', 2211), ('supported', 2212), ('addressed', 2213), ('plain', 2214), ('ukcan', 2215), ('hook', 2216), ('dot', 2217), ('installing', 2218), ('avenel', 2219), ('works', 2220), ('fourth', 2221), ('inferior', 2222), ('hv', 2223), ('informatiom', 2224), ('tendered', 2225), ('fr', 2226), ('hs', 2227), ('partially', 2228), ('postit', 2229), ('fridge', 2230), ('reachable', 2231), ('mean', 2232), ('usual', 2233), ('alsi', 2234), ('hike', 2235), ('rupees', 2236), ('preferences', 2237), ('warranty', 2238), ('chain', 2239), ('staff', 2240), ('intervene', 2241), ('body', 2242), ('visited', 2243), ('househow', 2244), ('readyseems', 2245), ('intelligencepl', 2246), ('👍', 2247), ('stacks', 2248), ('strangers', 2249), ('receipts', 2250), ('names', 2251), ('suggest', 2252), ('confidential', 2253), ('possibly', 2254), ('slowly', 2255), ('degrading', 2256), ('themseems', 2257), ('secondly', 2258), ('lodged', 2259), ('separate', 2260), ('decor', 2261), ('category', 2262), ('build', 2263), ('wnt', 2264), ('arrogance', 2265), ('leads', 2266), ('downfall', 2267), ('dys', 2268), ('foramp', 2269), ('wiped', 2270), ('regulation', 2271), ('turning', 2272), ('revision', 2273), ('clarified', 2274), ('supporting', 2275), ('headphone', 2276), ('annoyed', 2277), ('wedding', 2278), ('wow', 2279), ('efficient', 2280), ('pleasantly', 2281), ('swift', 2282), ('oasis', 2283), ('audible', 2284), ('audibles', 2285), ('kindles', 2286), ('bounced', 2287), ('cross', 2288), ('massage', 2289), ('deliveryhow', 2290), ('data', 2291), ('colleagues', 2292), ('lethargic', 2293), ('deteriorating', 2294), ('reset', 2295), ('refunded', 2296), ('mockery', 2297), ('laterin', 2298), ('avoid', 2299), ('buying', 2300), ('somebody', 2301), ('😕', 2302), ('bluffs', 2303), ('sc', 2304), ('buyers', 2305), ('wks', 2306), ('awful', 2307), ('stamped', 2308), ('fraudulent', 2309), ('practices', 2310), ('adjust', 2311), ('prepaid', 2312), ('trained', 2313), ('robots', 2314), ('lakhs', 2315), ('cf', 2316), ('mr', 2317), ('sick', 2318), ('unsatisfactory', 2319), ('losing', 2320), ('sollution', 2321), ('redelivered', 2322), ('gimmick', 2323), ('carried', 2324), ('misguide', 2325), ('damned', 2326), ('ds', 2327), ('tym', 2328), ('act', 2329), ('filthy', 2330), ('pleased', 2331), ('prod', 2332), ('categories', 2333), ('brazil', 2334), ('scratch', 2335), ('teething', 2336), ('childs', 2337), ('melted', 2338), ('experiences', 2339), ('competence', 2340), ('unfair', 2341), ('trade', 2342), ('sadly', 2343), ('buck', 2344), ('connection', 2345), ('path', 2346), ('approx', 2347), ('assure', 2348), ('latter', 2349), ('costume', 2350), ('vivo', 2351), ('shld', 2352), ('proceed', 2353), ('wife', 2354), ('brings', 2355), ('management', 2356), ('screen', 2357), ('guidebook', 2358), ('trip', 2359), ('brother', 2360), ('halifax', 2361), ('destination', 2362), ('humour', 2363), ('middle', 2364), ('bluff', 2365), ('z', 2366), ('dtdc', 2367), ('stole', 2368), ('hardly', 2369), ('legible', 2370), ('untimely', 2371), ('pain', 2372), ('nocost', 2373), ('extremely', 2374), ('complicated', 2375), ('gr', 2376), ('careful', 2377), ('sme', 2378), ('indialack', 2379), ('deposit', 2380), ('store', 2381), ('weirder', 2382), ('blocks', 2383), ('ps', 2384), ('amit', 2385), ('agarwal', 2386), ('competent', 2387), ('head', 2388), ('forum', 2389), ('shippeddelivered', 2390), ('pic', 2391), ('ignore', 2392), ('inability', 2393), ('attach', 2394), ('deduction', 2395), ('easier', 2396), ('signing', 2397), ('updatecontact', 2398), ('thoroughly', 2399), ('displeased', 2400), ('sites', 2401), ('bpl', 2402), ('secure', 2403), ('changing', 2404), ('forth', 2405), ('dropped', 2406), ('functioning', 2407), ('scrap', 2408), ('known', 2409), ('intermittently', 2410), ('coz', 2411), ('typing', 2412), ('hopefully', 2413), ('rang', 2414), ('quickest', 2415), ('futile', 2416), ('filling', 2417), ('concert', 2418), ('innovative', 2419), ('attract', 2420), ('alabama', 2421), ('tonight', 2422), ('rest', 2423), ('shall', 2424), ('bd', 2425), ('approval', 2426), ('parceli', 2427), ('toll', 2428), ('disconnects', 2429), ('grey', 2430), ('crushed', 2431), ('disable', 2432), ('unimpressive', 2433), ('saturdaynd', 2434), ('followed', 2435), ('intention', 2436), ('disturb', 2437), ('faith', 2438), ('refer', 2439), ('deliverdmailed', 2440), ('trap', 2441), ('habit', 2442), ('shocked', 2443), ('offered', 2444), ('bundled', 2445), ('stuffs', 2446), ('self', 2447), ('pune', 2448), ('chakan', 2449), ('delayno', 2450), ('applied', 2451), ('mega', 2452), ('branding', 2453), ('aid', 2454), ('thursday', 2455), ('ref', 2456), ('incorrectu', 2457), ('shippingbilling', 2458), ('problematic', 2459), ('pc', 2460), ('vain', 2461), ('highly', 2462), ('intact', 2463), ('committed', 2464), ('britches', 2465), ('denying', 2466), ('hld', 2467), ('pound', 2468), ('dead', 2469), ('maryland', 2470), ('whole', 2471), ('brilliant', 2472), ('writen', 2473), ('fb', 2474), ('hotline', 2475), ('black', 2476), ('fridayonline', 2477), ('awb', 2478), ('crying', 2479), ('loud', 2480), ('bear', 2481), ('claptrap', 2482), ('serv', 2483), ('yethope', 2484), ('owner', 2485), ('marshall', 2486), ('amzon', 2487), ('intimating', 2488), ('lip', 2489), ('harrassment', 2490), ('arrogant', 2491), ('crap', 2492), ('looong', 2493), ('bck', 2494), ('took', 2495), ('col', 2496), ('happen', 2497), ('relief', 2498), ('hipe', 2499), ('neglect', 2500), ('foam', 2501), ('rubber', 2502), ('associates', 2503), ('recieving', 2504), ('acknowledgement', 2505), ('hes', 2506), ('subscribing', 2507), ('betray', 2508), ('communicating', 2509), ('chargeback', 2510), ('merchant', 2511), ('stereotype', 2512), ('disappoint', 2513), ('topped', 2514), ('suffering', 2515), ('mile', 2516), ('frustratingunhelpful', 2517), ('conv', 2518), ('concerning', 2519), ('unsure', 2520), ('dealt', 2521), ('painful', 2522), ('experienced', 2523), ('renew', 2524), ('rejected', 2525), ('canada', 2526), ('callback', 2527), ('reimbursement', 2528), ('indiapost', 2529), ('shoutout', 2530), ('rashmi', 2531), ('calming', 2532), ('conflicting', 2533), ('nonetheless', 2534), ('decade', 2535), ('waterproof', 2536), ('sweat', 2537), ('wanted', 2538), ('denied', 2539), ('misunderstood', 2540), ('mid', 2541), ('forgotten', 2542), ('suggestion', 2543), ('hardik', 2544), ('patel', 2545), ('saller', 2546), ('paymant', 2547), ('fruitful', 2548), ('impossible', 2549), ('charger', 2550), ('switched', 2551), ('ddr', 2552), ('ram', 2553), ('recieved', 2554), ('difference', 2555), ('jeeze', 2556), ('chill', 2557), ('😂', 2558), ('explanations', 2559), ('employed', 2560), ('expnot', 2561), ('increasing', 2562), ('banged', 2563), ('christmas', 2564), ('tons', 2565), ('backed', 2566), ('specialist', 2567), ('internet', 2568), ('cabin', 2569), ('sep', 2570), ('initiation', 2571), ('deceiving', 2572), ('typically', 2573), ('deliveryresched', 2574), ('packing', 2575), ('torn', 2576), ('tricks', 2577), ('usa', 2578), ('desk', 2579), ('wondering', 2580), ('praise', 2581), ('creating', 2582), ('culture', 2583), ('accessible', 2584), ('templates', 2585), ('fluctuation', 2586), ('tia', 2587), ('evidenceswaited', 2588), ('prescribed', 2589), ('instructed', 2590), ('brand', 2591), ('realise', 2592), ('attached', 2593), ('supplier', 2594), ('angry', 2595), ('disregard', 2596), ('mic', 2597), ('smartcheck', 2598), ('invalid', 2599), ('psp', 2600), ('pro', 2601), ('chasing', 2602), ('valid', 2603), ('admit', 2604), ('supp', 2605), ('factor', 2606), ('auth', 2607), ('noreply', 2608), ('choose', 2609), ('platform', 2610), ('constantly', 2611), ('liquid', 2612), ('zs', 2613), ('deleted', 2614), ('retry', 2615), ('assumption', 2616), ('messed', 2617), ('otp', 2618), ('shops', 2619), ('tweeting', 2620), ('sheet', 2621), ('pad', 2622), ('setting', 2623), ('organization', 2624), ('shameful', 2625), ('appears', 2626), ('proceeded', 2627), ('multiorder', 2628), ('receipt', 2629), ('treatment', 2630), ('handles', 2631), ('lockers', 2632), ('loot', 2633), ('peoplebig', 2634), ('hats', 2635), ('recd', 2636), ('difficult', 2637), ('ownership', 2638), ('fuming', 2639), ('several', 2640), ('suffer', 2641), ('cuz', 2642), ('prority', 2643), ('mostly', 2644), ('cudnt', 2645), ('trapped', 2646), ('recordwhos', 2647), ('drinking', 2648), ('thinga', 2649), ('cameras', 2650), ('ring', 2651), ('memory', 2652), ('except', 2653), ('dollar', 2654), ('mi', 2655), ('choosing', 2656), ('insecure', 2657), ('offering', 2658), ('yep', 2659), ('approaching', 2660), ('bookings', 2661), ('matter', 2662), ('bw', 2663), ('pace', 2664), ('incident', 2665), ('vacation', 2666), ('occasions', 2667), ('hiding', 2668), ('plot', 2669), ('comes', 2670), ('ensure', 2671), ('honoured', 2672), ('wallet', 2673), ('loose', 2674), ('embarassed', 2675), ('amazonamp', 2676), ('experinece', 2677), ('inflicted', 2678), ('costed', 2679), ('swiping', 2680), ('serious', 2681), ('strict', 2682), ('mood', 2683), ('surely', 2684), ('peopleitz', 2685), ('advisor', 2686), ('class', 2687), ('asleep', 2688), ('tactics', 2689), ('task', 2690), ('addresses', 2691), ('predictably', 2692), ('fifth', 2693), ('documents', 2694), ('auto', 2695), ('nw', 2696), ('plyng', 2697), ('cn', 2698), ('url', 2699), ('intiated', 2700), ('informing', 2701), ('tiny', 2702), ('highlighted', 2703), ('surprise', 2704), ('flop', 2705), ('movie', 2706), ('upload', 2707), ('tip', 2708), ('previous', 2709), ('reinvestigating', 2710), ('dt', 2711), ('reqst', 2712), ('reduced', 2713), ('wishlist', 2714), ('drive', 2715), ('clicks', 2716), ('addition', 2717), ('detailed', 2718), ('forwarded', 2719), ('royally', 2720), ('stuffed', 2721), ('ages', 2722), ('illegal', 2723), ('released', 2724), ('warn', 2725), ('noticed', 2726), ('gave', 2727), ('conclusion', 2728), ('moreover', 2729), ('regions', 2730), ('frauding', 2731), ('increases', 2732), ('wen', 2733), ('literally', 2734), ('watching', 2735), ('hire', 2736), ('decent', 2737), ('manning', 2738), ('line', 2739), ('submit', 2740), ('ticket', 2741), ('whatsoever', 2742), ('cat', 2743), ('poop', 2744), ('botched', 2745), ('shit', 2746), ('together', 2747), ('reputation', 2748), ('cd', 2749), ('magazines', 2750), ('thnx', 2751), ('shoppng', 2752), ('eye', 2753), ('opener', 2754), ('promote', 2755), ('whch', 2756), ('dnt', 2757), ('tryna', 2758), ('wards', 2759), ('hand', 2760), ('heart', 2761), ('standards', 2762), ('nailing', 2763), ('release', 2764), ('atleast', 2765), ('increase', 2766), ('decide', 2767), ('hungup', 2768), ('brag', 2769), ('spam', 2770), ('bookmyshow', 2771), ('egv', 2772), ('continuously', 2773), ('h', 2774), ('states', 2775), ('norwegian', 2776), ('audio', 2777), ('cast', 2778), ('unpredictable', 2779), ('killing', 2780), ('okpls', 2781), ('donewent', 2782), ('idscustomer', 2783), ('profile', 2784), ('f', 2785), ('deliverd', 2786), ('logging', 2787), ('landlord', 2788), ('outcome', 2789), ('hm', 2790), ('intriguing', 2791), ('playlists', 2792), ('fulfilling', 2793), ('specifically', 2794), ('insight', 2795), ('yeah', 2796), ('parts', 2797), ('broke', 2798), ('fly', 2799), ('mechanic', 2800), ('web', 2801), ('rectify', 2802), ('moneyshould', 2803), ('daysstill', 2804), ('spain', 2805), ('checking', 2806), ('fails', 2807), ('exchanging', 2808), ('shoes', 2809), ('brief', 2810), ('hesitant', 2811), ('completely', 2812), ('wpast', 2813), ('canclling', 2814), ('psa', 2815), ('clever', 2816), ('become', 2817), ('upon', 2818), ('renewal', 2819), ('inch', 2820), ('thick', 2821), ('mattress', 2822), ('unresolved', 2823), ('among', 2824), ('updating', 2825), ('axis', 2826), ('debited', 2827), ('search', 2828), ('mov', 2829), ('fyi', 2830), ('delvry', 2831), ('attmpt', 2832), ('den', 2833), ('txt', 2834), ('sayn', 2835), ('bring', 2836), ('eco', 2837), ('spot', 2838), ('recorded', 2839), ('andbrheybdenied', 2840), ('instruction', 2841), ('oh', 2842), ('apologised', 2843), ('lying', 2844), ('whereas', 2845), ('idiot', 2846), ('copycat', 2847), ('moron', 2848), ('suppose', 2849), ('tools', 2850), ('immediately', 2851), ('antiquated', 2852), ('zef', 2853), ('basics', 2854), ('lightning', 2855), ('sticker', 2856), ('serial', 2857), ('completion', 2858), ('standing', 2859), ('screw', 2860), ('nondelivery', 2861), ('seperately', 2862), ('sbi', 2863), ('closing', 2864), ('conniving', 2865), ('compassionate', 2866), ('gesture', 2867), ('fad', 2868), ('ruthless', 2869), ('dumbest', 2870), ('nither', 2871), ('co', 2872), ('initially', 2873), ('reordering', 2874), ('suddenly', 2875), ('fragile', 2876), ('thinks', 2877), ('reviewing', 2878), ('photos', 2879), ('ricoh', 2880), ('sn', 2881), ('relations', 2882), ('unsecured', 2883), ('seeds', 2884), ('direct', 2885), ('huts', 2886), ('dignity', 2887), ('independence', 2888), ('subsistence', 2889), ('farmers', 2890), ('thief', 2891), ('patheticno', 2892), ('adde', 2893), ('appliances', 2894), ('shakes', 2895), ('confidence', 2896), ('covered', 2897), ('chk', 2898), ('creditcardi', 2899), ('blank', 2900), ('truly', 2901), ('authorization', 2902), ('mailing', 2903), ('pack', 2904), ('shocker', 2905), ('target', 2906), ('achievement', 2907), ('joined', 2908), ('organisation', 2909), ('ow', 2910), ('nr', 2911), ('reinstall', 2912), ('style', 2913), ('pdt', 2914), ('thricebut', 2915), ('existing', 2916), ('insult', 2917), ('injury', 2918), ('basically', 2919), ('frankly', 2920), ('angered', 2921), ('experiencedyou', 2922), ('⭐', 2923), ('❗', 2924), ('atrocious', 2925), ('locally', 2926), ('breath', 2927), ('ser', 2928), ('hub', 2929), ('understanding', 2930), ('convince', 2931), ('husband', 2932), ('micromax', 2933), ('ke', 2934), ('wale', 2935), ('dabbe', 2936), ('kewal', 2937), ('chargerdabba', 2938), ('khali', 2939), ('bina', 2940), ('wo', 2941), ('accessories', 2942), ('replacementrefund', 2943), ('docafe', 2944), ('filtering', 2945), ('hardcore', 2946), ('lover', 2947), ('paperwhite', 2948), ('faq', 2949), ('disconnected', 2950), ('properly', 2951), ('😒', 2952), ('scenarios', 2953), ('dispute', 2954), ('somethingmy', 2955), ('mom', 2956), ('automatically', 2957), ('scared', 2958), ('decency', 2959), ('escalating', 2960), ('tight', 2961), ('rough', 2962), ('compny', 2963), ('dis', 2964), ('users', 2965), ('register', 2966), ('obtain', 2967), ('research', 2968), ('puerto', 2969), ('rico', 2970), ('amazonseller', 2971), ('feature', 2972), ('producti', 2973), ('workingpoor', 2974), ('engineer', 2975), ('denies', 2976), ('thrown', 2977), ('envelopes', 2978), ('packaged', 2979), ('demand', 2980), ('ah', 2981), ('bin', 2982), ('indeed', 2983), ('treated', 2984), ('international', 2985), ('vcc', 2986), ('tb', 2987), ('firecuda', 2988), ('nas', 2989), ('pretend', 2990), ('safety', 2991), ('argued', 2992), ('opcancelling', 2993), ('membershipfeel', 2994), ('virus', 2995), ('downloading', 2996), ('invent', 2997), ('apply', 2998), ('activate', 2999), ('reminds', 3000), ('airport', 3001), ('towards', 3002), ('holy', 3003), ('cow', 3004), ('ball', 3005), ('instant', 3006), ('gratification', 3007), ('dangerzone', 3008), ('gst', 3009), ('hsn', 3010), ('moltul', 3011), ('mobil', 3012), ('oil', 3013), ('🤔', 3014), ('complains', 3015), ('yday', 3016), ('diasater', 3017), ('verify', 3018), ('serviceu', 3019), ('issuecant', 3020), ('satisfy', 3021), ('servicehighly', 3022), ('verified', 3023), ('mind', 3024), ('✌', 3025), ('citing', 3026), ('justice', 3027), ('bottomline', 3028), ('mercy', 3029), ('paste', 3030), ('tweeted', 3031), ('nah', 3032), ('vikas', 3033), ('thakur', 3034), ('located', 3035), ('earpod', 3036), ('hp', 3037), ('firefox', 3038), ('pictures', 3039), ('commandeered', 3040), ('moto', 3041), ('g', 3042), ('mobilebut', 3043), ('translation', 3044), ('hilariously', 3045), ('messing', 3046), ('reminded', 3047), ('unheard', 3048), ('knowing', 3049), ('🙄', 3050), ('nonprime', 3051), ('preparing', 3052), ('pampers', 3053), ('premium', 3054), ('taille', 3055), ('diapers', 3056), ('delviering', 3057), ('stooped', 3058), ('elderly', 3059), ('peoplecompanies', 3060), ('stopping', 3061), ('eyeliner', 3062), ('rubbish', 3063), ('chor', 3064), ('companies', 3065), ('suits', 3066), ('consistent', 3067), ('wlisting', 3068), ('inputs', 3069), ('randomly', 3070), ('redeem', 3071), ('top', 3072), ('severe', 3073), ('indicate', 3074), ('blog', 3075), ('color', 3076), ('smaller', 3077), ('kyon', 3078), ('karate', 3079), ('ho', 3080), ('yaar', 3081), ('notmy', 3082), ('helpless', 3083), ('loaded', 3084), ('defaulted', 3085), ('default', 3086), ('mins', 3087), ('wednesday', 3088), ('heck', 3089), ('orderd', 3090), ('tenor', 3091), ('denial', 3092), ('yeahh', 3093), ('mondays', 3094), ('lashonta', 3095), ('preaching', 3096), ('💯', 3097), ('falsely', 3098), ('amex', 3099), ('transaction', 3100), ('humans', 3101), ('perhaps', 3102), ('explains', 3103), ('okay', 3104), ('steel', 3105), ('torch', 3106), ('switch', 3107), ('unpacking', 3108), ('contacts', 3109), ('places', 3110), ('blatant', 3111), ('compelled', 3112), ('hopeless', 3113), ('planning', 3114), ('jus', 3115), ('oneplus', 3116), ('issueauto', 3117), ('fucking', 3118), ('delver', 3119), ('avialable', 3120), ('oneliner', 3121), ('froze', 3122), ('prouduct', 3123), ('fit', 3124), ('reclaim', 3125), ('nearing', 3126), ('expiry', 3127), ('moves', 3128), ('distance', 3129), ('opposite', 3130), ('pointing', 3131), ('ugly', 3132), ('evn', 3133), ('bothrd', 3134), ('cal', 3135), ('knw', 3136), ('wat', 3137), ('ws', 3138), ('rplying', 3139), ('alwys', 3140), ('humane', 3141), ('shoe', 3142), ('priced', 3143), ('atm', 3144), ('laughing', 3145), ('shouting', 3146), ('swearing', 3147), ('background', 3148), ('hurts', 3149), ('richman', 3150), ('unanswered', 3151), ('pity', 3152), ('state', 3153), ('deadlock', 3154), ('master', 3155), ('ac', 3156), ('cooler', 3157), ('shalu', 3158), ('belt', 3159), ('small', 3160), ('argue', 3161), ('recordings', 3162), ('export', 3163), ('llc', 3164), ('africa', 3165), ('records', 3166), ('timing', 3167), ('board', 3168), ('oneday', 3169), ('crucial', 3170), ('wig', 3171), ('calendar', 3172), ('rounds', 3173), ('benefits', 3174), ('politely', 3175), ('tf', 3176), ('install', 3177), ('cache', 3178), ('probably', 3179), ('loader', 3180), ('overlapping', 3181), ('believed', 3182), ('fashion', 3183), ('youth', 3184), ('romantic', 3185), ('comedy', 3186), ('vol', 3187), ('light', 3188), ('novel', 3189), ('pillows', 3190), ('farming', 3191), ('miles', 3192), ('minutesreceiving', 3193), ('refunding', 3194), ('falty', 3195), ('dropping', 3196), ('timelines', 3197), ('del', 3198), ('slips', 3199), ('weybridge', 3200), ('behaving', 3201), ('rudely', 3202), ('launch', 3203), ('mentioning', 3204), ('oriented', 3205), ('orelse', 3206), ('tenure', 3207), ('luxembourg', 3208), ('exists', 3209), ('zip', 3210), ('phd', 3211), ('unrelated', 3212), ('common', 3213), ('widout', 3214), ('favourite', 3215), ('french', 3216), ('grer', 3217), ('vos', 3218), ('abonnements', 3219), ('shits', 3220), ('wary', 3221), ('emotional', 3222), ('p', 3223), ('ltd', 3224), ('thankeew', 3225), ('shortly', 3226), ('idiots', 3227), ('exclude', 3228), ('remerber', 3229), ('hacker', 3230), ('sleep', 3231), ('ignoring', 3232), ('yrs', 3233), ('lg', 3234), ('perfect', 3235), ('correspond', 3236), ('kuddos', 3237), ('frauded', 3238), ('reauthorise', 3239), ('effort', 3240), ('hunt', 3241), ('kdp', 3242), ('shitshow', 3243), ('rspc', 3244), ('forwarding', 3245), ('knife', 3246), ('toothpaste', 3247), ('thermometer', 3248), ('bluetooth', 3249), ('beanies', 3250), ('mens', 3251), ('antenna', 3252), ('laundry', 3253), ('bags', 3254), ('cords', 3255), ('stocknis', 3256), ('band', 3257), ('flickering', 3258), ('sometime', 3259), ('unresponsive', 3260), ('v', 3261), ('unhappy', 3262), ('onus', 3263), ('tax', 3264), ('recommend', 3265), ('concierge', 3266), ('entry', 3267), ('zero', 3268), ('resolutions', 3269), ('lacking', 3270), ('publisher', 3271), ('responsegood', 3272), ('incoming', 3273), ('pr', 3274), ('kr', 3275), ('rhe', 3276), ('kuch', 3277), ('koi', 3278), ('aurwhat', 3279), ('legitimate', 3280), ('temporarily', 3281), ('reactivate', 3282), ('blah', 3283), ('squeeze', 3284), ('shipoment', 3285), ('prompted', 3286), ('comments', 3287), ('rmail', 3288), ('counting', 3289), ('fulfill', 3290), ('malfunctioning', 3291), ('arduous', 3292), ('philips', 3293), ('trimmer', 3294), ('niva', 3295), ('earths', 3296), ('customerfriendly', 3297), ('unmoved', 3298), ('wana', 3299), ('salute', 3300), ('finger', 3301), ('approximately', 3302), ('overcharging', 3303), ('disaster', 3304), ('ad', 3305), ('deactivated', 3306), ('entering', 3307), ('performance', 3308), ('manned', 3309), ('awaited', 3310), ('booked', 3311), ('followups', 3312), ('teach', 3313), ('september', 3314), ('smartphone', 3315), ('lessor', 3316), ('directs', 3317), ('um', 3318), ('bloody', 3319), ('froud', 3320), ('heads', 3321), ('jkasdfjkjkjkljklsdfnmdfmngdsnfgmdsgnsdjklgnkljdfgkldfjgsdfkl', 3322), ('disclaimer', 3323), ('bureaucratic', 3324), ('playing', 3325), ('comm', 3326), ('brands', 3327), ('supplemented', 3328), ('surepost', 3329), ('anyi', 3330), ('soc', 3331), ('mmbr', 3332), ('gowthamhe', 3333), ('yo', 3334), ('allows', 3335), ('understatement', 3336), ('term', 3337), ('solely', 3338), ('holding', 3339), ('responds', 3340), ('vat', 3341), ('teachrequire', 3342), ('truth', 3343), ('wrongly', 3344), ('rebook', 3345), ('paytm', 3346), ('harrassing', 3347), ('ten', 3348), ('expired', 3349), ('providers', 3350), ('mnc', 3351), ('indepth', 3352), ('excellent', 3353), ('glad', 3354), ('🤫', 3355), ('hr', 3356), ('flight', 3357), ('paris', 3358), ('sake', 3359), ('discrepancy', 3360), ('glitched', 3361), ('😫', 3362), ('appropriated', 3363), ('proposed', 3364), ('chatting', 3365), ('implement', 3366), ('advertisements', 3367), ('focused', 3368), ('inevitable', 3369), ('profits', 3370), ('focusing', 3371), ('requirements', 3372), ('suggested', 3373), ('distressing', 3374), ('reflects', 3375), ('badly', 3376), ('nxt', 3377), ('agn', 3378), ('difrnt', 3379), ('glitches', 3380), ('showed', 3381), ('mention', 3382), ('broadband', 3383), ('provider', 3384), ('screwed', 3385), ('squashing', 3386), ('consequences', 3387), ('deborah', 3388), ('dicrespectful', 3389), ('entered', 3390), ('flat', 3391), ('advice', 3392), ('preorder', 3393), ('jobs', 3394), ('completing', 3395), ('survey', 3396), ('android', 3397), ('chrome', 3398), ('ebt', 3399), ('ssi', 3400), ('seconds', 3401), ('unacceptable', 3402), ('pckg', 3403), ('declared', 3404), ('furtheris', 3405), ('ebay', 3406), ('hiring', 3407), ('avid', 3408), ('btwn', 3409), ('hav', 3410), ('sameday', 3411), ('market', 3412), ('lowered', 3413), ('searched', 3414), ('neighborhood', 3415), ('misdelivered', 3416), ('remote', 3417), ('speaks', 3418), ('finding', 3419), ('photo', 3420), ('disrespectful', 3421), ('benn', 3422), ('kaisy', 3423), ('reexplaining', 3424), ('transferred', 3425), ('postage', 3426), ('position', 3427), ('yearly', 3428), ('operated', 3429), ('powers', 3430), ('accountable', 3431), ('seeing', 3432), ('permanent', 3433), ('giant', 3434), ('₹', 3435), ('liar', 3436), ('favorable', 3437), ('dumb', 3438), ('managed', 3439), ('whoever', 3440), ('insist', 3441), ('moms', 3442), ('womb', 3443), ('ugh', 3444), ('sth', 3445), ('noon', 3446), ('patronised', 3447), ('surprising', 3448), ('stth', 3449), ('necessary', 3450), ('doa', 3451), ('bouncing', 3452), ('padded', 3453), ('envelope', 3454), ('sigh', 3455), ('appear', 3456), ('confiscates', 3457), ('pdf', 3458), ('closure', 3459), ('kms', 3460), ('luks', 3461), ('walking', 3462), ('sheesh', 3463), ('fuzzy', 3464), ('scott', 3465), ('reservoir', 3466), ('aap', 3467), ('pe', 3468), ('nai', 3469), ('sakte', 3470), ('mere', 3471), ('kar', 3472), ('perfection', 3473), ('upsusps', 3474), ('pigeon', 3475), ('travel', 3476), ('morrow', 3477), ('activating', 3478), ('oid', 3479), ('station', 3480), ('fuck', 3481), ('frozen', 3482), ('fully', 3483), ('violating', 3484), ('courage', 3485), ('bether', 3486), ('competed', 3487), ('clearer', 3488), ('reject', 3489), ('strictly', 3490), ('reviewed', 3491), ('prepare', 3492), ('spare', 3493), ('room', 3494), ('moved', 3495), ('neighbors', 3496), ('developers', 3497), ('inclusive', 3498), ('taxes', 3499), ('deliverable', 3500), ('ones', 3501), ('colleges', 3502), ('sumithra', 3503), ('thomas', 3504), ('pass', 3505), ('coach', 3506), ('rain', 3507), ('shoppers', 3508), ('feedbacks', 3509), ('acted', 3510), ('friendss', 3511), ('expectedthe', 3512), ('transport', 3513), ('equally', 3514), ('hearing', 3515), ('midnight', 3516), ('deadline', 3517), ('foolish', 3518), ('honest', 3519), ('restaurant', 3520), ('unreliable', 3521), ('hd', 3522), ('jere', 3523), ('inside', 3524), ('fianc', 3525), ('medical', 3526), ('equipment', 3527), ('breathe', 3528), ('depending', 3529), ('batteries', 3530), ('ky', 3531), ('ue', 3532), ('yr', 3533), ('stopped', 3534), ('screwing', 3535), ('ratio', 3536), ('blunders', 3537), ('answerable', 3538), ('hide', 3539), ('vanished', 3540), ('void', 3541), ('apologetic', 3542), ('displayed', 3543), ('hoping', 3544), ('exploded', 3545), ('shower', 3546), ('gel', 3547), ('overnighted', 3548), ('contracted', 3549), ('traditional', 3550), ('maintain', 3551), ('ripped', 3552), ('con', 3553), ('router', 3554), ('girl', 3555), ('utter', 3556), ('nuisance', 3557), ('beggars', 3558), ('published', 3559), ('silver', 3560), ('spoon', 3561), ('anime', 3562), ('entertain', 3563), ('scenario', 3564), ('expectation', 3565), ('thn', 3566), ('drains', 3567), ('overall', 3568), ('jan', 3569), ('execs', 3570), ('private', 3571), ('comfortable', 3572), ('publicly', 3573), ('meant', 3574), ('teamsad', 3575), ('advertisement', 3576), ('snapshot', 3577), ('peterboroughuk', 3578), ('phishing', 3579), ('untrained', 3580), ('excited', 3581), ('anxiously', 3582), ('horrifying', 3583), ('nevertheless', 3584), ('dishonest', 3585), ('setup', 3586), ('snap', 3587), ('shots', 3588), ('creepy', 3589), ('automatic', 3590), ('obvious', 3591), ('pswd', 3592), ('forgot', 3593), ('err', 3594), ('tsup', 3595), ('met', 3596), ('sat', 3597), ('tue', 3598), ('alerted', 3599), ('beta', 3600), ('subtitle', 3601), ('unaware', 3602), ('primeim', 3603), ('acc', 3604), ('ph', 3605), ('removed', 3606), ('blackberry', 3607), ('keyone', 3608), ('galaxy', 3609), ('contests', 3610), ('usd', 3611), ('gbp', 3612), ('dimension', 3613), ('weight', 3614), ('limits', 3615), ('unboxed', 3616), ('mad', 3617), ('ipad', 3618), ('landscape', 3619), ('latest', 3620), ('tie', 3621), ('downright', 3622), ('silly', 3623), ('forwards', 3624), ('tedious', 3625), ('potential', 3626), ('hostingcloud', 3627), ('presume', 3628), ('behalf', 3629), ('prealpha', 3630), ('tester', 3631), ('greiverances', 3632), ('weak', 3633), ('bird', 3634), ('improved', 3635), ('😩', 3636), ('complicate', 3637), ('delever', 3638), ('announce', 3639), ('outdated', 3640), ('bhupendra', 3641), ('disconnect', 3642), ('often', 3643), ('eventually', 3644), ('✅', 3645), ('lower', 3646), ('diary', 3647), ('misplaced', 3648), ('quibble', 3649), ('inform', 3650), ('aquaguard', 3651), ('purifier', 3652), ('mar', 3653), ('educational', 3654), ('avoided', 3655), ('five', 3656), ('propose', 3657), ('including', 3658), ('projection', 3659), ('todaybut', 3660), ('debitcredit', 3661), ('putting', 3662), ('clauses', 3663), ('customergood', 3664), ('🙏', 3665), ('dual', 3666), ('rslost', 3667), ('apology', 3668), ('qualify', 3669), ('template', 3670), ('cr', 3671), ('washing', 3672), ('redressal', 3673), ('bar', 3674), ('desactivated', 3675), ('hectic', 3676), ('ordr', 3677), ('dogs', 3678), ('directions', 3679), ('hidden', 3680), ('filing', 3681), ('symbol', 3682), ('waits', 3683), ('arrives', 3684), ('decides', 3685), ('resend', 3686), ('besides', 3687), ('redelivery', 3688), ('ie', 3689), ('cafely', 3690), ('lasership', 3691), ('lazy', 3692), ('witnessed', 3693), ('throwing', 3694), ('choked', 3695), ('handy', 3696), ('thumbs', 3697), ('aggravated', 3698), ('amazonuk', 3699), ('leaving', 3700), ('sour', 3701), ('taste', 3702), ('mouth', 3703), ('blocking', 3704), ('tolerated', 3705), ('responses', 3706), ('plans', 3707), ('shout', 3708), ('verifying', 3709), ('waking', 3710), ('piss', 3711), ('hack', 3712), ('woeful', 3713), ('valued', 3714), ('sums', 3715), ('techie', 3716), ('reward', 3717), ('dealsand', 3718), ('primeif', 3719), ('hdd', 3720), ('initiate', 3721), ('pushing', 3722), ('hk', 3723), ('belgium', 3724), ('overnight', 3725), ('anybody', 3726), ('flex', 3727), ('yestrday', 3728), ('deliverywill', 3729), ('compensate', 3730), ('professional', 3731), ('popup', 3732), ('banned', 3733), ('although', 3734), ('´', 3735), ('ink', 3736), ('ruined', 3737), ('effective', 3738), ('tat', 3739), ('submitting', 3740), ('iv', 3741), ('tagging', 3742), ('mystery', 3743), ('unpleasant', 3744), ('exprerience', 3745), ('goofed', 3746), ('occasionyou', 3747), ('dumped', 3748), ('bins', 3749), ('doors', 3750), ('guysvery', 3751), ('harrasment', 3752), ('loops', 3753), ('lecture', 3754), ('leadership', 3755), ('rapidly', 3756), ('professionally', 3757), ('walked', 3758), ('china', 3759), ('avaliable', 3760), ('lemon', 3761), ('caring', 3762), ('running', 3763), ('directional', 3764), ('thrujust', 3765), ('lots', 3766), ('preordered', 3767), ('became', 3768), ('whoes', 3769), ('twitch', 3770), ('tryst', 3771), ('ruining', 3772), ('legit', 3773), ('refundi', 3774), ('onwards', 3775), ('issuepure', 3776), ('ignorance', 3777), ('serviceampinstallation', 3778), ('stopreturn', 3779), ('defected', 3780), ('operators', 3781), ('listened', 3782), ('systems', 3783), ('pst', 3784), ('quick', 3785), ('decisive', 3786), ('restrictive', 3787), ('subsciptions', 3788), ('subscibe', 3789), ('bon', 3790), ('jovi', 3791), ('priority', 3792), ('tablet', 3793), ('jst', 3794), ('nowits', 3795), ('protective', 3796), ('padding', 3797), ('dispatch', 3798), ('trail', 3799), ('redirect', 3800), ('vishal', 3801), ('yadav', 3802), ('harsheen', 3803), ('ab', 3804), ('extreme', 3805), ('gym', 3806), ('equipmenti', 3807), ('welcoming', 3808), ('games', 3809), ('air', 3810), ('lst', 3811), ('shooping', 3812), ('preferred', 3813), ('todaysays', 3814), ('deliveryreturned', 3815), ('president', 3816), ('sit', 3817), ('involving', 3818), ('mt', 3819), ('curious', 3820), ('wallets', 3821), ('success', 3822), ('mastercard', 3823), ('bug', 3824), ('adds', 3825), ('pun', 3826), ('confuse', 3827), ('indicated', 3828), ('striked', 3829), ('hilarious', 3830), ('cb', 3831), ('claimed', 3832), ('issuer', 3833), ('liereceived', 3834), ('dispersed', 3835), ('malta', 3836), ('lehigh', 3837), ('valley', 3838), ('costumer', 3839), ('dumbness', 3840), ('startling', 3841), ('rigid', 3842), ('realis', 3843), ('tic', 3844), ('secured', 3845), ('refrigerator', 3846), ('behind', 3847), ('dedicated', 3848), ('aramax', 3849), ('engaged', 3850), ('exchanges', 3851), ('openly', 3852), ('intentional', 3853), ('isolated', 3854), ('shitty', 3855), ('companyyou', 3856), ('test', 3857), ('pigeons', 3858), ('prefect', 3859), ('drone', 3860), ('dream', 3861), ('😍', 3862), ('policies', 3863), ('toy', 3864), ('dries', 3865), ('switchboard', 3866), ('extension', 3867), ('flase', 3868), ('mediocre', 3869), ('avail', 3870), ('escaped', 3871), ('dispatching', 3872), ('datetwice', 3873), ('clarification', 3874), ('bribe', 3875), ('versed', 3876), ('strongly', 3877), ('ve', 3878), ('declineing', 3879), ('raising', 3880), ('trackedyou', 3881), ('king', 3882), ('towers', 3883), ('pi', 3884), ('rescinded', 3885), ('photographs', 3886), ('thks', 3887), ('boat', 3888), ('shipper', 3889), ('predict', 3890), ('near', 3891), ('daughter', 3892), ('starting', 3893), ('described', 3894), ('disillusioned', 3895), ('lisiting', 3896), ('inactive', 3897), ('birminghams', 3898), ('julie', 3899), ('lately', 3900), ('perishables', 3901), ('inconvenience', 3902), ('caused', 3903), ('replcmnt', 3904), ('walnut', 3905), ('unsuitable', 3906), ('hole', 3907), ('nothingness', 3908), ('challenging', 3909), ('toldme', 3910), ('acknowledging', 3911), ('timeframe', 3912), ('congratulations', 3913), ('joining', 3914), ('desired', 3915), ('hyundai', 3916), ('electric', 3917), ('kettle', 3918), ('incomplete', 3919), ('setpower', 3920), ('base', 3921), ('neverending', 3922), ('pursuing', 3923), ('specialists', 3924), ('attachment', 3925), ('robbed', 3926), ('definitely', 3927), ('financial', 3928), ('wear', 3929), ('weather', 3930), ('amazonsuch', 3931), ('pathatic', 3932), ('stsfc', 3933), ('dealer', 3934), ('undetermined', 3935), ('thth', 3936), ('supervisormanager', 3937), ('amounting', 3938), ('idiotacy', 3939), ('stalling', 3940), ('continuation', 3941), ('ordeal', 3942), ('difficulty', 3943), ('advertised', 3944), ('await', 3945), ('digits', 3946), ('facebook', 3947), ('exploiting', 3948), ('pause', 3949), ('custommer', 3950), ('law', 3951), ('untile', 3952), ('deling', 3953), ('secent', 3954), ('begining', 3955), ('shock', 3956), ('fled', 3957), ('scene', 3958), ('insurance', 3959), ('reluctant', 3960), ('num', 3961), ('suspicious', 3962), ('activity', 3963), ('personally', 3964), ('dianne', 3965), ('invite', 3966), ('maintaining', 3967), ('integrity', 3968), ('phonehelp', 3969), ('fucked', 3970), ('couldbut', 3971), ('verificationwhich', 3972), ('mandatory', 3973), ('pos', 3974), ('inventory', 3975), ('dropship', 3976), ('arghhh', 3977), ('vary', 3978), ('tag', 3979), ('buks', 3980), ('wd', 3981), ('furniture', 3982), ('assembly', 3983), ('heavy', 3984), ('holidays', 3985), ('barred', 3986), ('supportwhats', 3987), ('dirt', 3988), ('marks', 3989), ('bajaj', 3990), ('finserv', 3991), ('oneplust', 3992), ('solutioni', 3993), ('doubled', 3994), ('srvice', 3995), ('towels', 3996), ('straws', 3997), ('gravy', 3998), ('strainer', 3999), ('sig', 4000), ('upheld', 4001), ('recevd', 4002), ('mai', 4003), ('conclude', 4004), ('whoa', 4005), ('thrs', 4006), ('waitlist', 4007), ('smthings', 4008), ('nth', 4009), ('dialog', 4010), ('pattern', 4011), ('official', 4012), ('rupay', 4013), ('navigational', 4014), ('restarted', 4015), ('talks', 4016), ('kick', 4017), ('originally', 4018), ('nine', 4019), ('claims', 4020), ('fun', 4021), ('uhhhgg', 4022), ('updateaction', 4023), ('ther', 4024), ('♂', 4025), ('🤦', 4026), ('trial', 4027), ('irony', 4028), ('discnt', 4029), ('promising', 4030), ('echos', 4031), ('stereo', 4032), ('santa', 4033), ('clause', 4034), ('lifesucking', 4035), ('geneva', 4036), ('convention', 4037), ('probs', 4038), ('headzup', 4039), ('posting', 4040), ('annoy', 4041), ('stillfeeling', 4042), ('agreed', 4043), ('somewhat', 4044), ('disingenuous', 4045), ('po', 4046), ('opinion', 4047), ('died', 4048), ('patna', 4049), ('exhibition', 4050), ('road', 4051), ('orderfinally', 4052), ('par', 4053), ('whining', 4054), ('elaborate', 4055), ('intensionally', 4056), ('wht', 4057), ('beenn', 4058), ('looted', 4059), ('lyf', 4060), ('pleasure', 4061), ('pics', 4062), ('stood', 4063), ('pulled', 4064), ('assistants', 4065), ('regional', 4066), ('loosing', 4067), ('faxing', 4068), ('aampe', 4069), ('picnic', 4070), ('decorative', 4071), ('cane', 4072), ('multipurpose', 4073), ('fruits', 4074), ('vegetables', 4075), ('occasion', 4076), ('apparent', 4077), ('corner', 4078), ('dissapoint', 4079), ('thattheir', 4080), ('horror', 4081), ('purchasingcancel', 4082), ('receivd', 4083), ('counter', 4084), ('facts', 4085), ('incidence', 4086), ('duped', 4087), ('appeal', 4088), ('dussapointing', 4089), ('listens', 4090), ('documented', 4091), ('isolation', 4092), ('ummno', 4093), ('gap', 4094), ('competitors', 4095), ('vouchers', 4096), ('xiaomi', 4097), ('fans', 4098), ('resp', 4099), ('tough', 4100), ('mysteriously', 4101), ('curiosity', 4102), ('scraped', 4103), ('unusual', 4104), ('cite', 4105), ('pendrive', 4106), ('bhopal', 4107), ('mever', 4108), ('csr', 4109), ('agreement', 4110), ('hassles', 4111), ('trucks', 4112), ('driving', 4113), ('evade', 4114), ('tolls', 4115), ('😟', 4116), ('script', 4117), ('grotesque', 4118), ('accent', 4119), ('unbearable', 4120), ('lists', 4121), ('therefore', 4122), ('living', 4123), ('street', 4124), ('blast', 4125), ('stranger', 4126), ('singing', 4127), ('song', 4128), ('refundedwht', 4129), ('sealed', 4130), ('kill', 4131), ('restart', 4132), ('flatmate', 4133), ('subtitles', 4134), ('convoluted', 4135), ('dark', 4136), ('dsnt', 4137), ('worked', 4138), ('beyond', 4139), ('becoming', 4140), ('justify', 4141), ('seperate', 4142), ('twoday', 4143), ('videos', 4144), ('screws', 4145), ('hookup', 4146), ('supposedly', 4147), ('gs', 4148), ('contains', 4149), ('compmsd', 4150), ('mebrshp', 4151), ('cloud', 4152), ('reader', 4153), ('linux', 4154), ('wine', 4155), ('damnedest', 4156), ('failure', 4157), ('ko', 4158), ('karne', 4159), ('bhi', 4160), ('vaale', 4161), ('ya', 4162), ('ye', 4163), ('bnaya', 4164), ('hai', 4165), ('ki', 4166), ('baar', 4167), ('yehi', 4168), ('dena', 4169), ('fired', 4170), ('honeymoon', 4171), ('aaked', 4172), ('bolke', 4173), ('bhejoge', 4174), ('kya', 4175), ('residents', 4176), ('cia', 4177), ('nodal', 4178), ('particularly', 4179), ('gold', 4180), ('seam', 4181), ('stumble', 4182), ('rectified', 4183), ('chapter', 4184), ('tata', 4185), ('coffee', 4186), ('grand', 4187), ('providedall', 4188), ('exucative', 4189), ('nikon', 4190), ('canon', 4191), ('eos', 4192), ('threaten', 4193), ('postpone', 4194), ('saw', 4195), ('bamph', 4196), ('win', 4197), ('decrease', 4198), ('digitalisation', 4199), ('uttrly', 4200), ('arrange', 4201), ('investigations', 4202), ('moot', 4203), ('play', 4204), ('retail', 4205), ('beginning', 4206), ('paly', 4207), ('emotion', 4208), ('child', 4209), ('voice', 4210), ('fulfil', 4211), ('adopted', 4212), ('webpage', 4213), ('harder', 4214), ('kg', 4215), ('gms', 4216), ('lame', 4217), ('galore', 4218), ('timewhy', 4219), ('troubling', 4220), ('thatno', 4221), ('goons', 4222), ('nouse', 4223), ('firestick', 4224), ('amazin', 4225), ('nfl', 4226), ('upgrade', 4227), ('recognise', 4228), ('amazed', 4229), ('largest', 4230), ('blu', 4231), ('ray', 4232), ('design', 4233), ('annoyingly', 4234), ('bolded', 4235), ('pop', 4236), ('vinyls', 4237), ('todaydamaged', 4238), ('bringing', 4239), ('flights', 4240), ('stairs', 4241), ('outragous', 4242), ('hot', 4243), ('zone', 4244), ('resulting', 4245), ('outright', 4246), ('gotten', 4247), ('fortune', 4248), ('bluedart', 4249), ('ewaste', 4250), ('disposal', 4251), ('appearing', 4252), ('nasty', 4253), ('acces', 4254), ('fucks', 4255), ('manner', 4256), ('drain', 4257), ('honored', 4258), ('cl', 4259), ('relied', 4260), ('reship', 4261), ('reviewers', 4262), ('ment', 4263), ('whtr', 4264), ('esteemed', 4265), ('proudly', 4266), ('starving', 4267), ('rob', 4268), ('vunerable', 4269), ('snapdeal', 4270), ('js', 4271), ('aspects', 4272), ('advisors', 4273), ('honour', 4274), ('tampc', 4275), ('exemplary', 4276), ('lives', 4277), ('worlds', 4278), ('customercare', 4279), ('uselessnot', 4280), ('scripts', 4281), ('degraded', 4282), ('todays', 4283), ('wonder', 4284), ('truthfully', 4285), ('indians', 4286), ('japan', 4287), ('octi', 4288), ('👇', 4289), ('notifying', 4290), ('disgrace', 4291), ('stinks', 4292), ('plagiarized', 4293), ('amanda', 4294), ('oregon', 4295), ('ecom', 4296), ('officers', 4297), ('audacity', 4298), ('toys', 4299), ('expose', 4300), ('children', 4301), ('toxic', 4302), ('materials', 4303), ('amazonis', 4304), ('ahh', 4305), ('story', 4306), ('fullfilled', 4307), ('taught', 4308), ('soaking', 4309), ('wet', 4310), ('electrical', 4311), ('hate', 4312), ('employing', 4313), ('routes', 4314), ('internal', 4315), ('inappropriate', 4316), ('tolerance', 4317), ('imei', 4318), ('username', 4319), ('exception', 4320), ('relying', 4321), ('consistency', 4322), ('enjoying', 4323), ('unlimited', 4324), ('goodreads', 4325), ('spin', 4326), ('characters', 4327), ('favor', 4328), ('widespread', 4329), ('reports', 4330), ('est', 4331), ('fri', 4332), ('agency', 4333), ('reminders', 4334), ('subscribed', 4335), ('loved', 4336), ('listing', 4337), ('pants', 4338), ('sudden', 4339), ('spotify', 4340), ('james', 4341), ('miracle', 4342), ('worker', 4343), ('thi', 4344), ('muting', 4345), ('muffle', 4346), ('twitterrific', 4347), ('handsfree', 4348), ('showroom', 4349), ('lure', 4350), ('contrary', 4351), ('nothingbut', 4352), ('leap', 4353), ('dosent', 4354), ('hebron', 4355), ('kygteast', 4356), ('pointgagtyoung', 4357), ('harris', 4358), ('gawrong', 4359), ('facilitygtmemphistngtatlantagand', 4360), ('messaging', 4361), ('bills', 4362), ('stressed', 4363), ('perk', 4364), ('unsurprisingly', 4365), ('😊', 4366), ('wtech', 4367), ('streaming', 4368), ('craps', 4369), ('bandwidth', 4370), ('funky', 4371), ('tvs', 4372), ('directing', 4373), ('pdo', 4374), ('reimburse', 4375), ('consecutively', 4376), ('bs', 4377), ('permanently', 4378), ('publish', 4379), ('dirty', 4380), ('blanket', 4381), ('iddlisbk', 4382), ('frequently', 4383), ('ajay', 4384), ('corporation', 4385), ('films', 4386), ('produced', 4387), ('nfdc', 4388), ('engage', 4389), ('buffs', 4390), ('tracks', 4391), ('wiid', 4392), ('shud', 4393), ('fone', 4394), ('invoices', 4395), ('tlkd', 4396), ('smone', 4397), ('rishabh', 4398), ('boston', 4399), ('timestamp', 4400), ('cheaper', 4401), ('lucky', 4402), ('key', 4403), ('crazy', 4404), ('absorb', 4405), ('flaws', 4406), ('belong', 4407), ('rated', 4408), ('independent', 4409), ('heavily', 4410), ('negligence', 4411), ('suspect', 4412), ('hopes', 4413), ('transferring', 4414), ('nm', 4415), ('gd', 4416), ('incompetence', 4417), ('scheduling', 4418), ('jc', 4419), ('genpact', 4420), ('creates', 4421), ('abuse', 4422), ('voiceview', 4423), ('menu', 4424), ('incredible', 4425), ('circus', 4426), ('junk', 4427), ('folder', 4428), ('hitting', 4429), ('terminating', 4430), ('tips', 4431), ('flaw', 4432), ('six', 4433), ('thirdforth', 4434), ('garaunteed', 4435), ('phonewhy', 4436), ('combo', 4437), ('apologizing', 4438), ('compassion', 4439), ('attentiveness', 4440), ('greatly', 4441), ('appreciating', 4442), ('files', 4443), ('dad', 4444), ('age', 4445), ('mecrap', 4446), ('confirmationwarning', 4447), ('accused', 4448), ('circumventing', 4449), ('approved', 4450), ('classrooms', 4451), ('infoampdrain', 4452), ('seemingly', 4453), ('sprite', 4454), ('scream', 4455), ('delete', 4456), ('erin', 4457), ('brokovich', 4458), ('traceable', 4459), ('dysbit', 4460), ('seal', 4461), ('coordinate', 4462), ('gm', 4463), ('coin', 4464), ('cx', 4465), ('richmond', 4466), ('ground', 4467), ('cutomer', 4468), ('behaves', 4469), ('inquiry', 4470), ('prise', 4471), ('amt', 4472), ('plzz', 4473), ('pocket', 4474), ('firstly', 4475), ('unauthorised', 4476), ('logs', 4477), ('guilty', 4478), ('malpractice', 4479), ('exploitation', 4480), ('dearest', 4481), ('indication', 4482), ('pushed', 4483), ('reassured', 4484), ('cheatvery', 4485), ('exploit', 4486), ('estimation', 4487), ('retweeted', 4488), ('cared', 4489), ('rahe', 4490), ('iski', 4491), ('topi', 4492), ('uske', 4493), ('apneaap', 4494), ('thak', 4495), ('chod', 4496), ('dega', 4497), ('karna', 4498), ('pincodes', 4499), ('misdelivery', 4500), ('eggs', 4501), ('easily', 4502), ('falling', 4503), ('norefund', 4504), ('numb', 4505), ('sp', 4506), ('promisedbut', 4507), ('orderraised', 4508), ('logitech', 4509), ('passes', 4510), ('respected', 4511), ('possitively', 4512), ('suspected', 4513), ('datesa', 4514), ('sowing', 4515), ('mother', 4516), ('hve', 4517), ('homeless', 4518), ('fa', 4519), ('codes', 4520), ('pw', 4521), ('water', 4522), ('weekends', 4523), ('unique', 4524), ('thousand', 4525), ('khatam', 4526), ('hone', 4527), ('baad', 4528), ('meri', 4529), ('baat', 4530), ('sun', 4531), ('lena', 4532), ('contractors', 4533), ('rethinking', 4534), ('sound', 4535), ('soundbot', 4536), ('proactive', 4537), ('servicesadvise', 4538), ('😀', 4539), ('recng', 4540), ('pkgs', 4541), ('apt', 4542), ('building', 4543), ('madam', 4544), ('hedwig', 4545), ('gud', 4546), ('rating', 4547), ('resetting', 4548), ('afyer', 4549), ('ampecinomical', 4550), ('selection', 4551), ('swing', 4552), ('hq', 4553), ('hosting', 4554), ('supportrequest', 4555), ('apni', 4556), ('dukaan', 4557), ('property', 4558), ('kids', 4559), ('abbyfern', 4560), ('jiaoyunshi', 4561), ('limbo', 4562), ('e', 4563), ('kim', 4564), ('shortened', 4565), ('protect', 4566), ('misuse', 4567), ('pen', 4568), ('refundtheir', 4569), ('bangles', 4570), ('congratulate', 4571), ('jacob', 4572), ('ampm', 4573), ('lengthy', 4574), ('turn', 4575), ('space', 4576), ('creditcardif', 4577), ('incentive', 4578), ('incent', 4579), ('behavior', 4580), ('overwhelmed', 4581), ('omg', 4582), ('ireland', 4583), ('ccare', 4584), ('factory', 4585), ('unplugged', 4586), ('reschedule', 4587), ('digested', 4588), ('browsers', 4589), ('suosneion', 4590), ('madden', 4591), ('fishy', 4592), ('jacking', 4593), ('discounting', 4594), ('inspire', 4595), ('letting', 4596), ('frame', 4597), ('ndth', 4598), ('nextday', 4599), ('spamming', 4600), ('weightloss', 4601), ('projector', 4602), ('sounded', 4603), ('cashload', 4604), ('afternoon', 4605), ('yodel', 4606), ('suit', 4607), ('comming', 4608), ('uncover', 4609), ('undervalued', 4610), ('penalty', 4611), ('decling', 4612), ('vehement', 4613), ('threats', 4614), ('unreal', 4615), ('crossbeats', 4616), ('raga', 4617), ('earphone', 4618), ('earpiece', 4619), ('repurchase', 4620), ('quit', 4621), ('phne', 4622), ('cud', 4623), ('fences', 4624), ('stands', 4625), ('sidewalk', 4626), ('heaves', 4627), ('unlocked', 4628), ('gate', 4629), ('onto', 4630), ('porch', 4631), ('overpackage', 4632), ('unbreakable', 4633), ('muppets', 4634), ('absolute', 4635), ('mohankrishna', 4636), ('charcoal', 4637), ('indigo', 4638), ('grateful', 4639), ('restore', 4640), ('holder', 4641), ('hired', 4642), ('gibberish', 4643), ('understanderwhen', 4644), ('fight', 4645), ('oneclick', 4646), ('mechanism', 4647), ('worrying', 4648), ('vulnerable', 4649), ('escaping', 4650), ('urgency', 4651), ('transactions', 4652), ('advising', 4653), ('etc', 4654), ('reaches', 4655), ('hiim', 4656), ('funny', 4657), ('underneath', 4658), ('green', 4659), ('teathis', 4660), ('bucks', 4661), ('beacause', 4662), ('bluffing', 4663), ('popsicle', 4664), ('skulduggery', 4665), ('font', 4666), ('bcoz', 4667), ('field', 4668), ('fridaycyber', 4669), ('pissed', 4670), ('chromalux', 4671), ('💡', 4672), ('frostedw', 4673), ('verif', 4674), ('addres', 4675), ('unclear', 4676), ('reflecting', 4677), ('era', 4678), ('promoted', 4679), ('accidentally', 4680), ('car', 4681), ('manufacturing', 4682), ('plural', 4683), ('twisting', 4684), ('deptmnt', 4685), ('ths', 4686), ('whrevr', 4687), ('cctv', 4688), ('footage', 4689), ('assuring', 4690), ('yea', 4691), ('resigned', 4692), ('undo', 4693), ('patch', 4694), ('sellerorderid', 4695), ('shiptrack', 4696), ('selecting', 4697), ('amprequested', 4698), ('intentions', 4699), ('correcting', 4700), ('smooth', 4701), ('memebership', 4702), ('mall', 4703), ('<unknown>', 4704)])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding matrix\n",
    "embedding_dim = 200\n",
    "vocab_size = len(vocabulary) + 1  # +1 for unknown token \n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in vocabulary.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        # Assign the chosen unknown vector representation\n",
    "        embedding_matrix[i] = embeddings_index.get(\"<unknown>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the embedding matrix to a pickle file \n",
    "with open(\"../objects/embedding_matrix.pkl\", \"wb\") as f:\n",
    "    pkl.dump(embedding_matrix, f)\n",
    "    \n",
    "# Dump the vocabulary to a pickle file\n",
    "with open(\"../objects/vocabulary.pkl\", \"wb\") as f:\n",
    "    pkl.dump(vocabulary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encocde sentences as sequences of integers: This is something I have just added\n",
    "def encode_sequences(tokenized_sentences, vocab):\n",
    "    sequences = []\n",
    "    for sentence in tokenized_sentences:\n",
    "        sequence = [vocab.get(word, \"<unknown>\") for word in sentence]  # 0 for unknown words\n",
    "        sequences.append(sequence)\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq = encode_sequences(X, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Label encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split dataset into stratified train and test sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_seq, y_encoded, test_size=0.2, shuffle=True, random_state=seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../objects/label_encoder.joblib']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the label encoder to a joblib file \n",
    "joblib.dump(label_encoder, \"../objects/label_encoder.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Convert the target variable to a tensor\n",
    "X_train_tensors = [torch.tensor(sequence, dtype=torch.long) for sequence in X_train]\n",
    "X_val_tensors = [torch.tensor(sequence, dtype=torch.long) for sequence in X_val]\n",
    "\n",
    "# Pad the sequences\n",
    "X_train_tensor = pad_sequence(X_train_tensors, batch_first=True)\n",
    "X_val_tensor = pad_sequence(X_val_tensors, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10721, 32]), torch.Size([2681, 29]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape, X_val_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['account', 'challenge_robot', 'discount', 'goodbye', 'greeting',\n",
       "       'quality', 'speak_representative', 'support', 'track'],\n",
       "      dtype='<U20')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_pad_sequences(tensor, fixed_length):\n",
    "    # Calculate the difference in length\n",
    "    length_diff = fixed_length - tensor.shape[1]\n",
    "    \n",
    "    if length_diff > 0:\n",
    "        # If the tensor is shorter, pad it\n",
    "        padding = torch.zeros((tensor.shape[0], length_diff), dtype=tensor.dtype)\n",
    "        padded_tensor = torch.cat([tensor, padding], dim=1)\n",
    "    elif length_diff < 0:\n",
    "        # If the tensor is longer, truncate it\n",
    "        padded_tensor = tensor[:, :fixed_length]\n",
    "    else:\n",
    "        # If the tensor is already at the desired length, do nothing\n",
    "        padded_tensor = tensor\n",
    "    \n",
    "    return padded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = re_pad_sequences(X_train_tensor, 32)\n",
    "X_val_tensor = re_pad_sequences(X_val_tensor, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor = torch.tensor(y_train)\n",
    "y_val_tensor = torch.tensor(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jeff',\n",
       " 'sir',\n",
       " 'you',\n",
       " 'should',\n",
       " 'take',\n",
       " 'an',\n",
       " 'action',\n",
       " 'to',\n",
       " 'improve',\n",
       " 'service',\n",
       " 'in',\n",
       " 'india',\n",
       " 'if',\n",
       " 'it',\n",
       " 'happened',\n",
       " 'with',\n",
       " 'flipkart',\n",
       " 'problem',\n",
       " 'had',\n",
       " 'been',\n",
       " 'resolved',\n",
       " 'so',\n",
       " 'far',\n",
       " 'with',\n",
       " 'some',\n",
       " 'gift']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tokens'][1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'support'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['intent'][1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'computer': 1,\n",
       " 'program': 2,\n",
       " 've': 3,\n",
       " 'plans': 4,\n",
       " 'bring': 5,\n",
       " 'item': 6,\n",
       " 'prime': 7,\n",
       " 'trust': 8,\n",
       " 'sellers': 9,\n",
       " 'defective': 10,\n",
       " 'replacement': 11,\n",
       " 'process': 12,\n",
       " 'details': 13,\n",
       " 'talk': 14,\n",
       " 'support': 15,\n",
       " 'agent': 16,\n",
       " 'discounted': 17,\n",
       " 'price': 18,\n",
       " 'discount': 19,\n",
       " 'im': 20,\n",
       " 'done': 21,\n",
       " 'see': 22,\n",
       " 'given': 23,\n",
       " 'options': 24,\n",
       " 'track': 25,\n",
       " 'order': 26,\n",
       " 'info': 27,\n",
       " 'available': 28,\n",
       " 'emailed': 29,\n",
       " 'customer': 30,\n",
       " 'service': 31,\n",
       " 'contact': 32,\n",
       " 'number': 33,\n",
       " 'thanks': 34,\n",
       " 'sorry': 35,\n",
       " 'hassle': 36,\n",
       " 'virtual': 37,\n",
       " 'assistant': 38,\n",
       " 'find': 39,\n",
       " 'shipping': 40,\n",
       " 'speak': 41,\n",
       " 'someone': 42,\n",
       " 'fall': 43,\n",
       " 'sale': 44,\n",
       " 'information': 45,\n",
       " 'apply': 46,\n",
       " 'uk': 47,\n",
       " 'residents': 48,\n",
       " 'hello': 49,\n",
       " 'everybody': 50,\n",
       " 'link': 51,\n",
       " 'anything': 52,\n",
       " 'message': 53,\n",
       " 'sent': 54,\n",
       " 'know': 55,\n",
       " 'minor': 56,\n",
       " 'thing': 57,\n",
       " 'opt': 58,\n",
       " 'general': 59,\n",
       " 'account': 60,\n",
       " 'hard': 61,\n",
       " 'remember': 62,\n",
       " 'smile': 63,\n",
       " 'apparently': 64,\n",
       " 'parcel': 65,\n",
       " 'due': 66,\n",
       " 'delivery': 67,\n",
       " 'yesterday': 68,\n",
       " 'still': 69,\n",
       " 'arrived': 70,\n",
       " 'days': 71,\n",
       " 'wasted': 72,\n",
       " 'site': 73,\n",
       " 'seriously': 74,\n",
       " 'first': 75,\n",
       " 'time': 76,\n",
       " 'facing': 77,\n",
       " 'keep': 78,\n",
       " 'happening': 79,\n",
       " 'always': 80,\n",
       " 'promise': 81,\n",
       " 'something': 82,\n",
       " 'come': 83,\n",
       " 'excuses': 84,\n",
       " 'promised': 85,\n",
       " 'noon': 86,\n",
       " 'today': 87,\n",
       " 'let': 88,\n",
       " 'us': 89,\n",
       " 'clear': 90,\n",
       " 'want': 91,\n",
       " 'refund': 92,\n",
       " 'compensation': 93,\n",
       " 'teach': 94,\n",
       " 'idiot': 95,\n",
       " 'people': 96,\n",
       " 'response': 97,\n",
       " 'reported': 98,\n",
       " 'amazon': 99,\n",
       " 'unable': 100,\n",
       " 'solution': 101,\n",
       " 'check': 102,\n",
       " 'bin': 103,\n",
       " 'series': 104,\n",
       " 'indeed': 105,\n",
       " 'treated': 106,\n",
       " 'international': 107,\n",
       " 'vcc': 108,\n",
       " 'life': 109,\n",
       " 'event': 110,\n",
       " 'deal': 111,\n",
       " 'nice': 112,\n",
       " 'day': 113,\n",
       " 'representative': 114,\n",
       " 'much': 115,\n",
       " 'lots': 116,\n",
       " 'apologies': 117,\n",
       " 'promises': 118,\n",
       " 'investigations': 119,\n",
       " 'feel': 120,\n",
       " 'like': 121,\n",
       " 'interested': 122,\n",
       " 'solving': 123,\n",
       " 'problem': 124,\n",
       " 'folks': 125,\n",
       " 'status': 126,\n",
       " 'hey': 127,\n",
       " 'please': 128,\n",
       " 'pay': 129,\n",
       " 'seller': 130,\n",
       " 'funds': 131,\n",
       " 'held': 132,\n",
       " 'email': 133,\n",
       " 'really': 134,\n",
       " 'understand': 135,\n",
       " 'concern': 136,\n",
       " 'tell': 137,\n",
       " 'eta': 138,\n",
       " 'resolve': 139,\n",
       " 'fix': 140,\n",
       " 'issue': 141,\n",
       " 'customers': 142,\n",
       " 'face': 143,\n",
       " 'clearance': 144,\n",
       " 'tricks': 145,\n",
       " 'delivered': 146,\n",
       " 'refurbished': 147,\n",
       " 'device': 148,\n",
       " 'center': 149,\n",
       " 'claiming': 150,\n",
       " 'warranty': 151,\n",
       " 'responding': 152,\n",
       " 'lost': 153,\n",
       " 'k': 154,\n",
       " 'yes': 155,\n",
       " 'received': 156,\n",
       " 'reference': 157,\n",
       " 'package': 158,\n",
       " 'ordered': 159,\n",
       " 'processed': 160,\n",
       " 'even': 161,\n",
       " 'regular': 162,\n",
       " 'follow': 163,\n",
       " 'product': 164,\n",
       " 'robotic': 165,\n",
       " 'system': 166,\n",
       " 'soon': 167,\n",
       " 'live': 168,\n",
       " 'automated': 169,\n",
       " 'holiday': 170,\n",
       " 'offer': 171,\n",
       " 'chat': 172,\n",
       " 'person': 173,\n",
       " 'justification': 174,\n",
       " 'inappropriate': 175,\n",
       " 'looking': 176,\n",
       " 'connect': 177,\n",
       " 'quality': 178,\n",
       " 'doesnt': 179,\n",
       " 'meet': 180,\n",
       " 'expectations': 181,\n",
       " 'greetings': 182,\n",
       " 'already': 183,\n",
       " 'filled': 184,\n",
       " 'form': 185,\n",
       " 'reply': 186,\n",
       " 'also': 187,\n",
       " 'pls': 188,\n",
       " 'cal': 189,\n",
       " 'solve': 190,\n",
       " 'matter': 191,\n",
       " 'high': 192,\n",
       " 'cheap': 193,\n",
       " 'trying': 194,\n",
       " 'deliver': 195,\n",
       " 'perhaps': 196,\n",
       " 'driver': 197,\n",
       " 'might': 198,\n",
       " 'try': 199,\n",
       " 'normal': 200,\n",
       " 'hour': 201,\n",
       " 'chatbot': 202,\n",
       " 'thank': 203,\n",
       " 'goodbye': 204,\n",
       " 'tracking': 205,\n",
       " 'million': 206,\n",
       " 'comes': 207,\n",
       " 'complaints': 208,\n",
       " 'app': 209,\n",
       " 'confirmation': 210,\n",
       " 'advise': 211,\n",
       " 'guess': 212,\n",
       " 'shipment': 213,\n",
       " 'progress': 214,\n",
       " 'think': 215,\n",
       " 'must': 216,\n",
       " 'stop': 217,\n",
       " 'making': 218,\n",
       " 'fool': 219,\n",
       " 'giving': 220,\n",
       " 'cash': 221,\n",
       " 'back': 222,\n",
       " 'delay': 223,\n",
       " 'another': 224,\n",
       " 'stock': 225,\n",
       " 'choose': 226,\n",
       " 'told': 227,\n",
       " 'care': 228,\n",
       " 'nothing': 229,\n",
       " 'rd': 230,\n",
       " 'months': 231,\n",
       " 'handle': 232,\n",
       " 'stupid': 233,\n",
       " 'early': 234,\n",
       " 'morning': 235,\n",
       " 'third': 236,\n",
       " 'call': 237,\n",
       " 'would': 238,\n",
       " 'mail': 239,\n",
       " 'november': 240,\n",
       " 'th': 241,\n",
       " 'everyone': 242,\n",
       " 'going': 243,\n",
       " 'sure': 244,\n",
       " 'tomorrow': 245,\n",
       " 'online': 246,\n",
       " 'says': 247,\n",
       " 'arriving': 248,\n",
       " 'wednesday': 249,\n",
       " 'date': 250,\n",
       " 'though': 251,\n",
       " 'guy': 252,\n",
       " 'called': 253,\n",
       " 'threaten': 254,\n",
       " 'feedback': 255,\n",
       " 'bye': 256,\n",
       " 'loyal': 257,\n",
       " 'bunch': 258,\n",
       " 'hi': 259,\n",
       " 'chatted': 260,\n",
       " 'representatives': 261,\n",
       " 'many': 262,\n",
       " 'times': 263,\n",
       " 'past': 264,\n",
       " 'years': 265,\n",
       " 'issues': 266,\n",
       " 'deliveries': 267,\n",
       " 'resolved': 268,\n",
       " 'reassured': 269,\n",
       " 'never': 270,\n",
       " 'happen': 271,\n",
       " 'ill': 272,\n",
       " 'contacting': 273,\n",
       " 'guys': 274,\n",
       " 'robot': 275,\n",
       " 'missed': 276,\n",
       " 'executive': 277,\n",
       " 'request': 278,\n",
       " 'ment': 279,\n",
       " 'whtr': 280,\n",
       " 'catch': 281,\n",
       " 'later': 282,\n",
       " 'ai': 283,\n",
       " 'appreciate': 284,\n",
       " 'replies': 285,\n",
       " 'investigation': 286,\n",
       " 'appear': 287,\n",
       " 'orders': 288,\n",
       " 'actually': 289,\n",
       " 'fulfilled': 290,\n",
       " 'work': 291,\n",
       " 'one': 292,\n",
       " 'month': 293,\n",
       " 'struggling': 294,\n",
       " 'feels': 295,\n",
       " 'futile': 296,\n",
       " 'happy': 297,\n",
       " 'filling': 298,\n",
       " 'concert': 299,\n",
       " 'sold': 300,\n",
       " 'injured': 301,\n",
       " 'home': 302,\n",
       " 'way': 303,\n",
       " 'refuse': 304,\n",
       " 'plz': 305,\n",
       " 'new': 306,\n",
       " 'year': 307,\n",
       " 'get': 308,\n",
       " 'ive': 309,\n",
       " 'finished': 310,\n",
       " 'tampered': 311,\n",
       " 'supplied': 312,\n",
       " 'fake': 313,\n",
       " 'faileddetectonline': 314,\n",
       " 'help': 315,\n",
       " 'identified': 316,\n",
       " 'cartridges': 317,\n",
       " 'weekend': 318,\n",
       " 'updates': 319,\n",
       " 'hours': 320,\n",
       " 'cancel': 321,\n",
       " 'proceed': 322,\n",
       " 'cancellation': 323,\n",
       " 'action': 324,\n",
       " 'website': 325,\n",
       " 'human': 326,\n",
       " 'promotion': 327,\n",
       " 'drop': 328,\n",
       " 'showing': 329,\n",
       " 'content': 330,\n",
       " 'need': 331,\n",
       " 'n': 332,\n",
       " 'able': 333,\n",
       " 'return': 334,\n",
       " 'bad': 335,\n",
       " 'press': 336,\n",
       " 'button': 337,\n",
       " 'take': 338,\n",
       " 'week': 339,\n",
       " 'point': 340,\n",
       " 'membership': 341,\n",
       " 'svc': 342,\n",
       " 'rep': 343,\n",
       " 'joke': 344,\n",
       " 'bpl': 345,\n",
       " 'tv': 346,\n",
       " 'listed': 347,\n",
       " 'informed': 348,\n",
       " 'pricing': 349,\n",
       " 'error': 350,\n",
       " 'id': 351,\n",
       " 'happens': 352,\n",
       " 'written': 353,\n",
       " 'waste': 354,\n",
       " 'rural': 355,\n",
       " 'others': 356,\n",
       " 'exchange': 357,\n",
       " 'better': 358,\n",
       " 'next': 359,\n",
       " 'condition': 360,\n",
       " 'helping': 361,\n",
       " 'wonderful': 362,\n",
       " 'evening': 363,\n",
       " 'login': 364,\n",
       " 'anymore': 365,\n",
       " 'reason': 366,\n",
       " 'file': 367,\n",
       " 'case': 368,\n",
       " 'consumer': 369,\n",
       " 'court': 370,\n",
       " 'resolution': 371,\n",
       " 'local': 372,\n",
       " 'team': 373,\n",
       " 'denied': 374,\n",
       " 'could': 375,\n",
       " 'place': 376,\n",
       " 'however': 377,\n",
       " 'intimation': 378,\n",
       " 'retailer': 379,\n",
       " 'using': 380,\n",
       " 'responded': 381,\n",
       " 'communication': 382,\n",
       " 'forwarded': 383,\n",
       " 'emails': 384,\n",
       " 'thats': 385,\n",
       " 'locate': 386,\n",
       " 'consider': 387,\n",
       " 'leave': 388,\n",
       " 'lightly': 389,\n",
       " 'share': 390,\n",
       " 'legal': 391,\n",
       " 'address': 392,\n",
       " 'advocate': 393,\n",
       " 'got': 394,\n",
       " 'attached': 395,\n",
       " 'proof': 396,\n",
       " 'completion': 397,\n",
       " 'writing': 398,\n",
       " 'least': 399,\n",
       " 'refunding': 400,\n",
       " 'use': 401,\n",
       " 'falty': 402,\n",
       " 'usually': 403,\n",
       " 'complain': 404,\n",
       " 'things': 405,\n",
       " '😌': 406,\n",
       " 'shipped': 407,\n",
       " 'ish': 408,\n",
       " 'little': 409,\n",
       " 'faith': 410,\n",
       " 'add': 411,\n",
       " 'insult': 412,\n",
       " 'injury': 413,\n",
       " 'telling': 414,\n",
       " 'basically': 415,\n",
       " 'fault': 416,\n",
       " 'providing': 417,\n",
       " 'instructions': 418,\n",
       " 'frankly': 419,\n",
       " 'angered': 420,\n",
       " 'insulted': 421,\n",
       " 'works': 422,\n",
       " 'boys': 423,\n",
       " 'drones': 424,\n",
       " 'decision': 425,\n",
       " 'paygrade': 426,\n",
       " 'escalate': 427,\n",
       " 'internally': 428,\n",
       " 'hold': 429,\n",
       " 'marketing': 430,\n",
       " 'gimmick': 431,\n",
       " 'carried': 432,\n",
       " 'misguide': 433,\n",
       " 'increased': 434,\n",
       " 'festival': 435,\n",
       " 'escalates': 436,\n",
       " 'thatpathetic': 437,\n",
       " 'services': 438,\n",
       " 'ups': 439,\n",
       " 'unavailable': 440,\n",
       " 'interaction': 441,\n",
       " 'artificial': 442,\n",
       " 'intelligence': 443,\n",
       " 'restock': 444,\n",
       " 'attempted': 445,\n",
       " 'supposed': 446,\n",
       " 'disappointed': 447,\n",
       " 'provide': 448,\n",
       " 'drivers': 449,\n",
       " 'fail': 450,\n",
       " 'attention': 451,\n",
       " 'detail': 452,\n",
       " 'dm': 453,\n",
       " 'ongoing': 454,\n",
       " 'couple': 455,\n",
       " 'weeks': 456,\n",
       " 'checkout': 457,\n",
       " 'apart': 458,\n",
       " 'assistance': 459,\n",
       " 'required': 460,\n",
       " 'kindly': 461,\n",
       " 'range': 462,\n",
       " 'last': 463,\n",
       " 'benefit': 464,\n",
       " 'pdt': 465,\n",
       " 'nw': 466,\n",
       " 'replcmnt': 467,\n",
       " 'ads': 468,\n",
       " 'invalid': 469,\n",
       " 'asked': 470,\n",
       " 'selling': 471,\n",
       " 'toys': 472,\n",
       " 'expose': 473,\n",
       " 'children': 474,\n",
       " 'toxic': 475,\n",
       " 'materials': 476,\n",
       " 'unfair': 477,\n",
       " 'transfer': 478,\n",
       " 'payment': 479,\n",
       " 'purpose': 480,\n",
       " 'appalling': 481,\n",
       " 'againweb': 482,\n",
       " 'lack': 483,\n",
       " 'poor': 484,\n",
       " 'anyone': 485,\n",
       " 'sensible': 486,\n",
       " 'sort': 487,\n",
       " 'deliberately': 488,\n",
       " 'free': 489,\n",
       " 'trace': 490,\n",
       " 'listing': 491,\n",
       " 'mrp': 492,\n",
       " 'crime': 493,\n",
       " 'india': 494,\n",
       " 'member': 495,\n",
       " 'easy': 496,\n",
       " 'digital': 497,\n",
       " 'good evening': 498,\n",
       " 'voucher': 499,\n",
       " 'helpful': 500,\n",
       " 'technical': 501,\n",
       " 'busy': 502,\n",
       " 'mobile': 503,\n",
       " 'bothered': 504,\n",
       " 'social': 505,\n",
       " 'media': 506,\n",
       " 'escalation': 507,\n",
       " 'improve': 508,\n",
       " 'experience': 509,\n",
       " 'responsibility': 510,\n",
       " 'real': 511,\n",
       " 'flash': 512,\n",
       " 'made': 513,\n",
       " 'twice': 514,\n",
       " 'shopping': 515,\n",
       " 'recommend': 516,\n",
       " 'every': 517,\n",
       " 'suggest': 518,\n",
       " 'bot': 519,\n",
       " 'carrier': 520,\n",
       " 'assigned': 521,\n",
       " 'said': 522,\n",
       " 'amzl': 523,\n",
       " 'hello there': 524,\n",
       " 'products': 525,\n",
       " 'continue': 526,\n",
       " 'damaged': 527,\n",
       " 'amd': 528,\n",
       " 'fc': 529,\n",
       " 'ask': 530,\n",
       " 'relevant': 531,\n",
       " 'touch': 532,\n",
       " 'possible': 533,\n",
       " 'enough': 534,\n",
       " 'everything': 535,\n",
       " 'exclusive': 536,\n",
       " 'well': 537,\n",
       " 'simplier': 538,\n",
       " 'job': 539,\n",
       " 'anyway': 540,\n",
       " 'less': 541,\n",
       " 'worse': 542,\n",
       " 'option': 543,\n",
       " 'expected': 544,\n",
       " 'redelivery': 545,\n",
       " 'guarantee': 546,\n",
       " 'waiting': 547,\n",
       " 'clearly': 548,\n",
       " 'working': 549,\n",
       " 'box': 550,\n",
       " 'good': 551,\n",
       " 'review': 552,\n",
       " 'purchased': 553,\n",
       " 'reviews': 554,\n",
       " 'keeps': 555,\n",
       " 'sending': 556,\n",
       " 'notifications': 557,\n",
       " 'elses': 558,\n",
       " 'contacted': 559,\n",
       " 'man': 560,\n",
       " 'start': 561,\n",
       " 'thinking': 562,\n",
       " 'hiding': 563,\n",
       " 'cheating': 564,\n",
       " 'fluctuations': 565,\n",
       " 'assist': 566,\n",
       " 'approaching': 567,\n",
       " 'sad': 568,\n",
       " 'special': 569,\n",
       " 'period': 570,\n",
       " 'promisedbut': 571,\n",
       " 'orderraised': 572,\n",
       " 'complaint': 573,\n",
       " 'frustrating': 574,\n",
       " 'items': 575,\n",
       " 'idea': 576,\n",
       " 'started': 577,\n",
       " 'ago': 578,\n",
       " 'hear': 579,\n",
       " 'counted': 580,\n",
       " 'transactional': 581,\n",
       " 'books': 582,\n",
       " 'rather': 583,\n",
       " 'argue': 584,\n",
       " 'pi': 585,\n",
       " 'give': 586,\n",
       " 'report': 587,\n",
       " 'missing': 588,\n",
       " 'avoid': 589,\n",
       " 'experiencing': 590,\n",
       " 'autumn': 591,\n",
       " 'fire': 592,\n",
       " 'sales': 593,\n",
       " 'schedule': 594,\n",
       " 'pickup': 595,\n",
       " 'long': 596,\n",
       " 'amex': 597,\n",
       " 'trouble': 598,\n",
       " 'getting': 599,\n",
       " 'near': 600,\n",
       " 'worst': 601,\n",
       " 'ever': 602,\n",
       " 'lied': 603,\n",
       " 'requested': 604,\n",
       " 'oct': 605,\n",
       " 'reach': 606,\n",
       " 'capable': 607,\n",
       " 'regarding': 608,\n",
       " 'senior': 609,\n",
       " 'manager': 610,\n",
       " 'prob': 611,\n",
       " 'mentioning': 612,\n",
       " 'spoke': 613,\n",
       " 'mind': 614,\n",
       " 'paying': 615,\n",
       " 'shared': 616,\n",
       " 'quoted': 617,\n",
       " 'guaranteed': 618,\n",
       " 'dispatched': 619,\n",
       " 'monday': 620,\n",
       " 'glitch': 621,\n",
       " 'warning': 622,\n",
       " 'lot': 623,\n",
       " 'cod': 624,\n",
       " 'placing': 625,\n",
       " 'returnrefund': 626,\n",
       " 'wrong': 627,\n",
       " 'packed': 628,\n",
       " 'amazonseller': 629,\n",
       " 'returns': 630,\n",
       " 'talking': 631,\n",
       " 'look': 632,\n",
       " 'history': 633,\n",
       " 'useless': 634,\n",
       " 'different': 635,\n",
       " 'comment': 636,\n",
       " 'excuse': 637,\n",
       " 'cashback': 638,\n",
       " 'ref': 639,\n",
       " 'considering': 640,\n",
       " 'effort': 641,\n",
       " 'makes': 642,\n",
       " 'click': 643,\n",
       " 'amp': 644,\n",
       " 'fill': 645,\n",
       " 'recd': 646,\n",
       " 'sue': 647,\n",
       " 'weekly': 648,\n",
       " 'impressed': 649,\n",
       " 'speaking': 650,\n",
       " 'assistants': 651,\n",
       " 'regards': 652,\n",
       " 'packaging': 653,\n",
       " 'hv': 654,\n",
       " 'phd': 655,\n",
       " 'd': 656,\n",
       " 'r': 657,\n",
       " 'totally': 658,\n",
       " 'unrelated': 659,\n",
       " 'common': 660,\n",
       " 'sense': 661,\n",
       " 'fed': 662,\n",
       " 'mails': 663,\n",
       " 'widout': 664,\n",
       " 'results': 665,\n",
       " 'scream': 666,\n",
       " 'twitter': 667,\n",
       " 'void': 668,\n",
       " 'delete': 669,\n",
       " 'credit': 670,\n",
       " 'card': 671,\n",
       " 'charge': 672,\n",
       " 'stuff': 673,\n",
       " 'go': 674,\n",
       " 'erin': 675,\n",
       " 'brokovich': 676,\n",
       " 'answer': 677,\n",
       " 'question': 678,\n",
       " 'pending': 679,\n",
       " 'consistent': 680,\n",
       " 'wlisting': 681,\n",
       " 'policy': 682,\n",
       " 'enquiry': 683,\n",
       " 'mohankrishna': 684,\n",
       " 'replied': 685,\n",
       " 'transit': 686,\n",
       " 'pity': 687,\n",
       " 'organisation': 688,\n",
       " 'set': 689,\n",
       " 'locked': 690,\n",
       " 'cancelled': 691,\n",
       " 'debited': 692,\n",
       " 'replace': 693,\n",
       " 'charged': 694,\n",
       " 'double': 695,\n",
       " 'overall': 696,\n",
       " 'buy': 697,\n",
       " 'damnedest': 698,\n",
       " 'hp': 699,\n",
       " 'laptop': 700,\n",
       " 'firefox': 701,\n",
       " 'pictures': 702,\n",
       " 'project': 703,\n",
       " 'drive': 704,\n",
       " 'needed': 705,\n",
       " 'nope': 706,\n",
       " 'correct': 707,\n",
       " 'infact': 708,\n",
       " 'great': 709,\n",
       " 'delivers': 710,\n",
       " 'fraud': 711,\n",
       " 'suggesting': 712,\n",
       " 'mobiles': 713,\n",
       " 'name': 714,\n",
       " 'offers': 715,\n",
       " 'letter': 716,\n",
       " 'markdown': 717,\n",
       " 'brilliant': 718,\n",
       " 'noone': 719,\n",
       " 'phone': 720,\n",
       " 'salutations': 721,\n",
       " 'taken': 722,\n",
       " 'checked': 723,\n",
       " 'remove': 724,\n",
       " 'incorrect': 725,\n",
       " 'eu': 726,\n",
       " 'chargers': 727,\n",
       " 'complete': 728,\n",
       " 'completed': 729,\n",
       " 'fingers': 730,\n",
       " 'crossed': 731,\n",
       " 'assurance': 732,\n",
       " 'wait': 733,\n",
       " 'stooped': 734,\n",
       " 'low': 735,\n",
       " 'provided': 736,\n",
       " 'central': 737,\n",
       " 'deposit': 738,\n",
       " 'confirm': 739,\n",
       " 'beware': 740,\n",
       " 'bluffs': 741,\n",
       " 'sc': 742,\n",
       " 'harassment': 743,\n",
       " 'accepting': 744,\n",
       " 'buyers': 745,\n",
       " 'harassed': 746,\n",
       " 'market': 747,\n",
       " 'performance': 748,\n",
       " 'buying': 749,\n",
       " 'manned': 750,\n",
       " 'office': 751,\n",
       " 'yet': 752,\n",
       " 'claim': 753,\n",
       " 'ok': 754,\n",
       " 'video': 755,\n",
       " 'games': 756,\n",
       " 'm': 757,\n",
       " 'damned': 758,\n",
       " 'ds': 759,\n",
       " 'tym': 760,\n",
       " 'act': 761,\n",
       " 'filthy': 762,\n",
       " 'mailed': 763,\n",
       " 'prority': 764,\n",
       " 'looks': 765,\n",
       " 'zef': 766,\n",
       " 'forward': 767,\n",
       " 'billed': 768,\n",
       " 'previously': 769,\n",
       " 'left': 770,\n",
       " 'finally': 771,\n",
       " 'pckg': 772,\n",
       " 'declared': 773,\n",
       " 'undeliverable': 774,\n",
       " 'reasons': 775,\n",
       " 'seeking': 776,\n",
       " 'specialist': 777,\n",
       " 'buddy': 778,\n",
       " 'fixed': 779,\n",
       " 'hit': 780,\n",
       " 'birthday': 781,\n",
       " 'changed': 782,\n",
       " 'password': 783,\n",
       " 'calling': 784,\n",
       " 'minutes': 785,\n",
       " 'endless': 786,\n",
       " 'script': 787,\n",
       " 'completely': 788,\n",
       " 'grotesque': 789,\n",
       " 'accent': 790,\n",
       " 'unbearable': 791,\n",
       " 'haha': 792,\n",
       " 'nowadays': 793,\n",
       " 'gf': 794,\n",
       " 'rate': 795,\n",
       " 'cheats': 796,\n",
       " 'paid': 797,\n",
       " 'balance': 798,\n",
       " 'deducted': 799,\n",
       " 'simple': 800,\n",
       " 'purchase': 801,\n",
       " 'needful': 802,\n",
       " 'promo': 803,\n",
       " 'code': 804,\n",
       " 'correspondence': 805,\n",
       " 'almost': 806,\n",
       " 'glad': 807,\n",
       " 'giant': 808,\n",
       " 'company': 809,\n",
       " 'taking': 810,\n",
       " 'companies': 811,\n",
       " 'packages': 812,\n",
       " 'chk': 813,\n",
       " 'properly': 814,\n",
       " 'waited': 815,\n",
       " 'till': 816,\n",
       " 'become': 817,\n",
       " 'richman': 818,\n",
       " 'query': 819,\n",
       " 'unanswered': 820,\n",
       " 'truly': 821,\n",
       " 'violated': 822,\n",
       " 'location': 823,\n",
       " 'played': 824,\n",
       " 'reimbursement': 825,\n",
       " 'normally': 826,\n",
       " 'thru': 827,\n",
       " 'grandsons': 828,\n",
       " 'payments': 829,\n",
       " 'declined': 830,\n",
       " 'cloud': 831,\n",
       " 'reader': 832,\n",
       " 'book': 833,\n",
       " 'bought': 834,\n",
       " 'linux': 835,\n",
       " 'installing': 836,\n",
       " 'wine': 837,\n",
       " 'expired': 838,\n",
       " 'update': 839,\n",
       " 'feedbacks': 840,\n",
       " 'acted': 841,\n",
       " 'gone': 842,\n",
       " 'trash': 843,\n",
       " 'certain': 844,\n",
       " 'may': 845,\n",
       " 'recorded': 846,\n",
       " 'handed': 847,\n",
       " 'apple': 848,\n",
       " 'iphone': 849,\n",
       " 'advance': 850,\n",
       " 'traking': 851,\n",
       " 'updated': 852,\n",
       " 'since': 853,\n",
       " 'sunday': 854,\n",
       " 'portal': 855,\n",
       " 'setting': 856,\n",
       " 'echo': 857,\n",
       " 'language': 858,\n",
       " '₹': 859,\n",
       " 'innovative': 860,\n",
       " 'attract': 861,\n",
       " 'cart': 862,\n",
       " 'sometimes': 863,\n",
       " 'notification': 864,\n",
       " 'pincode': 865,\n",
       " 'gets': 866,\n",
       " 'delivrd': 867,\n",
       " 'waygo': 868,\n",
       " 'digitalisationuuttrly': 869,\n",
       " 'unprofessnl': 870,\n",
       " 'toll': 871,\n",
       " 'disconnects': 872,\n",
       " 'closed': 873,\n",
       " 'allow': 874,\n",
       " 'problems': 875,\n",
       " 'unacceptable': 876,\n",
       " 'except': 877,\n",
       " 'standard': 878,\n",
       " 'utterly': 879,\n",
       " 'cstmr': 880,\n",
       " 'emi': 881,\n",
       " 'power': 882,\n",
       " 'campaign': 883,\n",
       " 'asking': 884,\n",
       " 'send': 885,\n",
       " 'longer': 886,\n",
       " 'access': 887,\n",
       " 'cc': 888,\n",
       " 'old': 889,\n",
       " 'logistics': 890,\n",
       " 'end': 891,\n",
       " 'eligible': 892,\n",
       " 'oneplus': 893,\n",
       " 'launch': 894,\n",
       " 'oriented': 895,\n",
       " 'orelse': 896,\n",
       " 'tenure': 897,\n",
       " 'seen': 898,\n",
       " 'battery': 899,\n",
       " 'computerized': 900,\n",
       " 'clue': 901,\n",
       " 'meif': 902,\n",
       " 'actual': 903,\n",
       " 'canceled': 904,\n",
       " 'happened': 905,\n",
       " 'buyer': 906,\n",
       " 'responsible': 907,\n",
       " 'requesting': 908,\n",
       " 'strange': 909,\n",
       " 'cust': 910,\n",
       " 'saying': 911,\n",
       " 'failed': 912,\n",
       " 'choosing': 913,\n",
       " 'insecure': 914,\n",
       " 'money': 915,\n",
       " 'returning': 916,\n",
       " 'picked': 917,\n",
       " 'notice': 918,\n",
       " 'names': 919,\n",
       " 'escaped': 920,\n",
       " 'became': 921,\n",
       " 'irresponsible': 922,\n",
       " 'dispatching': 923,\n",
       " 'state': 924,\n",
       " 'half': 925,\n",
       " 'conversation': 926,\n",
       " 'via': 927,\n",
       " 'unmoved': 928,\n",
       " 'public': 929,\n",
       " 'appreciated': 930,\n",
       " 'second': 931,\n",
       " 'house': 932,\n",
       " 'resident': 933,\n",
       " 'needs': 934,\n",
       " 'nonsense': 935,\n",
       " 'seems': 936,\n",
       " 'placed': 937,\n",
       " 'arrive': 938,\n",
       " 'pm': 939,\n",
       " 'far': 940,\n",
       " 'dispatch': 941,\n",
       " 'courier': 942,\n",
       " 'atoz': 943,\n",
       " 'undelivered': 944,\n",
       " 'compensates': 945,\n",
       " 'interest': 946,\n",
       " 'associates': 947,\n",
       " 'respond': 948,\n",
       " 'impossible': 949,\n",
       " 'open': 950,\n",
       " 'andbrheybdenied': 951,\n",
       " 'tried': 952,\n",
       " 'instruction': 953,\n",
       " 'posted': 954,\n",
       " 'hell': 955,\n",
       " 'turning': 956,\n",
       " 'explain': 957,\n",
       " 'pathetic': 958,\n",
       " 'cs': 959,\n",
       " 'kind': 960,\n",
       " 'horrible': 961,\n",
       " 'shows': 962,\n",
       " 'super': 963,\n",
       " 'signed': 964,\n",
       " 'netherlands': 965,\n",
       " 'abut': 966,\n",
       " 'watch': 967,\n",
       " 'asks': 968,\n",
       " 'method': 969,\n",
       " 'two': 970,\n",
       " 'temper': 971,\n",
       " 'glass': 972,\n",
       " 'vide': 973,\n",
       " 'tempered': 974,\n",
       " 'timelines': 975,\n",
       " 'invoice': 976,\n",
       " 'january': 977,\n",
       " 'irritated': 978,\n",
       " 'harassing': 979,\n",
       " 'screwed': 980,\n",
       " 'misleading': 981,\n",
       " 'ready': 982,\n",
       " 'cut': 983,\n",
       " 'concerns': 984,\n",
       " 'kidding': 985,\n",
       " 'proper': 986,\n",
       " 'expensive': 987,\n",
       " 'electronic': 988,\n",
       " 'smh': 989,\n",
       " 'logged': 990,\n",
       " 'cheated': 991,\n",
       " 'translation': 992,\n",
       " 'availability': 993,\n",
       " 'protection': 994,\n",
       " 'plan': 995,\n",
       " 'originally': 996,\n",
       " 'stated': 997,\n",
       " 'nine': 998,\n",
       " 'claims': 999,\n",
       " 'soc': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just save the vocabulary to a pickle file\n",
    "with open(\"../objects/vocabulary.pkl\", \"wb\") as f:\n",
    "    pkl.dump(vocabulary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch import LongTensor\n",
    "# train_seq_lengths = LongTensor(list(map(len, X_train_tensors)))\n",
    "# val_seq_lengths = LongTensor(list(map(len, X_val_tensors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort sequences by lengths in descending order (if not already sorted)\n",
    "# X_train_sorted, train_lengths_sorted = X_train_tensor[train_seq_lengths.sort(descending=True)[1]], train_seq_lengths[train_seq_lengths.sort(descending=True)[1]]\n",
    "# X_val_sorted, val_lengths_sorted = X_val_tensor[val_seq_lengths.sort(descending=True)[1]], val_seq_lengths[val_seq_lengths.sort(descending=True)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming y_train and y_val are your target tensors\n",
    "\n",
    "# Get sorting indices for train and validation sequences\n",
    "# train_sort_indices = train_seq_lengths.sort(descending=True)[1]\n",
    "# val_sort_indices = val_seq_lengths.sort(descending=True)[1]\n",
    "\n",
    "# # Sort y_train and y_val using the obtained indices\n",
    "# y_train_sorted = y_train_tensor[train_sort_indices]\n",
    "# y_val_sorted = y_val_tensor[val_sort_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pack the padded sequences \n",
    "# X_train_packed = pack_padded_sequence(X_train_sorted, train_lengths_sorted, batch_first=True, enforce_sorted=False)\n",
    "# X_val_packed = pack_padded_sequence(X_val_sorted, val_lengths_sorted, batch_first=True, enforce_sorted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collate_fn(batch):\n",
    "#     sequences, labels = zip(*batch)\n",
    "#     lengths = torch.tensor([len(seq) for seq in sequences])\n",
    "#     padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "#     labels = torch.tensor(labels)\n",
    "#     return padded_sequences, labels, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test datasets\n",
    "# train_dataset = Subset(TensorDataset(X_tensor, y_tensor), train_indices)\n",
    "# test_dataset = Subset(TensorDataset(X_tensor, y_tensor), val_indices)\n",
    "\n",
    "# DataLoader for train and test datasets\n",
    "train_dataloader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(TensorDataset(X_val_tensor, y_val_tensor), batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'train' is a DataFrame containing 'Utterance' and 'Intent' columns\n",
    "\n",
    "# Tokenize the text data using PyTorch's tokenizer\n",
    "# The text already seems to be tokenized \n",
    "\n",
    "# Split the data into train and validation sets\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, \n",
    "#                                                   shuffle=True, stratify=y, random_state=seed_value)\n",
    "\n",
    "# # Label encode the target variable\n",
    "# label_encoder = LabelEncoder()\n",
    "# y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "# y_val_encoded = label_encoder.transform(y_val)\n",
    "\n",
    "\n",
    "# # Convert encoded targets to PyTorch tensors\n",
    "# y_train_encoded = torch.tensor(y_train_encoded, dtype=torch.long) \n",
    "# y_val_encoded = torch.tensor(y_val_encoded, dtype=torch.long)\n",
    "\n",
    "# print(f'\\nShape checks:\\nX_train: {len(X_train)} X_val: {len(X_val)}\\ny_train: {len(y_train_encoded)} y_val: {len(y_val_encoded)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_X_train = encode_sequences(X_train, vocabulary)\n",
    "# encoded_X_val = encode_sequences(X_val, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to a fixed length: This is something I have just added\n",
    "\n",
    "# Convert encoded sequences to PyTorch tensors\n",
    "# encoded_X_train_tensors = [torch.tensor(seq) for seq in encoded_X_train]\n",
    "# encoded_X_val_tensors = [torch.tensor(seq) for seq in encoded_X_val]\n",
    "\n",
    "# Pad sequences\n",
    "# Set batch_first=True to have the batch dimension first\n",
    "# padded_X_train = pad_sequence(encoded_X_train_tensors, batch_first=True, padding_value=0)\n",
    "# padded_X_val = pad_sequence(encoded_X_val_tensors, batch_first=True, padding_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Custom collate function to pad sequences \n",
    "# def collate_fn(batch):\n",
    "#     sequences, labels = zip(*batch)\n",
    "#     lengths = torch.tensor([len(seq) for seq in sequences])\n",
    "#     padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "#     labels = torch.tensor(labels)\n",
    "#     return padded_sequences, lengths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just an experimental check\n",
    "from torch.nn import Embedding  \n",
    "# embedding_layer = Embedding(num_embeddings=embedding_matrix_tensor.size(0), \n",
    "#                             embedding_dim=embedding_matrix_tensor.size(1), \n",
    "#                             _weight=embedding_matrix_tensor)\n",
    "\n",
    "# # Freeze the embedding layer\n",
    "# embedding_layer.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming padded_X_train and padded_X_val are NumPy arrays\n",
    "# padded_X_train_tensor = torch.LongTensor(padded_X_train)\n",
    "# padded_X_val_tensor = torch.LongTensor(padded_X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padded_X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padded_X_val_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repad the data\n",
    "# Assuming you've decided on a fixed sequence length, for example, the max length found in the training set\n",
    "# fixed_seq_length = 32\n",
    "\n",
    "# Function to re-pad tensors to a fixed length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_len = padded_X_train_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-pad both the training and validation tensors\n",
    "# padded_X_train_tensor = re_pad_sequences(padded_X_train_tensor, fixed_seq_length)\n",
    "# padded_X_val_tensor = re_pad_sequences(padded_X_val_tensor, fixed_seq_length)\n",
    "\n",
    "# Now both tensors should have the same shape in terms of sequence length\n",
    "# print(padded_X_train_tensor.shape)\n",
    "# print(padded_X_val_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Embedding layer\n",
    "# embedding_matrix_tensor = torch.FloatTensor(embedding_matrix)\n",
    "# embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "# embedding.weight = nn.Parameter(embedding_matrix_tensor)\n",
    "# embedding.weight.requires_grad = False  # To not train the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sweep config \n",
    "# sweep_config = {\n",
    "#     \"method\": \"random\",\n",
    "#     \"metric\": {\"goal\": \"maximize\", \"name\": \"val_accuracy\"}, \n",
    "#     \"parameters\": {\n",
    "#                     \"learning_rate\": {\"values\": [0.01, 0.001, 0.0001]},\n",
    "#                     \"epochs\": {\"values\": [30]},\n",
    "#                     \"batch_size\": {\"values\": [32, 64, 128]},\n",
    "#                     \"embedding_size\": {\"values\": [100]},\n",
    "#                     \"hidden_size\": {\"values\": [64, 128, 256]},\n",
    "#                     \"output_size\": {\"values\": [9]},\n",
    "#                     \"num_layers\": {\"values\": [1, 2, 3]},\n",
    "#                     \"dropout\": {\"values\": [0.1, 0.2, 0.3]}, \n",
    "#                     \"weight_decay\": {\"values\": [1e-3, 1e-4, 1e-5]},\n",
    "#                     \"scheduler_lambda_epoch_threshold\": {\"values\": [10]},\n",
    "#                     \"scheduler_decay_rate\": {\"values\": [-0.1]},\n",
    "#                 }\n",
    "# }\n",
    "\n",
    "# sweep_defaults = {\n",
    "#     \"learning_rate\": 0.001,\n",
    "#     \"epochs\": 30,\n",
    "#     \"batch_size\": 16, \n",
    "#     \"embedding_size\": 100,\n",
    "#     \"hidden_size\": 128,\n",
    "#     \"output_size\": 9,\n",
    "#     \"num_layers\": 3,\n",
    "#     \"dropout\": 0.05,\n",
    "#     \"eval_metric\": \"accuracy\", \n",
    "#     \"weight_decay\": 1e-3,\n",
    "#     \"scheduler_lambda_epoch_threshold\": 10,\n",
    "#     \"scheduler_decay_rate\": -0.1\n",
    "# }\n",
    "\n",
    "# sweep_id = wandb.sweep(sweep_config, project=\"intent-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MODEL_EVAL_METRIC:\n",
    "#     accuracy = \"accuracy\"\n",
    "#     f1_score = \"f1_score\"\n",
    "    \n",
    "# class Config: \n",
    "#     VOCAB_SIZE = 0\n",
    "#     BATCH_SIZE = 32 \n",
    "#     EMB_SIZE = 300 \n",
    "#     OUT_SIZE = 9 # Corresponds to the number of intents\n",
    "#     NUM_FOLDS = 5 \n",
    "#     NUM_EPOCHS = 5\n",
    "#     NUM_WORKERS = 8\n",
    "    \n",
    "#     # I want to update the pretrainhttps://wandb.ai/sinhasagar507/intent-classification/sweeps/4sd3drrded embedding weights during training process \n",
    "#     # I want to use a pretrained embedding\n",
    "#     OPTIMIZER = \"Adam\"\n",
    "#     EMB_WT_UPDATE = True\n",
    "#     DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     MODEL_EVAL_METRIC = MODEL_EVAL_METRIC.accuracy\n",
    "#     FAST_DEV_RUN = False \n",
    "#     PATIENCE = 6 \n",
    "#     IS_BIDIRECTIONAL = True \n",
    "    \n",
    "     \n",
    "#     # Model hyperparameters\n",
    "#     MODEL_PARAMS = {\n",
    "#         \"hidden_size\": 128,\n",
    "#         \"num_layers\": 2,\n",
    "#         \"drop_out\": 0.4258,\n",
    "#         \"lr\": 0.000366,\n",
    "#         \"weight_decay\": 0.00001\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just an experimental check\n",
    "# from torch.nn import Embedding  \n",
    "# embedding_layer = Embedding(num_embeddings=embedding_matrix_tensor.size(0), \n",
    "#                             embedding_dim=embedding_matrix_tensor.size(1), \n",
    "#                             _weight=embedding_matrix_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Applications/saggydev/projects_learning/amazon_support/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%writefile` not found.\n"
     ]
    }
   ],
   "source": [
    "# Enhance the architecture later \n",
    "%%writefile ../src/models/intent_classifier.py\n",
    "class IntentClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, seq_len, embedding_matrix): \n",
    "        super().__init__()\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding_dim = wandb.config[\"embedding_size\"]\n",
    "        embedding_matrix_tensor = torch.FloatTensor(embedding_matrix)\n",
    "        self.embedding = nn.Embedding(seq_len, self.embedding_dim)\n",
    "        self.embedding.weight = nn.Parameter(embedding_matrix_tensor)\n",
    "        self.embedding.weight.requires_grad = False  # To not train the embedding layer\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.hidden_dim = wandb.config[\"hidden_size\"]\n",
    "        self.num_layers = wandb.config[\"num_layers\"]\n",
    "        self.dropout = nn.Dropout(wandb.config[\"dropout\"])\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_dim, \n",
    "                            hidden_size=self.hidden_dim, \n",
    "                            num_layers=self.num_layers, \n",
    "                            bidirectional=True, \n",
    "                            dropout=wandb.config[\"dropout\"], \n",
    "                            batch_first=True)\n",
    "        \n",
    "        # The output of this operation should be \n",
    "        \n",
    "        # Dense layers \n",
    "\n",
    "        self.fc1 = nn.Linear(self.hidden_dim*2, 1024)  # 2 for bidirectional. Over here, its (128*2) = 256, 1024 is the output dimension of the first dense layer\n",
    "        self.fc2 = nn.Linear(1024, 512) \n",
    "        self.fc3 = nn.Linear(512, 256) \n",
    "        \n",
    "        # Dropout layer\n",
    "       # self.dropout = nn.Dropout(self.dropout)  \n",
    "        \n",
    "        # Output layer\n",
    "        self.output_dim = wandb.config[\"output_size\"]\n",
    "        self.out = nn.Linear(256, self.output_dim) ## Yaar idhr output hoga RNN ya LSTM ka (batch_size output_dim, no_of_classes) aayega kya? \n",
    "        # self.out_2 = nn.Linear(output_dim, 9)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        # text = [batch_size, embed_length]\n",
    "        \n",
    "        # embeddings = self.dropout(self.embedding(inputs))\n",
    "        \n",
    "        # embedded = [batch_size, sent_length, emb_dim]\n",
    "\n",
    "        # if self.embedding_matrix is not None: \n",
    "        #     assert self.embeddings.shape == (inputs.shape[0], inputs.shape[1], self.embedding_dim)\n",
    "         \n",
    "        # pack_padded_sequence before feeding to the LSTM. This is required so PyTorch knows \n",
    "        # which elements of the sequence are padded and ignores them in the computation \n",
    "        # Accomplished only after the embedding step \n",
    "        # embeds_pack = pack_padded_sequence(embeddings, inputs_lengths, batch_first=True)\n",
    "        \n",
    "        # Get the dimensions of the packed sequence \n",
    "        # dimensions = embeds_pack.data.size()\n",
    "\n",
    "        # Assert the shape of input sequence \n",
    "        # assert inputs.shape == (Config.BATCH_SIZE, 1000)\n",
    "\n",
    "        embeddings = self.embedding(inputs)\n",
    "        # print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "        _, (hidden, _) = self.lstm(embeddings)\n",
    "\n",
    "        # hidden shape: [num_layers*num_directions, batch_size, hidden_dim]\n",
    "        # print(f\"Hidden shape: {hidden.shape}\n",
    "        \n",
    "        # Ours task being a classification model, we are only interested in the final hidden state and not the LSTM output \n",
    "        # h_n and c_n = [num_directions * num_layers, batch_size, hidden_size]\n",
    "        final_hidden_forward = hidden[-2, :, :] # [batch_size, hidden_dim]\n",
    "        final_hidden_backward = hidden[-1, :, :] # [bacth_size, hidden_dim]\n",
    "\n",
    "        # print(f\"Final hidden forward shape: {final_hidden_forward.shape}\") # Iska shape is \n",
    "        # print(f\"Final hidden backward shape: {final_hidden_backward.shape}\")\n",
    "        \n",
    "        # Concat the final forward and hidden backward states \n",
    "        hidden = torch.cat((final_hidden_forward, final_hidden_backward), dim=1)\n",
    "        # print(f\"Hidden shape after concatenation: {hidden.shape}\")\n",
    "                \n",
    "        # Dense Linear Layers \n",
    "        dense_outputs_1 = self.fc1(hidden)\n",
    "        dense_outputs_1 = nn.ReLU()(dense_outputs_1) \n",
    "        # Dropout layer \n",
    "        dense_outputs_1 = self.dropout(dense_outputs_1) \n",
    "        dense_outputs_2 = self.fc2(dense_outputs_1)\n",
    "     #   dense_outputs_2 = self.dropout(dense_outputs_2)\n",
    "        dense_outputs_2 = nn.ReLU()(dense_outputs_2) \n",
    "        dense_outputs_3 = self.fc3(dense_outputs_2)\n",
    "        dense_outputs_3 = nn.ReLU()(dense_outputs_3)\n",
    "     #  dense_outputs_3 = self.dropout(dense_outputs_3)\n",
    "\n",
    "        # Final output classification layer\n",
    "        # Applying the Softmax layer \n",
    "        final_output = (self.out(dense_outputs_3))\n",
    "        # print(f\"Final output shape: {final_output.shape}\")\n",
    "    \n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "confusion_matrix_epoch, class_report_epoch = [], []\n",
    "class ModelTrainer:\n",
    "    def __init__(self, seq_len):\n",
    "        self.seq_len = seq_len\n",
    "        self.embedding_dim = wandb.config[\"embedding_size\"]\n",
    "        self.embedding_matrix = embedding_matrix   \n",
    "        self.hidden_dim = wandb.config[\"hidden_size\"]\n",
    "        self.output_dim = wandb.config[\"output_size\"]\n",
    "        self.n_layers = wandb.config[\"num_layers\"]\n",
    "        self.batch_size = wandb.config[\"batch_size\"]\n",
    "        self.epochs = wandb.config[\"epochs\"]\n",
    "     #   self.dropout = wandb.config[\"dropout\"]\n",
    "        # Assuming IntentClassifier is defined elsewhere and matches these parameters\n",
    "        # print(self.seq_len, self.embedding_dim, self.hidden_dim, self.output_dim, self.embedding_matrix)\n",
    "        self.model = IntentClassifier(self.seq_len, self.embedding_matrix)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        # Assuming Config.OPTIMIZER is a valid PyTorch optimizer class\n",
    "        self.learning_rate = wandb.config[\"learning_rate\"]\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate, weight_decay=wandb.config[\"weight_decay\"])\n",
    "        self.scheduler_epoch_threshold = wandb.config[\"scheduler_lambda_epoch_threshold\"]\n",
    "        self.scheduler_decay_rate = wandb.config[\"scheduler_decay_rate\"]\n",
    "        self.epoch_lst = []\n",
    "\n",
    "    def train(self, train_dataloader, val_dataloader):\n",
    "        #TODO: Change the function format afterwards \n",
    "        # X_train = torch.tensor(X_train, dtype=torch.float)\n",
    "        # X_val = torch.tensor(X_val, dtype=torch.float)\n",
    "        # y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "        # y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "        # Assuming X_train, y_train, X_val, y_val are already tensors\n",
    "        # Ensure they have matching first dimensions\n",
    "        # assert X_train.shape[0] == y_train.shape[0], \"Training feature and label count mismatch\"\n",
    "        # assert X_val.shape[0] == y_val.shape[0], \"Validation feature and label count mismatch\"\n",
    "        \n",
    "       \n",
    "        train_accuracies_epoch, val_accuracies_epoch = [], []\n",
    "        self.valid_loss_min = np.Inf\n",
    "\n",
    "        # Assuming `optimizer` is already defined\n",
    "        # Define the lambda function for learning rate adjustment using W&B config\n",
    "        # lambda_lr = lambda epoch: 1 if epoch < self.scheduler_epoch_threshold else torch.exp(torch.tensor(-self.scheduler_decay_rate))\n",
    "\n",
    "        # Initialize the LambdaLR scheduler with the optimizer and lambda function\n",
    "        # scheduler = torch.optim.lr_scheduler.LambdaLR(self.optimizer, lr_lambda=lambda_lr)\n",
    "\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            train_loss, valid_loss = 0.0, 0.0\n",
    "            correct, total = 0, 0\n",
    "\n",
    "\n",
    "            self.model.train()\n",
    "            for data, target in train_dataloader:\n",
    "                # Log the shape of the data and target tensors\n",
    "                # assert data.shape == (self.batch_size, self.embedding_dim), f\"Data shape mismatch: {data.shape}\"\n",
    "                # assert target.shape == (self.batch_size,), f\"Target shape mismatch: {target.shape}\"\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(data)\n",
    "                loss = self.criterion(output, target)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # print(output.shape)\n",
    "                pred_labels = torch.argmax(output, 1)\n",
    "                correct += (pred_labels == target).sum().item()\n",
    "                total += target.size(0)\n",
    "                train_loss += loss.item() * data.size(0)\n",
    "\n",
    "\n",
    "            train_accuracy = 100 * correct / total\n",
    "            train_accuracies_epoch.append(train_accuracy)\n",
    "\n",
    "            # Log the training loss and accuracy\n",
    "            # wandb.log({\"Training Accuracy\": train_accuracy, \"Training Loss\": train_loss})\n",
    "\n",
    "            self.model.eval()\n",
    "            correct, total = 0, 0\n",
    "            all_targets, all_preds = [], []\n",
    "            for data, target in val_dataloader:\n",
    "                output = self.model(data)\n",
    "                loss = self.criterion(output, target)\n",
    "\n",
    "                pred_labels = torch.argmax(output, 1)\n",
    "                correct += (pred_labels == target).sum().item()\n",
    "                total += target.size(0)\n",
    "                valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "                all_targets.extend(list(target.numpy()))\n",
    "                all_preds.extend(list(pred_labels.numpy()))\n",
    "\n",
    "            valid_accuracy = 100 * correct / total\n",
    "            val_accuracies_epoch.append(valid_accuracy)\n",
    "\n",
    "            f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "            conf_matrix = confusion_matrix(all_targets, all_preds)\n",
    "            class_report = classification_report(all_targets, all_preds, labels=[str(i) for i in range(self.output_dim)])\n",
    "            confusion_matrix_epoch.append(conf_matrix)\n",
    "            class_report_epoch.append(class_report)\n",
    "\n",
    "            # Log the validation loss and accuracy\n",
    "            # print(f\"Epoch: {epoch+1}/{self.epochs}.. Training Accuracy: {train_accuracy:.3f}.. Validation Accuracy: {valid_accuracy:.3f}\")\n",
    "\n",
    "            # Log epoch-wise accuracies\n",
    "            wandb.log({\"epoch\": epoch, \"Training Accuracy\": train_accuracy, \n",
    "                       \"Validation Accuracy\": valid_accuracy, \"Training Loss\": train_loss, \n",
    "                       \"Validation Loss\": valid_loss,  \"Validation F1 Score\": f1,\n",
    "                       })\n",
    "\n",
    "            if valid_loss <= self.valid_loss_min:\n",
    "                print(f\"Validation loss decreased ({self.valid_loss_min:.3f} --> {valid_loss:.3f}). Saving model...\")\n",
    "                \n",
    "                # Log the model and its parameters \n",
    "                # wandb.log_artifact(self.model)\n",
    "                state = {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"state_dict\": self.model.state_dict(),\n",
    "                    \"optimizer\": self.optimizer.state_dict(),\n",
    "                    \"loss\": valid_loss, \n",
    "                   \n",
    "                }\n",
    "                torch.save(state, \"../models/intent_classification_model.pt\")\n",
    "                self.valid_loss_min = valid_loss\n",
    "\n",
    "            self.epoch_lst.append(epoch + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things I Need to Add\n",
    "- WandB table\n",
    "- Log artifact (model)\n",
    "- For now, include all the basic elements (then we can improve upon this in the future)\n",
    "- Ability to track across multiple hyperparameters\n",
    "- Set the configuration after the run is complete\n",
    "- Sweeps (...) AND Improvisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# trainer = ModelTrainer(padded_X_train.shape[1])\n",
    "# train_features, val_features = padded_X_train, padded_X_val\n",
    "# trainer.train(train_features, y_train_encoded, val_features, y_val_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset needs extensive cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 1775.704). Saving model...\n",
      "Validation loss decreased (1775.704 --> 1410.457). Saving model...\n",
      "Validation loss decreased (1410.457 --> 1296.015). Saving model...\n",
      "Validation loss decreased (1296.015 --> 1148.233). Saving model...\n",
      "Validation loss decreased (1148.233 --> 1107.683). Saving model...\n",
      "Validation loss decreased (1107.683 --> 1070.194). Saving model...\n",
      "Validation loss decreased (1070.194 --> 1057.250). Saving model...\n",
      "Validation loss decreased (1057.250 --> 1038.462). Saving model...\n",
      "Validation loss decreased (1038.462 --> 1004.998). Saving model...\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer = ModelTrainer(seq_len)\n",
    "trainer.train(train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.69      0.74      0.71       314\\n           1       0.99      0.97      0.98       279\\n           2       0.89      0.88      0.88       293\\n           3       0.99      0.99      0.99       320\\n           4       0.97      1.00      0.98       279\\n           5       0.76      0.70      0.73       301\\n           6       0.99      1.00      1.00       312\\n           7       0.56      0.63      0.60       284\\n           8       0.91      0.81      0.85       299\\n\\n   micro avg       0.86      0.86      0.86      2681\\n   macro avg       0.86      0.86      0.86      2681\\nweighted avg       0.86      0.86      0.86      2681\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_report_epoch[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 5, ..., 3, 6, 4])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['challenge_robot', 'discount', 'quality', ..., 'goodbye',\n",
       "       'speak_representative', 'greeting'], dtype='<U20')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded_inverse = label_encoder.inverse_transform(y_encoded)\n",
    "y_encoded_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 5, 6, 2, 5, 3, 8, 0, 1, 8, 6, 2, 0, 4, 6, 7, 1, 5, 0])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['challenge_robot', 'discount', 'quality', 'speak_representative',\n",
       "       'discount', 'quality', 'goodbye', 'track', 'account',\n",
       "       'challenge_robot', 'track', 'speak_representative', 'discount',\n",
       "       'account', 'greeting', 'speak_representative', 'support',\n",
       "       'challenge_robot', 'quality', 'account'], dtype='<U20')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded_inverse[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a label-code dictionary\n",
    "label_code_dict = dict(zip(y_encoded, y_encoded_inverse))\n",
    "## Create inverse as well \n",
    "label_code_dict_inverse = dict(zip(y_encoded_inverse, y_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[231,   1,  11,   0,   0,   4,   1,  50,  16],\n",
       "       [  0, 272,   0,   0,   7,   0,   0,   0,   0],\n",
       "       [  8,   0, 257,   0,   0,  11,   0,  16,   1],\n",
       "       [  0,   0,   0, 318,   0,   2,   0,   0,   0],\n",
       "       [  0,   0,   0,   0, 279,   0,   0,   0,   0],\n",
       "       [ 14,   0,  12,   1,   0, 210,   0,  59,   5],\n",
       "       [  0,   0,   0,   0,   0,   0, 312,   0,   0],\n",
       "       [ 46,   0,   8,   2,   2,  44,   1, 179,   2],\n",
       "       [ 35,   1,   2,   0,   0,   7,   0,  13, 241]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix_epoch[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the Training Function\n",
    "# def train():\n",
    "#     # Initialize a new wandb run\n",
    "#     wandb.init(config=sweep_defaults)\n",
    "    \n",
    "#     # Modify the trainer initialization and training process to use config parameters\n",
    "#     trainer = ModelTrainer(padded_X_train.shape[1])\n",
    "#     train_features, val_features = padded_X_train, padded_X_val\n",
    "    \n",
    "#     # Assuming the trainer.train method is modified to accept epochs and batch_size\n",
    "#     trainer.train(train_features, y_train_encoded, val_features, y_val_encoded)\n",
    "        \n",
    "# # Step 4: Start the Sweep Agent\n",
    "# wandb.agent(sweep_id, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_checkpoint(model, optimizer, filename='../models/intent_classification_model.pt'):\n",
    "#     # Note: Input model & optimizer should be pre-defined.  This routine only updates their states.\n",
    "#     start_epoch = 15\n",
    "#     if os.path.isfile(filename):\n",
    "#         print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "#         checkpoint = torch.load(filename)\n",
    "#         start_epoch = checkpoint['epoch']\n",
    "#         model.load_state_dict(checkpoint['state_dict'])\n",
    "#         optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "#         losslogger = checkpoint['loss']\n",
    "#         print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "#                   .format(filename, checkpoint['epoch']))\n",
    "#     else:\n",
    "#         print(\"=> no checkpoint found at '{}'\".format(filename))\n",
    "\n",
    "#     return model, optimizer, start_epoch, losslogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = IntentClassifier(seq_len, embedding_matrix)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "# model, optimizer, start_epoch, losslogger = load_checkpoint(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue training the model\n",
    "# model_trainer = ModelTrainer(seq_len)\n",
    "# model_trainer.train(padded_X_train_tensor, y_train_encoded, padded_X_val_tensor, y_val_encoded, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the data and related information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TyPe checking\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "from ftlangdetect import detect\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "# Contractions \n",
    "import contractions as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "# Punctuations I want to remove, including the empty token\n",
    "puncts = ['\\u200d', '?', '....','..','...','','@','#', ',', '.', '\"', ':', ')', '(', '-', '!', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '*', '+', '\\\\', \n",
    "    '•', '~', '£', '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', \n",
    "    '½', 'à', '…', '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', \n",
    "    '—', '‹', '─', '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', \n",
    "    'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', \n",
    "    '¹', '≤', '‡', '√', '!','🅰','🅱']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What all functions I have applied earlier??? \n",
    "## I have applied \"detect_language\" function to the text data\n",
    "## Apply the \"clean_text\" function to the text data\n",
    "## Apply the \"lemmatize_and_pos\" function to the text data...not required exactly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My preprocessing functions (defining them here so that I could access them from anywhere in the notebook)\n",
    "# Capture the hashtags and/or usertags \n",
    "# Clean comment text \n",
    "\n",
    "tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "\n",
    "# Function to detect language using langdetect\n",
    "## Check if I have to perform sentence level tokenization first \n",
    "def detect_language(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Detect the language of the given text using langdetect library.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The input text for language detection.\n",
    "\n",
    "    Returns:\n",
    "    - str: The detected language code (e.g., 'en' for English).\n",
    "           If language detection fails, returns 'unknown'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Attempt to detect the language using langdetect\n",
    "        return detect(text)[\"lang\"]\n",
    "    \n",
    "    except Exception:\n",
    "        # Return 'unknown' if language detection fails\n",
    "        return \"unknown\"\n",
    "\n",
    "def clean_text(\n",
    "        text, words=True, stops=True, urls=True, tags=True, hashtags = True, punctuations=True,  \n",
    "        newLine=True, ellipsis=True, special_chars=True, condensed=True, non_breaking_space=True, \n",
    "        character_encodings=True, stopwords=True, only_words=True) -> str:\n",
    "    \n",
    "    \"\"\" Clean tweets after extracting all hashtags and username tags\n",
    "    Not comprehensive enough to capture all idiosyncrasies, but works for most of the time\n",
    "    \"\"\"\n",
    "    \n",
    "    # Capture only words and no numbers\n",
    "    if words:\n",
    "        pattern = r\"\\d\"\n",
    "        text = re.sub(pattern, \"\", text)\n",
    "        \n",
    "    # Remove URLs \n",
    "    if urls:\n",
    "        pattern = \"(https\\:)*\\/*\\/*(www\\.)?(\\w+)(\\.\\w+)\\/*\\w*\"\n",
    "        text = re.sub(pattern, \"\", text)\n",
    "        \n",
    "    # Remove tags \n",
    "    if tags:\n",
    "        text = re.sub(\"@\\S+\", \"\", text)\n",
    "        \n",
    "    # Remove hashtags \n",
    "    if hashtags: \n",
    "        text = re.sub(\"#\\w+\", \"\", text)\n",
    "        \n",
    "    # Remove punctuations\n",
    "    if punctuations:\n",
    "        for punct in puncts: \n",
    "            text = text.replace(punct, \"\")\n",
    "        \n",
    "    # Replacing one or more occurrences of '\\n' with ''\n",
    "    # Replacing multiple occurrences, i.e., >=2 occurrences with '.'\n",
    "    if newLine:\n",
    "        text = re.sub(\"\\n+\", \"\", text)\n",
    "        text = re.sub(r'\\.\\s+', '.', text)\n",
    "        \n",
    "    # Fix contractions\n",
    "    if condensed:\n",
    "        try:\n",
    "            text = cm.fix(text)\n",
    "        except: \n",
    "            print(text)\n",
    "        \n",
    "    # Remove non-breaking space \n",
    "    if non_breaking_space: \n",
    "        pattern = r\"(\\xa0|&nbsp)\"\n",
    "        text = re.sub(pattern, \"\", text)\n",
    "        \n",
    "    # Remove stopwords\n",
    "    if stopwords:\n",
    "        text = text.lower()\n",
    "        # print(f\"Original Shape of the Data is {.shape}\")\n",
    "        \n",
    "        # Splitting with NLTK's Tweet tokenizer. This limits repeated characters to \n",
    "        # three with the reduce lens parameter and strips all the \"@'s\". It also splits \n",
    "        # it into 1-gram tokens         \n",
    "        words = tokenizer.tokenize(text)\n",
    "        filtered_words = [word for word in words if word not in eng_stopwords]\n",
    "        text = \" \".join(words)\n",
    "        text = text.strip()  # Add further checks for cleaning \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inbound_text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>outbound_text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>inbound_lang</th>\n",
       "      <th>inbound_hashtags</th>\n",
       "      <th>outbound_hashtags</th>\n",
       "      <th>clean_inbound_text</th>\n",
       "      <th>clean_outbound_text</th>\n",
       "      <th>outbound_tokens_pos</th>\n",
       "      <th>inbound_tokens_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@AmazonHelp 3 different people have given 3 di...</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>2017-10-31 23:28:00+00:00</td>\n",
       "      <td>@115820 We'd like to take a further look into ...</td>\n",
       "      <td>619</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>different people have given different answers ...</td>\n",
       "      <td>wed like to take a further look into this with...</td>\n",
       "      <td>['-PRON-: NOUN', 'd: VERB', 'like: VERB', 'to:...</td>\n",
       "      <td>['different: NOUN', 'people: NOUN', 'have: NOU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Way to drop the ball on customer service @1158...</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>2017-10-31 22:29:00+00:00</td>\n",
       "      <td>@115820 I'm sorry we've let you down! Without ...</td>\n",
       "      <td>616</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>way to drop the ball on customer service so pi...</td>\n",
       "      <td>i am sorry we have let you down without provid...</td>\n",
       "      <td>['i: NOUN', 'be: NOUN', 'sorry: NOUN', '-PRON-...</td>\n",
       "      <td>['way: NOUN', 'to: NOUN', 'drop: VERB', 'the: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@115823 I want my amazon payments account CLOS...</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>2017-10-31 22:28:34+00:00</td>\n",
       "      <td>@115822 I am unable to affect your account via...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>i want my amazon payments account closed dm me...</td>\n",
       "      <td>i am unable to affect your account via twitter...</td>\n",
       "      <td>['i: NOUN', 'be: NOUN', 'unable: NOUN', 'to: N...</td>\n",
       "      <td>['i: NOUN', 'want: VERB', '-PRON-: NOUN', 'ama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@AmazonHelp @115826 Yeah this is crazy we’re l...</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>2017-11-01 12:53:34+00:00</td>\n",
       "      <td>@115827 Thanks for your patience. ^KM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>yeah this is crazy were less than a week away ...</td>\n",
       "      <td>thanks for your patience km</td>\n",
       "      <td>['thank: NOUN', 'for: NOUN', '-PRON-: NOUN', '...</td>\n",
       "      <td>['yeah: NOUN', 'this: NOUN', 'be: NOUN', 'craz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@115828 How about you guys figure out my Xbox ...</td>\n",
       "      <td>AmazonHelp</td>\n",
       "      <td>2017-10-31 22:28:00+00:00</td>\n",
       "      <td>@115826 I'm sorry for the wait. You'll receive...</td>\n",
       "      <td>627</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>how about you guys figure out my xbox one x pr...</td>\n",
       "      <td>i am sorry for the wait you will receive an em...</td>\n",
       "      <td>['i: NOUN', 'be: NOUN', 'sorry: NOUN', 'for: N...</td>\n",
       "      <td>['how: NOUN', 'about: NOUN', '-PRON-: NOUN', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        inbound_text   author_id  \\\n",
       "0  @AmazonHelp 3 different people have given 3 di...  AmazonHelp   \n",
       "1  Way to drop the ball on customer service @1158...  AmazonHelp   \n",
       "2  @115823 I want my amazon payments account CLOS...  AmazonHelp   \n",
       "3  @AmazonHelp @115826 Yeah this is crazy we’re l...  AmazonHelp   \n",
       "4  @115828 How about you guys figure out my Xbox ...  AmazonHelp   \n",
       "\n",
       "                  created_at  \\\n",
       "0  2017-10-31 23:28:00+00:00   \n",
       "1  2017-10-31 22:29:00+00:00   \n",
       "2  2017-10-31 22:28:34+00:00   \n",
       "3  2017-11-01 12:53:34+00:00   \n",
       "4  2017-10-31 22:28:00+00:00   \n",
       "\n",
       "                                       outbound_text response_tweet_id  \\\n",
       "0  @115820 We'd like to take a further look into ...               619   \n",
       "1  @115820 I'm sorry we've let you down! Without ...               616   \n",
       "2  @115822 I am unable to affect your account via...               NaN   \n",
       "3              @115827 Thanks for your patience. ^KM               NaN   \n",
       "4  @115826 I'm sorry for the wait. You'll receive...               627   \n",
       "\n",
       "  inbound_lang inbound_hashtags outbound_hashtags  \\\n",
       "0           en               []                []   \n",
       "1           en               []                []   \n",
       "2           en               []                []   \n",
       "3           en               []                []   \n",
       "4           en               []                []   \n",
       "\n",
       "                                  clean_inbound_text  \\\n",
       "0  different people have given different answers ...   \n",
       "1  way to drop the ball on customer service so pi...   \n",
       "2  i want my amazon payments account closed dm me...   \n",
       "3  yeah this is crazy were less than a week away ...   \n",
       "4  how about you guys figure out my xbox one x pr...   \n",
       "\n",
       "                                 clean_outbound_text  \\\n",
       "0  wed like to take a further look into this with...   \n",
       "1  i am sorry we have let you down without provid...   \n",
       "2  i am unable to affect your account via twitter...   \n",
       "3                        thanks for your patience km   \n",
       "4  i am sorry for the wait you will receive an em...   \n",
       "\n",
       "                                 outbound_tokens_pos  \\\n",
       "0  ['-PRON-: NOUN', 'd: VERB', 'like: VERB', 'to:...   \n",
       "1  ['i: NOUN', 'be: NOUN', 'sorry: NOUN', '-PRON-...   \n",
       "2  ['i: NOUN', 'be: NOUN', 'unable: NOUN', 'to: N...   \n",
       "3  ['thank: NOUN', 'for: NOUN', '-PRON-: NOUN', '...   \n",
       "4  ['i: NOUN', 'be: NOUN', 'sorry: NOUN', 'for: N...   \n",
       "\n",
       "                                  inbound_tokens_pos  \n",
       "0  ['different: NOUN', 'people: NOUN', 'have: NOU...  \n",
       "1  ['way: NOUN', 'to: NOUN', 'drop: VERB', 'the: ...  \n",
       "2  ['i: NOUN', 'want: VERB', '-PRON-: NOUN', 'ama...  \n",
       "3  ['yeah: NOUN', 'this: NOUN', 'be: NOUN', 'craz...  \n",
       "4  ['how: NOUN', 'about: NOUN', '-PRON-: NOUN', '...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import processed data \n",
    "processed_data = pd.read_csv(\"../data/processed/processed_v2.csv\")\n",
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@115828 How about you guys figure out my Xbox One X project Scorpio edition first. No expected delivery or shipping date and it’s only a week away'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data[\"inbound_text\"][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of common stopwords\n",
    "manual_stopwords = {\n",
    "    'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', \n",
    "    'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', \n",
    "    'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', \n",
    "    'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', \n",
    "    'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \n",
    "    'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', \n",
    "    'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', \n",
    "    'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', \n",
    "    'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', \n",
    "    'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', \n",
    "    'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', \n",
    "    'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def basic_preprocess_tokens(tokens):\n",
    "    \n",
    "    # Convert string representation of list to actual list\n",
    "    # tokens = ast.literal_eval(tokens)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove punctuation\n",
    "    tokens = [token.translate(str.maketrans('', '', string.punctuation)) for token in tokens]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in manual_stopwords]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sorry',\n",
       " 'wait',\n",
       " 'receive',\n",
       " 'email',\n",
       " 'soon',\n",
       " 'estimated',\n",
       " 'delivery',\n",
       " 'date',\n",
       " 'fj']"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text_eg = clean_text(processed_data[\"outbound_text\"][4])\n",
    "cleaned_tokens_eg = basic_preprocess_tokens(cleaned_text_eg.split())\n",
    "cleaned_tokens_eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_eg = shuffled_df[shuffled_df[\"intent\"] == \"support\"]\n",
    "account_eg = shuffled_df[shuffled_df[\"intent\"] == \"account\"]\n",
    "greet_eg = shuffled_df[shuffled_df[\"intent\"] == \"greeting\"]\n",
    "goodbye_eg = shuffled_df[shuffled_df[\"intent\"] == \"goodbye\"]\n",
    "representative_eg = shuffled_df[shuffled_df[\"intent\"] == \"speak_representative\"]\n",
    "robot_eg = shuffled_df[shuffled_df[\"intent\"] == \"challenge_robot\"]\n",
    "quality_eg = shuffled_df[shuffled_df[\"intent\"] == \"quality\"]\n",
    "track_eg = shuffled_df[shuffled_df[\"intent\"] == \"track\"]\n",
    "discount_eg = shuffled_df[shuffled_df[\"intent\"] == \"discount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[231,   1,  11,   0,   0,   4,   1,  50,  16],\n",
       "       [  0, 272,   0,   0,   7,   0,   0,   0,   0],\n",
       "       [  8,   0, 257,   0,   0,  11,   0,  16,   1],\n",
       "       [  0,   0,   0, 318,   0,   2,   0,   0,   0],\n",
       "       [  0,   0,   0,   0, 279,   0,   0,   0,   0],\n",
       "       [ 14,   0,  12,   1,   0, 210,   0,  59,   5],\n",
       "       [  0,   0,   0,   0,   0,   0, 312,   0,   0],\n",
       "       [ 46,   0,   8,   2,   2,  44,   1, 179,   2],\n",
       "       [ 35,   1,   2,   0,   0,   7,   0,  13, 241]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix_epoch[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'challenge_robot',\n",
       " 2: 'discount',\n",
       " 5: 'quality',\n",
       " 6: 'speak_representative',\n",
       " 3: 'goodbye',\n",
       " 8: 'track',\n",
       " 0: 'account',\n",
       " 4: 'greeting',\n",
       " 7: 'support'}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_code_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>tokens</th>\n",
       "      <th>cleaned_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>account</td>\n",
       "      <td>[have, you, the, contact, number, thanks, sorr...</td>\n",
       "      <td>[contact, number, thanks, sorry, hassle]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>account</td>\n",
       "      <td>[does, the, same, information, apply, to, uk, ...</td>\n",
       "      <td>[information, apply, uk, residents]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>account</td>\n",
       "      <td>[i, know, its, a, minor, thing, but, why, can,...</td>\n",
       "      <td>[know, minor, thing, opt, general, account, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>account</td>\n",
       "      <td>[hey, please, pay, my, seller, funds, which, h...</td>\n",
       "      <td>[hey, please, pay, seller, funds, held, days, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>account</td>\n",
       "      <td>[hey, and, what, is, the, deal, with, you, try...</td>\n",
       "      <td>[hey, deal, trying, deliver, something, perhap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13480</th>\n",
       "      <td>account</td>\n",
       "      <td>[i, have, sent, emails, and, am, locked, out, ...</td>\n",
       "      <td>[sent, emails, locked, account, response, fix]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13483</th>\n",
       "      <td>account</td>\n",
       "      <td>[what, is, up, with, your, deliveries, amazon,...</td>\n",
       "      <td>[deliveries, amazon, one, days, purchase, upda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13484</th>\n",
       "      <td>account</td>\n",
       "      <td>[if, you, need, anymore, info, please, let, me...</td>\n",
       "      <td>[need, anymore, info, please, let, know]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13488</th>\n",
       "      <td>account</td>\n",
       "      <td>[hey, thanks, for, the, link, couple, of, agen...</td>\n",
       "      <td>[hey, thanks, link, couple, agents, able, fix,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13494</th>\n",
       "      <td>account</td>\n",
       "      <td>[shout, out, to, for, not, verifying, customer...</td>\n",
       "      <td>[shout, verifying, customers, credit, card, in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1495 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        intent                                             tokens  \\\n",
       "8      account  [have, you, the, contact, number, thanks, sorr...   \n",
       "13     account  [does, the, same, information, apply, to, uk, ...   \n",
       "19     account  [i, know, its, a, minor, thing, but, why, can,...   \n",
       "34     account  [hey, please, pay, my, seller, funds, which, h...   \n",
       "57     account  [hey, and, what, is, the, deal, with, you, try...   \n",
       "...        ...                                                ...   \n",
       "13480  account  [i, have, sent, emails, and, am, locked, out, ...   \n",
       "13483  account  [what, is, up, with, your, deliveries, amazon,...   \n",
       "13484  account  [if, you, need, anymore, info, please, let, me...   \n",
       "13488  account  [hey, thanks, for, the, link, couple, of, agen...   \n",
       "13494  account  [shout, out, to, for, not, verifying, customer...   \n",
       "\n",
       "                                          cleaned_tokens  \n",
       "8               [contact, number, thanks, sorry, hassle]  \n",
       "13                   [information, apply, uk, residents]  \n",
       "19     [know, minor, thing, opt, general, account, su...  \n",
       "34     [hey, please, pay, seller, funds, held, days, ...  \n",
       "57     [hey, deal, trying, deliver, something, perhap...  \n",
       "...                                                  ...  \n",
       "13480     [sent, emails, locked, account, response, fix]  \n",
       "13483  [deliveries, amazon, one, days, purchase, upda...  \n",
       "13484           [need, anymore, info, please, let, know]  \n",
       "13488  [hey, thanks, link, couple, agents, able, fix,...  \n",
       "13494  [shout, verifying, customers, credit, card, in...  \n",
       "\n",
       "[1495 rows x 3 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out different examples\n",
    "account_eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deliveries',\n",
       " 'amazon',\n",
       " 'one',\n",
       " 'days',\n",
       " 'purchase',\n",
       " 'update',\n",
       " 'another',\n",
       " 'delayed',\n",
       " 'info']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "account_eg[\"cleaned_tokens\"][13483]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg_robot = robot_eg[\"cleaned_tokens\"][0]\n",
    "eg_account = account_eg[\"cleaned_tokens\"][13483]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = IntentClassifier(seq_len, embedding_matrix)\n",
    "checkpoint = torch.load(\"../models/intent_classification_model.pt\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-6)\n",
    "\n",
    "# Load the state dictionary\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "epoch = checkpoint[\"epoch\"]\n",
    "valid_loss = checkpoint[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4704"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[\"<unknown>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "733\n",
      "1092\n",
      "133\n",
      "167\n",
      "2461\n",
      "67\n",
      "250\n",
      "4704\n"
     ]
    }
   ],
   "source": [
    "for token in cleaned_tokens_eg:\n",
    "    token_repr = vocabulary.get(token, vocabulary[\"<unknown>\"])\n",
    "    print(token_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "def inference(tokens):\n",
    "    \"\"\" \n",
    "    Perform preprocessing and inference on the input text using the trained model.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The trained PyTorch model for intent classification.\n",
    "    - text: The input text string.\n",
    "    - vocabulary: A dictionary mapping tokens to indices.\n",
    "    - seq_len: The fixed sequence length expected by the model.\n",
    "    \n",
    "    Returns:\n",
    "    - pred_label: The predicted label index.\n",
    "    \"\"\"\n",
    "\n",
    "    # Preprocess the text\n",
    "    # tokens = text.split()\n",
    "    indices = [vocabulary.get(token, vocabulary[\"<unknown>\"]) for token in tokens]  # Use 0 for unknown words\n",
    "    padded_indices = indices[:seq_len] + [0] * max(0, seq_len - len(indices))  # Pad with zeros\n",
    "    print(padded_indices)\n",
    "    input_tensor = torch.tensor(padded_indices).unsqueeze(0)  # Add batch dimension\n",
    "    print(input_tensor)\n",
    "    # print(input_tensor.shape)\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        label = torch.argmax(output, 1)\n",
    "        label_text = label_encoder.inverse_transform(label)\n",
    "    \n",
    "    return label_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35, 733, 1092, 133, 167, 2461, 67, 250, 4704, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([[  35,  733, 1092,  133,  167, 2461,   67,  250, 4704,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['account'], dtype='<U20')"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(cleaned_tokens_eg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['greeting'], dtype='<U20')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_label = label_encoder.inverse_transform([4])\n",
    "original_label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amazon_support",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Approach: Heuristic Intent Distribution Exploration\n",
    "I need to get an insight into the true intents inside my Twitter data. Doing it by keyword might prove to be a good baseline way to do this. \n",
    "\n",
    "\n",
    "Using keywords as a starting point might offer a strong foundational approach for this task. I'm building upon this concept by employing heuristic clustering to organize my intents, aiming to minimize overlaps between them. The goal is to distill a set of intents that are both distinct and exclusive, enhancing Eve bot's ability to differentiate between them.\n",
    "\n",
    "I drew inspiration from observing other solutions, particularly the \"semantic fingerprint\" concept implemented by cortex, although the specific workings were undisclosed. This prompted me to devise my approach. Initially, I considered branching off into manual selection of 1000 examples, but I realized this was impractical and overly laborious.\n",
    "\n",
    "This notebook serves as my strategy for generating training data for intent classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(f'pandas: {pd.__version__}')\n",
    "import numpy as np\n",
    "print(f'numpy: {np.__version__}')\n",
    "# Visualization \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "# Making my visualizations pretty\n",
    "sns.set_style('whitegrid')\n",
    "# Combination exploration\n",
    "import itertools\n",
    "import yaml\n",
    "\n",
    "# Loading back processed data\n",
    "processed = pd.read_pickle('objects/processed.pkl') # Load data from 1.0_ipynb file \n",
    "print(f'\\ninbound:\\n{processed.head()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief Keyword Search EDA\n",
    "Using this as a tool to look at Tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search by keywords (single keyword filter)\n",
    "keyword = 'info'\n",
    "\n",
    "# Seeing what the processed Tweets look like\n",
    "filt = [(i,j) for i,j in enumerate(processed['Processed Inbound']) if keyword in j]\n",
    "filtered = processed.iloc[[i[0] for i in filt]]\n",
    "print(f'{len(filtered)} Tweets contain the keyword {keyword}')\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
